# Local README — Project Setup & Data Guide

> For collaborators working on the **Measuring Faithfulness of CoT Reasoning in LALMs** project.
> Cluster: **Fir** (Digital Research Alliance of Canada)

---

## Environment Setup

### Module Loading (required before activating any env)

```bash
module load StdEnv/2023 cuda/12.2 rust gcc arrow
```

### Virtual Environments

| Env            | Purpose                         | Activation                         |
| -------------- | ------------------------------- | ---------------------------------- |
| `qwen_env`     | Qwen2-Audio inference           | `source qwen_env/bin/activate`     |
| `salmonn_env`  | SALMONN inference (7B/13B)      | `source salmonn_env/bin/activate`  |
| `mistral_env`  | Mistral perturbation generation | `source mistral_env/bin/activate`  |
| `analysis_env` | Plotting, analysis scripts      | `source analysis_env/bin/activate` |

---

## Project Root

```
/scratch/lovenya/Measuring-Faithfulness-of-CoT-Reasoning-LALMs/
```

---

## Data Structure

### Raw Datasets (standardized JSONL + audio files)

Each dataset has a `*_test_standardized.jsonl` file (normalized MCQ format) and an `audio/` directory with WAV files.

```
data/
├── mmar/
│   ├── mmar_test_standardized.jsonl      ← normalized JSONL (question, choices, answer, audio_path)
│   └── audio/                             ← original audio files (.wav)
├── sakura/
│   ├── animal/
│   │   ├── sakura_animal_test_standardized.jsonl
│   │   └── audio/
│   ├── emotion/
│   │   ├── sakura_emotion_test_standardized.jsonl
│   │   └── audio/
│   ├── gender/
│   │   ├── sakura_gender_test_standardized.jsonl
│   │   └── audio/
│   └── language/
│       ├── sakura_language_test_standardized.jsonl
│       └── audio/
```

> **Normalization scripts** are in `data_processing/`. Each dataset has a `download_and_normalize_*.py` script
> that fetches the raw data and produces the standardized JSONL format. These are standard and reproducible.

### Standardized JSONL Format

Each line is a JSON object:

```json
{
  "item_id": "unique_id",
  "question": "What instrument is playing?",
  "choices": "(A) Piano\n(B) Guitar\n(C) Violin\n(D) Drums",
  "answer": "(A)",
  "audio_path": "data/mmar/audio/sample_001.wav"
}
```

### Masked Audio Datasets

Generated by `data_processing/mask_audio_dataset.py`. Structure follows `{mask_type}_{mask_mode}/{level}/`:

```
data/mmar_masked/
├── silence_start/
│   ├── 10/          ← 10% masked from start
│   │   ├── audio/   ← masked WAV files
│   │   └── mmar_test_standardized.jsonl  ← JSONL pointing to masked audio
│   ├── 20/
│   ├── ...
│   └── 100/
├── silence_end/
├── silence_scattered/
├── noise_start/
├── noise_end/
└── noise_scattered/

data/sakura/animal_masked/       ← same structure per Sakura subdataset
data/sakura/emotion_masked/
data/sakura/gender_masked/
data/sakura/language_masked/
```

**Mask types:** `silence` (zero out audio), `noise` (add Gaussian noise)
**Mask modes:** `start` (from beginning), `end` (from end), `scattered` (multiple random segments)

---

## Model Weights

All model weights are stored on `/scratch/`:

| Model            | Path                                                         |
| ---------------- | ------------------------------------------------------------ |
| Qwen2-Audio-7B   | `/scratch/lovenya/models/Qwen/Qwen2-Audio-7B`                |
| Audio Flamingo 3 | `./audio-flamingo-weights/` (project dir)                    |
| SALMONN 13B      | `./model_components/salmonn-13b-checkpoint/salmonn_v1.pth`   |
| SALMONN 7B       | `./model_components/salmonn-7b-checkpoint/salmonn_7b_v0.pth` |
| Mistral Small 3  | `./model_components/mistral-small-3/`                        |

See `config.py` for the full path mapping (`MODEL_PATHS` and `SALMONN_COMPONENT_PATHS`).

---

## Results Structure

Results are stored in `results/{model}/{experiment}/`:

```
results/
└── qwen/
    ├── audio_masking/
    │   ├── silence/
    │   │   ├── start/    ← audio_masking_qwen_mmar_silence_start.jsonl, etc.
    │   │   ├── end/
    │   │   └── scattered/
    │   └── noise/
    │       ├── start/
    │       ├── end/
    │       └── scattered/
    ├── adding_mistakes/   ← flat structure
    ├── paraphrasing/
    ├── partial_filler_text/
    └── baseline/
```

Each result JSONL contains one entry per trial with CoT, final answer, and consistency metrics.

---

## Submission Scripts & Logs

Hierarchical structure (mirrors results):

```
submission_scripts/qwen/audio_masking/{silence,noise}/{start,end,scattered}/
logs/qwen/audio_masking/{silence,noise}/{start,end,scattered}/
```

---

## Compute Accounts

| Account               | Purpose                         | Resources                                |
| --------------------- | ------------------------------- | ---------------------------------------- |
| `rrg-ravanelm`        | GPU experiments (H100)          | `--gpus=nvidia_h100_80gb_hbm3_3g.40gb:1` |
| `def-csubakan-ab_cpu` | CPU-only jobs (data processing) | No GPU                                   |

---

## Quick Reference Commands

```bash
# Submit an experiment
sbatch submission_scripts/qwen/audio_masking/silence/start/run_qwen_mmar.sh

# Check running jobs
squeue -u $USER -o "%.10i %.40j %.8T %.10M %.6D %R"

# Generate masked audio data
sbatch submission_scripts/data_processing/generate_masked_datasets.sh

# Run analysis/plots (use analysis_env)
python analysis/per_dataset/plot_audio_masking.py --model qwen --dataset mmar --mask-type all --mask-mode all

# Run a single experiment interactively (for debugging)
python main.py --model qwen --experiment audio_masking --dataset mmar --mask-type silence --mask-mode start --num-samples 5 --verbose
```

---

## Key Configuration Files

| File                    | Purpose                                                      |
| ----------------------- | ------------------------------------------------------------ |
| `config.py`             | Central config: model paths, dataset mapping, defaults       |
| `experiments_status.md` | Experiment tracking: completed, ready-to-submit, in-pipeline |
| `main.py`               | Entry point for all experiments                              |
