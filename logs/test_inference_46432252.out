========================================================
Starting Slurm Job: Testing Sample 3 Inference Code
Job ID: 46432252
Job Name: test_sample3_inference
Running on host: ng10604
Executing in directory: /project/def-csubakan-ab/lovenya/Measuring-Faithfulness-of-CoT-Reasoning-LALMs
Allocated GPU: 0
========================================================
Loading modules...
Activating Python environment...
Running the Python inference script...
Loading model from ./Qwen2-Audio-7B-Instruct/...
Model loaded successfully!
==================================================
MMAR Sample Inference
==================================================

Processing: mmar_3
Question: Is this man drunk?
Choices: ['Drunk', 'Not drunk']
Audio: data/mmar/audio/mmar_audio_3.wav
Model Response: (a)
Correct Answer Key: 0

==================================================
Sakura Sample Inference
==================================================

Processing: sakura_animal_33_single
Question: Can you select the animal from the provided options that matches the sound?
Choices: ['cow', 'cat', 'hen', 'dog']
Audio: data/sakura/animal/audio/sakura_animal_audio_33.wav
Model Response: The sound is most likely made by a (b) cat.
Correct Answer Key: 1

==================================================
SUMMARY
==================================================
MMAR Response: (a)
Sakura Response: The sound is most likely made by a (b) cat.
Python script finished with exit code: 0
Python environment deactivated.
========================================================
Slurm Job Finished.
========================================================
