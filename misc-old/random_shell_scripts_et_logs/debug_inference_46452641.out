========================================================
Starting Slurm Job: Testing debug inference Code
Job ID: 46452641
Job Name: debug_inference
Running on host: ng10302
Executing in directory: /project/def-csubakan-ab/lovenya/Measuring-Faithfulness-of-CoT-Reasoning-LALMs
Allocated GPU: 0
========================================================
Loading modules...
Activating Python environment...
Running the Python inference script...
Loading processor & model from './Qwen2-Audio-7B-Instruct'...
Loaded on device: cuda:0

[3] Processor expects sampling_rate = 16000, librosa.load using target_sr = 16000
[2] Loaded 64064 samples from data/sakura/emotion/audio/sakura_emotion_audio_7.wav, RMS amplitude = 0.118418
[1] Testing keyword-arg variants:
    • processor(..., audio=[wav], ...) accepted → keys: ['input_ids', 'attention_mask', 'input_features', 'feature_attention_mask']
    • processor(..., audios=[wav], ...) accepted → keys: ['input_ids', 'attention_mask', 'input_features', 'feature_attention_mask']

[4] Running minimal local‑file example:

[5] INPUT TENSORS (local minimal example) — shape listing:
    input_ids            (1, 134)
    attention_mask       (1, 134)
    input_features       (1, 128, 3000)
    feature_attention_mask (1, 3000)

    Local minimal output: It's a clock ticking. 


[5] Building inputs with the CORRECT kwarg (audio=)...

[5] INPUT TENSORS (Local file final) — shape listing:
    input_ids            (1, 132)
    attention_mask       (1, 132)
    input_features       (1, 128, 3000)
    feature_attention_mask (1, 3000)

[5] Generating on local file (final)...
    Raw model output: 'This is a dog.<|im_end|>'
Python script finished with exit code: 0
Python environment deactivated.
========================================================
Slurm Job Finished.
========================================================
