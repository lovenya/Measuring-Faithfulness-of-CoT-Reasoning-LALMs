========================================================
Starting Slurm Job: Test2 Inference
Job ID: 46431788
Job Name: sample2_inference
Running on host: ng10501
Executing in directory: /project/def-csubakan-ab/lovenya/Measuring-Faithfulness-of-CoT-Reasoning-LALMs
Allocated GPU: 0
========================================================
Loading modules...
Activating Python environment...
Running the Python inference script...
Using device: cuda
Loading model and processor from: ./Qwen2-Audio-7B-Instruct
Model loaded successfully!

=== Testing on sakura_animal ===
Sample ID: sakura_animal_459_single
Audio path: data/sakura/animal/audio/sakura_animal_audio_459.wav
Question: Out of the provided options, which animal do you think is responsible for the sound captured in the provided audio recording? (a) hen (b) rooster (c) sheep (d) cat
Choices: ['hen', 'rooster', 'sheep', 'cat']
(Ground truth: sheep)

=== Raw model output ===
<|im_end|>
========================

=== Testing on sakura_emotion ===
Sample ID: sakura_emotion_266_multi
Audio path: data/sakura/emotion/audio/sakura_emotion_audio_266.wav
Question: From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio? (a) Tightly pressed lips with glaring eyes (b) Downturned mouth and teary eyes (c) Relaxed facial muscles with a cheerful grin (d) Frozen facial expression with trembling lips and quickened breathing.
Choices: ['Tightly pressed lips with glaring eyes', 'Downturned mouth and teary eyes', 'Relaxed facial muscles with a cheerful grin', 'Frozen facial expression with trembling lips and quickened breathing.']
(Ground truth: Frozen facial expression with trembling lips and quickened breathing.)

=== Raw model output ===
<|im_end|>
========================

=== Testing on sakura_gender ===
Sample ID: sakura_gender_164_single
Audio path: data/sakura/gender/audio/sakura_gender_audio_164.wav
Question: Your task is to determine the gender of the speaker in the audio clip provided. Please identify the speaker's gender and select the option that you believe is most accurate. (a) Female (b) Male
Choices: ['Female', 'Male']
(Ground truth: Female)

=== Raw model output ===
<|im_end|>
========================

=== Testing on sakura_language ===
Sample ID: sakura_language_118_single
Audio path: data/sakura/language/audio/sakura_language_audio_118.wav
Question: Determine the language of the provided speech. (a) Korean (b) Chinese (c) Spanish (d) English
Choices: ['Korean', 'Chinese', 'Spanish', 'English']
(Ground truth: English)

=== Raw model output ===
<|im_end|>
========================

=== Testing on mmar ===
Sample ID: mmar_551
Audio path: data/mmar/audio/mmar_audio_551.wav
Question: Why are the woman and man laughing in the audio?
Choices: ['Because the baby is dancing', 'Because the baby is sneezing', 'Because the baby said the first word', 'Because the baby is making a funny face']
(Ground truth: Because the baby is sneezing)

=== Raw model output ===
<|im_end|>
========================
Python script finished with exit code: 0
Python environment deactivated.
========================================================
Slurm Job Finished.
========================================================
