{"id": "sakura_emotion_0_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_0_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Express understanding calmly and suggest leaving the unpleasant environment.", "Suggest spending some time together to cheer them up.", "Hold their hand or offer some physical reassurance.", "Listen attentively without interrupting to let them vent."], "answer": "Suggest spending some time together to cheer them up.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_0.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[130, 1708], [1895, 4464], [5564, 6590], [7256, 12766], [12833, 14100], [14889, 18504], [18815, 20327], [20556, 22266], [22330, 24398], [26002, 28159], [29309, 30501], [31451, 33602], [33749, 35243], [35963, 37488]], "num_segments": 14}
{"id": "sakura_emotion_1_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_1_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Provide emotional support and avoid dismissing their sadness.", "Encourage them to take deep breaths to relax.", "Reassure them and offer a way to move past the uncomfortable    situation.", "Suggest an activity to keep the positive energy flowing."], "answer": "Reassure them and offer a way to move past the uncomfortable    situation.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_1.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[212, 1362], [1448, 4187], [4265, 5273], [6870, 7711], [8147, 15245], [15550, 16436], [16747, 18409], [18860, 20492], [21431, 26248], [26999, 31071], [31385, 32894], [33562, 38924], [39264, 40622]], "num_segments": 13}
{"id": "sakura_emotion_5_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_5_masked_100pct.wav", "question": "Considering the emotion expressed in the audio, which of the following facial expressions would align most closely with it?", "choices": ["Squinted eyes and a pinched nose", "Wide-open eyes with raised eyebrows and slightly parted lips.", "A sharp, piercing gaze and compressed lips", "Eyes gazing downward with trembling lips"], "answer": "Eyes gazing downward with trembling lips", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_5.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1399, 6456], [7341, 8505], [9053, 13019], [14373, 20487], [20532, 21746], [22920, 27908], [29216, 35255], [35521, 37686]], "num_segments": 8}
{"id": "sakura_emotion_2_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_2_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "angry", "sad", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_2.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[107, 2065], [2593, 7419], [8525, 10369], [10460, 11612], [12230, 16677], [18133, 21056], [21135, 24041], [24276, 25589], [25666, 28461], [28750, 30190], [30911, 34662], [35245, 36327], [37069, 38164]], "num_segments": 13}
{"id": "sakura_emotion_0_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_0_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["sad", "fear", "happy", "disgust"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_0.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[120, 1596], [1671, 3668], [5025, 6271], [6468, 7800], [7965, 9050], [10575, 12256], [12507, 17536], [18849, 20183], [20586, 28472], [29948, 33323], [35184, 36388]], "num_segments": 11}
{"id": "sakura_emotion_6_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_6_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "disgust", "angry", "happy"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_6.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[629, 1724], [2174, 3038], [3453, 5502], [6169, 8033], [8852, 13951], [14877, 15723], [16528, 18525], [19930, 23599], [24817, 27501], [28378, 29952], [30294, 31742], [33452, 35007], [36587, 37487], [38205, 41359], [41461, 42590]], "num_segments": 15}
{"id": "sakura_emotion_1_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_1_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "disgust", "sad", "angry"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_1.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1185, 3121], [3191, 5137], [5547, 6846], [7465, 11214], [12314, 13551], [13875, 20969], [21593, 26949], [27631, 30430], [31734, 33554], [33620, 35546], [36759, 37694], [38321, 39795], [39851, 40959]], "num_segments": 13}
{"id": "sakura_emotion_7_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_7_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "angry", "fear", "sad"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_7.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[316, 2514], [3021, 5948], [7024, 14110], [14154, 15320], [16218, 18191], [19073, 20923], [21032, 22027], [22530, 23967], [24860, 25981], [26310, 28346], [28446, 33629], [34654, 41389], [41429, 42678], [43589, 48464], [48650, 51375], [52174, 53254], [53818, 56984], [57279, 59319], [59870, 61082], [61534, 62442], [62658, 63646]], "num_segments": 21}
{"id": "sakura_emotion_2_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_2_masked_100pct.wav", "question": "What facial expression most aligns with the emotion in the recording?", "choices": ["A warm, genuine smile with slightly tilted head", "Frozen facial expression with trembling lips and quickened breathing.", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "Tightly pressed lips with glaring eyes"], "answer": "Frozen facial expression with trembling lips and quickened breathing.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_2.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[755, 2015], [2152, 2989], [3105, 9085], [9847, 12333], [12600, 13851], [14242, 15501], [16627, 20370], [21067, 22056], [22467, 28153], [28777, 30932], [31325, 35789], [36683, 37828]], "num_segments": 12}
{"id": "sakura_emotion_6_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_6_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Saying goodbye at an airport.", "A person yelling after being cut off in traffic.", "Hearing a shocking and offensive statement.", "Facing an aggressive dog on the street."], "answer": "A person yelling after being cut off in traffic.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_6.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1115, 2121], [2194, 8413], [9334, 11887], [11989, 13084], [13684, 18806], [19096, 24813], [25426, 26299], [27002, 28112], [29075, 34827], [34882, 41928], [42117, 43008]], "num_segments": 11}
{"id": "sakura_emotion_8_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_8_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["sad", "fear", "angry", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_8.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[536, 8050], [8337, 9932], [10175, 16261], [16708, 17767], [18094, 19880], [19944, 20759], [21661, 23524], [24106, 25991], [26070, 29025], [29973, 30850], [31362, 34106], [34338, 35194]], "num_segments": 12}
{"id": "sakura_emotion_9_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_9_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["sad", "disgust", "angry", "happy"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_9.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[492, 3996], [5068, 6218], [6336, 12696], [15063, 16930], [18496, 24184], [25023, 25955], [26748, 33184], [34057, 35319], [35760, 37026], [37103, 38128], [38874, 42624], [43548, 51055]], "num_segments": 12}
{"id": "sakura_emotion_8_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_8_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Celebrate their joy with a cheerful response.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Hold their hand or offer some physical reassurance.", "Apologize and admit your mistake, if appropriate."], "answer": "Celebrate their joy with a cheerful response.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_8.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1176, 3044], [3594, 4789], [5654, 7046], [7687, 9409], [9758, 10936], [11460, 15439], [15782, 16786], [17781, 19855], [21004, 27544], [28772, 29799], [29810, 32100], [32827, 33698], [33756, 34944]], "num_segments": 13}
{"id": "sakura_emotion_3_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_3_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "sad", "happy", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_3.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1012, 6993], [7104, 8437], [9781, 16090], [16296, 21933], [21981, 27136], [27771, 28659], [29919, 37347]], "num_segments": 7}
{"id": "sakura_emotion_10_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_10_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "happy", "angry", "sad"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_10.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1368, 3323], [3714, 5543], [5887, 13370], [13374, 17277], [17713, 21424], [21989, 24365], [24893, 26651], [26670, 30442], [30720, 31814], [32109, 37084], [37682, 39097], [39464, 40854], [40876, 43136], [43475, 45536], [46813, 47768]], "num_segments": 15}
{"id": "sakura_emotion_9_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_9_masked_100pct.wav", "question": "Considering the emotion expressed in the audio, which of the following facial expressions would align most closely with it?", "choices": ["A broad smile with sparkling eyes", "Clenched teeth with side facial muscles showing tension.", "Eyes gazing downward with trembling lips", "A wrinkled nose and raised upper lip"], "answer": "Clenched teeth with side facial muscles showing tension.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_9.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[725, 5360], [5696, 7467], [7580, 10281], [10788, 12478], [12784, 14661], [14929, 16366], [16705, 23282], [24741, 32122], [32224, 33065], [33871, 34770], [34972, 36776], [37720, 38983], [39671, 43741], [44531, 45908], [45977, 51764]], "num_segments": 15}
{"id": "sakura_emotion_3_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_3_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["Attending a close friend's funeral.", "Reacting to a sudden loud noise in an empty house.", "Turning away from spoiled food.", "A person smiling after receiving good news."], "answer": "Reacting to a sudden loud noise in an empty house.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_3.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[850, 4255], [5099, 6115], [6683, 7789], [8272, 14365], [15330, 16203], [16288, 17178], [17193, 18897], [18914, 22101], [22862, 25272], [26215, 27502], [27521, 28418], [28666, 30477], [30938, 31995], [32660, 35827], [36406, 37218]], "num_segments": 15}
{"id": "sakura_emotion_5_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_5_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["sad", "disgust", "angry", "happy"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_5.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[205, 3820], [4045, 6103], [6300, 10461], [10959, 12746], [12959, 14638], [15006, 16634], [16664, 22188], [22320, 23379], [23622, 29764], [31901, 35578], [36938, 37759]], "num_segments": 11}
{"id": "sakura_emotion_11_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_11_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Attending a close friend's funeral.", "Walking alone in a dark alley at night.", "Celebrating a birthday with friends and family.", "Seeing an unpleasant image online."], "answer": "Seeing an unpleasant image online.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_11.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[953, 2025], [2190, 9705], [10029, 10946], [11288, 12386], [14238, 20178], [20200, 22332], [23176, 30841], [30867, 31847], [31877, 33710], [33835, 35964], [36073, 38282], [38738, 41837], [42816, 44917], [45439, 46260], [46792, 52996], [53885, 56840]], "num_segments": 16}
{"id": "sakura_emotion_11_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_11_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "angry", "disgust", "happy"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_11.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[302, 1859], [2846, 4137], [6445, 7306], [8405, 14602], [15107, 19333], [19810, 20962], [21963, 22862], [23152, 26334], [27389, 34816], [34888, 36305], [36631, 42535], [44854, 49642], [50442, 53134], [55132, 58019]], "num_segments": 14}
{"id": "sakura_emotion_4_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_4_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["angry", "disgust", "happy", "fear"], "answer": "angry", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_4.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1027, 6335], [6986, 7836], [9042, 12894], [13165, 13980], [14101, 18990], [19037, 19910], [20886, 22832], [23067, 28042], [28330, 30451], [31618, 33810], [34088, 37301], [37897, 39632], [39668, 40705]], "num_segments": 13}
{"id": "sakura_emotion_4_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_4_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Avoid discussing further and respect their aversion to the topic.", "Express genuine excitement for their good news or achievement.", "Stay calm and provide support to ease their anxiety.", "Calmly acknowledge their frustration and suggest a solution."], "answer": "Calmly acknowledge their frustration and suggest a solution.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_4.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[422, 2967], [3455, 5222], [5626, 7279], [7620, 11728], [12791, 20416], [21342, 23479], [23766, 26501], [26995, 28599], [29051, 29923], [29976, 32578], [33161, 34637], [34885, 37335], [37420, 38593], [39280, 40836]], "num_segments": 14}
{"id": "sakura_emotion_10_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_10_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Preparing for a high-stakes exam with anxiety.", "Seeing an unpleasant image online.", "Laughing at a funny joke in a conversation.", "Saying goodbye at an airport."], "answer": "Laughing at a funny joke in a conversation.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_10.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[105, 2703], [3230, 4598], [4717, 9008], [10370, 15279], [15606, 18258], [18612, 21997], [22343, 23314], [24096, 28666], [29140, 34692], [34929, 37868], [38830, 40274], [41168, 42069], [42594, 44175], [44953, 47378]], "num_segments": 14}
{"id": "sakura_emotion_7_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_7_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Suggest an activity to keep the positive energy flowing.", "Reassure them and offer a way to move past the uncomfortable    situation.", "Provide emotional support and avoid dismissing their sadness.", "Calmly acknowledge their frustration and suggest a solution."], "answer": "Calmly acknowledge their frustration and suggest a solution.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_7.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[114, 2125], [2501, 4066], [4759, 11120], [13105, 14247], [14468, 16318], [16601, 18068], [19254, 21846], [22590, 23638], [23642, 24669], [25109, 26248], [26552, 28405], [29993, 32317], [33532, 37034], [37232, 38181], [39454, 46670], [47112, 47960], [48356, 49356], [49503, 51206], [52440, 56820], [56970, 58001], [58034, 59320], [59467, 60897], [61970, 63409]], "num_segments": 23}
{"id": "sakura_emotion_12_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_12_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "happy", "sad", "angry"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_12.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[284, 1169], [2010, 2950], [3577, 7800], [8251, 9066], [9660, 15824], [16326, 17550], [17633, 25181], [25997, 26825], [27173, 28900], [29218, 30118], [30118, 31813], [32353, 33376], [33638, 35186]], "num_segments": 13}
{"id": "sakura_emotion_12_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_12_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["Wrinkled forehead and a forlorn expression", "Tightly furrowed brow with trembling lips", "Flared nostrils with a tense expression", "A radiant expression with raised cheeks"], "answer": "Wrinkled forehead and a forlorn expression", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_12.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[430, 5673], [5956, 9910], [10044, 11524], [11715, 13068], [13398, 16987], [17475, 18882], [19015, 20976], [22049, 26357], [26462, 30262], [31418, 32276], [33580, 35226]], "num_segments": 11}
{"id": "sakura_emotion_13_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_13_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "disgust", "angry", "sad"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_13.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[548, 3974], [4437, 5267], [5327, 6459], [6751, 9971], [10427, 11296], [11704, 18771], [19653, 27090], [27875, 34030], [34041, 35763], [37099, 39535], [40683, 41562]], "num_segments": 11}
{"id": "sakura_emotion_13_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_13_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["Stop making excuses; this is entirely your fault!", "It\u2019s so dirty! Please clean it as quick as possible.", "I can\u2019t breathe, I\u2019m just so afraid right now.", "I feel so grateful and full of joy right now."], "answer": "I can\u2019t breathe, I\u2019m just so afraid right now.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_13.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[569, 1443], [2511, 3598], [3926, 7215], [7294, 10427], [10676, 11804], [12811, 13827], [14016, 15267], [16541, 20455], [21665, 28977], [29742, 32269], [33350, 38488], [39041, 40933]], "num_segments": 12}
{"id": "sakura_emotion_14_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_14_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "fear", "angry", "happy"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_14.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[245, 1084], [1239, 6552], [7615, 11818], [12221, 14288], [15203, 19488], [19863, 25499], [26702, 31677], [31910, 32883], [32998, 40425], [41170, 44870], [45015, 48669], [48822, 49756], [49955, 51149]], "num_segments": 13}
{"id": "sakura_emotion_15_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_15_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["disgust", "happy", "angry", "sad"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_15.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1390, 2328], [2365, 3779], [4547, 6813], [8259, 10178], [10458, 12276], [12279, 14916], [15368, 16394], [16908, 18510], [19795, 24777], [25486, 28422], [28720, 29691], [29818, 37124], [38471, 39340]], "num_segments": 13}
{"id": "sakura_emotion_15_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_15_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Stay calm and provide support to ease their anxiety.", "Give them space to cool off before engaging further.", "Avoid discussing further and respect their aversion to the topic.", "Suggest spending some time together to cheer them up."], "answer": "Give them space to cool off before engaging further.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_15.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[108, 2167], [3455, 4522], [4807, 10270], [10830, 15564], [15935, 17938], [18455, 19321], [20319, 27522], [28689, 31009], [32025, 33688], [34079, 35140], [35600, 38573]], "num_segments": 11}
{"id": "sakura_emotion_14_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_14_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Calmly acknowledge their frustration and suggest a solution.", "Offer a comforting hug or words of reassurance.", "Encourage them to take deep breaths to relax."], "answer": "Calmly acknowledge their frustration and suggest a solution.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_14.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1344, 4402], [4412, 5323], [6149, 7909], [8789, 10112], [11564, 13294], [13354, 15058], [15206, 22261], [22483, 24754], [25067, 25891], [26210, 28970], [29079, 30421], [31002, 33062], [33342, 36824], [37243, 38733], [39641, 42554], [43532, 48606], [48754, 49827]], "num_segments": 17}
{"id": "sakura_emotion_17_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_17_masked_100pct.wav", "question": "What facial expression most aligns with the emotion in the recording?", "choices": ["Relaxed facial muscles with a cheerful grin", "Tightly pressed lips with glaring eyes", "Averted gaze with a grimacing mouth", "Wide-open eyes with raised eyebrows and slightly parted lips."], "answer": "Relaxed facial muscles with a cheerful grin", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_17.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[133, 1263], [1909, 3944], [4053, 5356], [5363, 12268], [13429, 15742], [16166, 17208], [17489, 18922], [19054, 20083], [21098, 25911], [26525, 27466], [27916, 28756], [29241, 31760], [32973, 34602], [34658, 35467], [35684, 39151], [39339, 41532], [42110, 43230], [43482, 45908], [46416, 47331]], "num_segments": 19}
{"id": "sakura_emotion_18_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_18_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "sad", "happy", "angry"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_18.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1051, 1890], [2320, 3311], [3402, 10332], [10731, 12581], [12860, 14116], [14175, 19379], [19610, 23307], [23816, 24983], [26504, 31540], [32369, 37672], [38270, 40142], [40173, 41624]], "num_segments": 12}
{"id": "sakura_emotion_17_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_17_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["fear", "angry", "happy", "disgust"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_17.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[392, 5100], [5847, 10725], [11029, 11922], [12053, 13753], [14196, 15296], [15504, 23008], [23053, 23960], [25579, 32932], [33317, 34590], [35166, 36695], [37016, 39844], [39879, 41435], [41456, 44694], [44718, 46468], [46543, 48058]], "num_segments": 15}
{"id": "sakura_emotion_18_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_18_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Stay calm and provide support to ease their anxiety.", "Suggest spending some time together to cheer them up.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Suggest an activity to keep the positive energy flowing."], "answer": "Suggest an activity to keep the positive energy flowing.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_18.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1232, 2214], [2975, 4536], [4884, 5824], [6095, 8511], [8817, 15331], [15924, 17345], [17449, 19360], [21386, 23219], [23405, 25714], [25882, 26742], [27227, 28308], [28419, 29332], [29826, 34639], [35011, 37253], [38379, 40812]], "num_segments": 15}
{"id": "sakura_emotion_16_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_16_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Saying goodbye at an airport.", "Winning a long-anticipated award or prize.", "Throwing an object in frustration.", "Preparing for a high-stakes exam with anxiety."], "answer": "Saying goodbye at an airport.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_16.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[363, 1395], [2757, 9971], [10376, 12287], [13372, 17675], [18144, 20391], [21946, 26186], [26538, 28492], [28515, 32896], [34089, 37219], [39312, 41887], [42097, 45815], [45968, 47060], [47448, 49830], [50226, 51201], [51505, 52587], [52606, 55758], [56431, 57837], [58717, 59577]], "num_segments": 18}
{"id": "sakura_emotion_20_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_20_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "sad", "happy", "fear"], "answer": "angry", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_20.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[904, 6054], [6345, 11332], [11558, 14093], [14344, 15844], [15912, 18321], [19058, 19986], [20892, 21695], [21758, 25197], [25300, 26873], [27336, 34078], [35447, 38729], [38928, 40856], [41496, 44660], [45504, 47525], [48579, 53683]], "num_segments": 15}
{"id": "sakura_emotion_16_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_16_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "disgust", "sad", "happy"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_16.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[788, 1975], [2430, 4059], [4516, 5373], [6223, 13576], [14273, 18757], [18796, 20088], [20322, 24095], [25282, 26256], [26552, 30128], [30702, 33864], [34005, 35104], [35164, 42108], [43066, 45455], [46909, 47843], [48958, 56606], [56820, 57807]], "num_segments": 16}
{"id": "sakura_emotion_20_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_20_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I\u2019m really scared about what might happen next.", "I\u2019ve had enough of this nonsense.", "I don\u2019t know how to move on from this loss.", "I can\u2019t stop smiling, everything feels so right."], "answer": "I\u2019ve had enough of this nonsense.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_20.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[212, 1424], [1730, 4015], [4288, 8333], [8837, 16650], [17983, 18961], [19302, 21431], [22093, 23114], [23649, 24928], [25178, 27933], [28844, 32095], [32212, 33473], [33640, 35322], [35448, 36873], [37297, 38108], [38336, 43404], [44341, 50436], [50791, 51757], [51850, 52737], [53120, 55013]], "num_segments": 19}
{"id": "sakura_emotion_21_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_21_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "fear", "angry", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_21.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[482, 6251], [7190, 8475], [9636, 13593], [13678, 15149], [15578, 17704], [17978, 19594], [20021, 22734], [24324, 29682], [29810, 30764], [31130, 34509], [34527, 38466], [38601, 40036], [40198, 41811], [42317, 43428]], "num_segments": 14}
{"id": "sakura_emotion_24_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_24_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Watching a touching but sorrowful movie scene.", "Watching a horror movie alone in the dark.", "Celebrating a birthday with friends and family.", "Throwing an object in frustration."], "answer": "Watching a touching but sorrowful movie scene.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_24.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1535, 5338], [5395, 6351], [7531, 9611], [9757, 14916], [15025, 17651], [18531, 19683], [19881, 21325], [22021, 23131], [23888, 25043], [25797, 27302], [27404, 28722], [29184, 32577], [32827, 34310], [35297, 36434], [37240, 39931], [40410, 42149]], "num_segments": 16}
{"id": "sakura_emotion_21_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_21_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Smile and engage positively in the conversation.", "Offer reassurance and remind them they are safe.", "Offer a comforting hug or words of reassurance.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable."], "answer": "Smile and engage positively in the conversation.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_21.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[679, 2498], [2785, 3827], [3862, 11103], [11234, 12797], [13189, 14320], [14776, 16275], [17286, 19418], [19578, 22706], [23061, 24584], [24654, 26098], [27510, 34579], [34889, 36166], [36404, 42046], [42222, 43128]], "num_segments": 14}
{"id": "sakura_emotion_22_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_22_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Eyes crinkling with an open-mouthed laugh", "Squinted eyes and a pinched nose", "Wide-open eyes with raised eyebrows and slightly parted lips.", "Flared nostrils with a tense expression"], "answer": "Flared nostrils with a tense expression", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_22.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[858, 6293], [6893, 11405], [11793, 12777], [13057, 14044], [14468, 15797], [15916, 17065], [17327, 19117], [19677, 22589], [23649, 26761], [27174, 28251], [28934, 35836], [36513, 38213], [38941, 40335], [40394, 43697], [44019, 49922], [50059, 50881]], "num_segments": 16}
{"id": "sakura_emotion_24_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_24_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["disgust", "angry", "sad", "happy"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_24.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[314, 1194], [2089, 3053], [4323, 10624], [11717, 12978], [13560, 20423], [20671, 22193], [22771, 28313], [29089, 31092], [31248, 32219], [32707, 33727], [34116, 35313], [35387, 36245], [36247, 37373], [37532, 38878], [38924, 40481], [40975, 41978]], "num_segments": 16}
{"id": "sakura_emotion_22_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_22_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "sad", "angry", "fear"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_22.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[750, 6839], [7471, 9114], [9148, 10612], [11128, 14447], [15060, 15876], [16364, 18553], [19629, 20656], [21447, 22715], [23040, 29827], [29975, 35850], [36345, 42399], [42769, 45136], [45698, 50433]], "num_segments": 13}
{"id": "sakura_emotion_23_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_23_masked_100pct.wav", "question": "Considering the emotion expressed in the audio, which of the following facial expressions would align most closely with it?", "choices": ["Flared nostrils with a tense expression", "Head slightly pulled back with a terrified gaze, as if searching for an escape.", "Eyes gazing downward with trembling lips", "Averted gaze with a grimacing mouth"], "answer": "Flared nostrils with a tense expression", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_23.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[842, 7057], [7145, 8552], [8580, 10544], [11044, 12306], [12496, 13362], [14598, 15507], [15626, 16987], [17929, 19225], [20258, 25947], [27227, 35121], [35212, 37836], [38073, 39131]], "num_segments": 12}
{"id": "sakura_emotion_25_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_25_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["sad", "happy", "angry", "disgust"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_25.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[694, 2810], [2958, 4540], [5087, 6271], [7045, 11343], [12061, 13674], [14363, 18268], [19751, 24864], [25459, 27876], [27954, 29070], [29986, 32054], [32391, 34087], [34100, 38069]], "num_segments": 12}
{"id": "sakura_emotion_19_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_19_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "fear", "happy", "disgust"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_19.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1099, 1907], [1996, 5573], [6678, 12211], [12884, 13725], [13752, 15011], [15681, 19110], [19324, 21234], [21727, 24435], [24806, 26469], [27739, 33026], [34259, 39437], [39882, 41008], [41278, 44431], [45043, 49862], [50831, 53873], [53903, 55398], [56804, 57697], [57968, 60313]], "num_segments": 18}
{"id": "sakura_emotion_19_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_19_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Eyes crinkling with an open-mouthed laugh", "Wide-open eyes with raised eyebrows and slightly parted lips.", "Furrowed brows with slightly open mouth, as if about to shout.", "Averted gaze with a grimacing mouth"], "answer": "Wide-open eyes with raised eyebrows and slightly parted lips.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_19.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1296, 2511], [3284, 4362], [5079, 6234], [6464, 7600], [10506, 15468], [15478, 16886], [18086, 19301], [19717, 20712], [20950, 27224], [27294, 33403], [34413, 36089], [36169, 43250], [44603, 45848], [46160, 50821], [51891, 56007], [56535, 59386]], "num_segments": 16}
{"id": "sakura_emotion_23_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_23_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "sad", "angry", "happy"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_23.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[267, 5396], [5534, 7211], [7275, 8112], [8511, 12007], [12403, 15176], [16218, 19323], [19421, 20378], [21177, 24491], [25635, 28116], [28741, 33096], [35013, 35924], [36331, 38724]], "num_segments": 12}
{"id": "sakura_emotion_25_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_25_masked_100pct.wav", "question": "Which of the following sentences would most likely reflect the emotional state of people experiencing the same emotion as the speaker?", "choices": ["I\u2019m really scared about what might happen next.", "This thing looks absolutely gross and dirty; I can\u2019t stand it!", "Stop making excuses; this is entirely your fault!", "It\u2019s hard to imagine things ever getting better."], "answer": "It\u2019s hard to imagine things ever getting better.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_25.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[98, 1039], [1426, 2436], [3290, 4178], [5225, 9019], [9040, 9994], [10665, 14517], [14633, 16011], [16172, 16989], [18432, 22538], [23440, 24290], [24316, 25600], [25920, 27348], [27833, 28751], [28963, 35635], [36565, 37726]], "num_segments": 15}
{"id": "sakura_emotion_26_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_26_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["happy", "fear", "sad", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_26.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[415, 2402], [3858, 9359], [9760, 13665], [14245, 15832], [16069, 16938], [17020, 17915], [18042, 22070], [22553, 24629], [25586, 27334], [27866, 33256], [33428, 35444], [36923, 40271], [41139, 48607], [49025, 50389], [50658, 52715], [52899, 53774]], "num_segments": 16}
{"id": "sakura_emotion_28_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_28_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["fear", "happy", "sad", "disgust"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_28.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[102, 1188], [1697, 3635], [3842, 9412], [9738, 10804], [10993, 12715], [13880, 16370], [17415, 20088], [20287, 21127], [21712, 23148], [23954, 25071], [25815, 26731], [26828, 28137], [28812, 29871], [30892, 33210], [33505, 35906]], "num_segments": 15}
{"id": "sakura_emotion_26_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_26_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Raised eyebrows with a scowl", "Averted gaze with a grimacing mouth", "A heavy sigh with a frown and slumped posture", "A warm, genuine smile with slightly tilted head"], "answer": "Averted gaze with a grimacing mouth", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_26.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1038, 4369], [4523, 6735], [7656, 9590], [9633, 11268], [12103, 15325], [15430, 17115], [17462, 20462], [20600, 24411], [24681, 26166], [26283, 33806], [33996, 35257], [35301, 37344], [37683, 44903], [45669, 46598], [46992, 48544], [49452, 50491], [50950, 52779]], "num_segments": 17}
{"id": "sakura_emotion_28_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_28_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["I feel like I\u2019m in danger, and I don\u2019t know what to do.", "I don\u2019t know how to move on from this loss.", "It\u2019s so dirty! Please clean it as quick as possible.", "I can\u2019t believe this is happening, I\u2019m so furious!"], "answer": "I don\u2019t know how to move on from this loss.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_28.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[673, 1874], [2253, 6806], [7329, 10326], [11377, 12212], [13390, 15054], [15617, 18829], [19200, 20109], [21556, 27007], [28244, 29347], [29533, 31198], [31684, 35071], [35239, 36659]], "num_segments": 12}
{"id": "sakura_emotion_27_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_27_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Listen attentively without interrupting to let them vent.", "Stay calm and provide support to ease their anxiety.", "Smile and engage positively in the conversation.", "Offer a comforting hug or words of reassurance."], "answer": "Listen attentively without interrupting to let them vent.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_27.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[493, 1355], [1573, 4201], [5231, 7084], [7708, 14573], [15518, 16733], [18112, 20651], [20727, 22170], [22579, 23621], [23918, 25350], [26137, 27364], [29201, 32725], [33184, 40718], [41242, 42461], [42601, 44841], [45356, 46555]], "num_segments": 15}
{"id": "sakura_emotion_27_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_27_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "angry", "disgust", "fear"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_27.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[205, 7674], [8212, 9447], [10046, 12566], [12617, 16089], [16285, 17151], [17633, 20808], [21517, 24475], [25623, 26841], [27237, 28912], [29323, 30670], [30993, 38265], [38567, 40088], [40880, 41913], [42358, 43238], [43472, 45374], [45594, 46444]], "num_segments": 16}
{"id": "sakura_emotion_30_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_30_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "sad", "fear", "disgust"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_30.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[356, 2160], [2398, 4898], [4958, 7957], [8732, 13293], [13883, 19300], [19613, 22090], [22866, 23861], [24150, 25059], [25345, 26382], [27696, 28607], [29552, 33434], [34314, 37985]], "num_segments": 12}
{"id": "sakura_emotion_32_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_32_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "sad", "disgust", "happy"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_32.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[838, 2321], [3265, 4069], [4159, 4972], [6007, 12441], [13055, 13994], [14389, 16025], [16422, 22037], [22263, 23099], [23688, 26433], [26557, 28858], [28858, 32809]], "num_segments": 11}
{"id": "sakura_emotion_30_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_30_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Attending a close friend's funeral.", "A person smiling after receiving good news.", "Walking alone in a dark alley at night.", "Seeing an unpleasant image online."], "answer": "Attending a close friend's funeral.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_30.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1147, 4279], [5264, 10259], [11694, 14076], [15519, 16356], [16688, 20677], [21327, 22707], [23580, 25470], [25471, 33032], [33218, 35709], [35899, 37639]], "num_segments": 10}
{"id": "sakura_emotion_29_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_29_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Provide emotional support and avoid dismissing their sadness.", "Suggest an activity to keep the positive energy flowing.", "Avoid discussing further and respect their aversion to the topic.", "Give them space to cool off before engaging further."], "answer": "Avoid discussing further and respect their aversion to the topic.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_29.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1183, 3338], [4033, 5079], [6426, 10225], [11159, 17199], [18617, 26110], [26690, 33756], [34904, 36384], [37057, 39421], [39883, 42385], [42822, 48092], [48497, 49698], [49826, 50672]], "num_segments": 12}
{"id": "sakura_emotion_29_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_29_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["fear", "angry", "disgust", "happy"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_29.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[302, 1405], [1768, 5314], [5524, 7686], [8401, 9961], [10266, 11073], [12194, 14312], [14708, 20270], [21154, 22751], [22905, 25269], [26589, 27740], [27884, 32392], [33423, 37013], [37198, 40637], [41755, 43146], [44792, 46052], [46055, 49204], [49792, 50616]], "num_segments": 17}
{"id": "sakura_emotion_32_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_32_masked_100pct.wav", "question": "Based on the emotion identified in the audio, which of these facial expressions is most likely to match the speaker's emotional state?", "choices": ["Retracted chin with one corner of the mouth twitching, as if intolerable.", "Eyes crinkling with an open-mouthed laugh", "Wide-open eyes with raised eyebrows and slightly parted lips.", "A heavy sigh with a frown and slumped posture"], "answer": "Wide-open eyes with raised eyebrows and slightly parted lips.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_32.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[171, 1581], [1741, 9525], [9706, 10570], [11372, 17911], [18652, 25208], [26292, 29095], [30342, 31905], [31993, 33008]], "num_segments": 8}
{"id": "sakura_emotion_31_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_31_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["I can\u2019t stop smiling, everything feels so right.", "Stop making excuses; this is entirely your fault!", "I feel so empty, like nothing matters anymore.", "This is terrifying, I can\u2019t stop thinking about it."], "answer": "I can\u2019t stop smiling, everything feels so right.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_31.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[189, 1383], [1592, 5177], [5732, 7208], [7420, 8360], [9534, 12057], [12775, 19130], [19497, 27304], [27984, 29213], [29635, 34291], [34921, 36012], [36155, 38616]], "num_segments": 11}
{"id": "sakura_emotion_31_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_31_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "happy", "angry", "disgust"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_31.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[174, 1171], [1240, 2970], [3487, 4348], [4900, 9839], [10647, 14512], [14919, 15970], [16341, 18091], [18394, 19947], [20056, 21112], [21432, 23068], [23166, 24663], [24718, 26180], [27022, 28703], [30025, 30987], [31380, 33753], [35144, 38444]], "num_segments": 16}
{"id": "sakura_emotion_34_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_34_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "sad", "disgust", "happy"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_34.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[164, 1258], [1283, 2217], [2301, 3171], [4669, 5780], [6640, 8751], [9616, 14157], [15111, 21196], [21280, 23725], [23871, 30368], [30491, 31459], [31484, 33147], [33249, 38817]], "num_segments": 12}
{"id": "sakura_emotion_34_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_34_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["A person smiling after receiving good news.", "Attending a close friend's funeral.", "Facing an aggressive dog on the street.", "A person yelling after being cut off in traffic."], "answer": "Attending a close friend's funeral.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_34.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[47, 934], [1431, 2339], [2896, 4294], [4594, 5522], [6293, 7792], [8558, 11510], [11635, 15584], [16650, 17502], [17807, 22744], [24441, 26025], [26059, 27328], [28204, 30922], [31858, 38120]], "num_segments": 13}
{"id": "sakura_emotion_35_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_35_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I can\u2019t stop smiling, everything feels so right.", "I\u2019ve had enough of this nonsense.", "I just can\u2019t stop thinking about all those bad memories.", "I can\u2019t shake the feeling that something bad is coming."], "answer": "I just can\u2019t stop thinking about all those bad memories.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_35.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1167, 2129], [2509, 3423], [4851, 6051], [6055, 6895], [7201, 8064], [8175, 9250], [9864, 15812], [16003, 18231], [18342, 19699], [20618, 22142], [22362, 24441], [24709, 26243], [26294, 34075], [34270, 35369], [36616, 37741]], "num_segments": 15}
{"id": "sakura_emotion_35_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_35_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "angry", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_35.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[708, 2631], [3866, 5627], [5745, 6739], [6978, 8159], [9027, 10305], [10979, 14299], [15064, 16215], [16243, 17721], [17789, 18879], [19563, 26984], [28307, 29578], [29676, 34709], [35300, 36390], [37408, 38519]], "num_segments": 14}
{"id": "sakura_emotion_37_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_37_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "happy", "sad", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_37.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[410, 1379], [2096, 3767], [3994, 9144], [9690, 15348], [17332, 21420], [22860, 24203], [24752, 26147], [26192, 32110], [32958, 33969], [34185, 35403], [35600, 39540], [40064, 41642], [41651, 44618], [44869, 46026]], "num_segments": 14}
{"id": "sakura_emotion_37_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_37_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Seeing an unpleasant image online.", "Watching a horror movie alone in the dark.", "Attending a close friend's funeral.", "Laughing at a funny joke in a conversation."], "answer": "Seeing an unpleasant image online.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_37.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[494, 5402], [6686, 8476], [9259, 15874], [17137, 21366], [21913, 25073], [25193, 31052], [31106, 36874], [37132, 40249], [40763, 46303]], "num_segments": 9}
{"id": "sakura_emotion_39_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_39_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["happy", "disgust", "angry", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_39.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[351, 1762], [2260, 6929], [8214, 10102], [10753, 11876], [12025, 18195], [19235, 22508], [23407, 27585], [27689, 29499], [29782, 32422]], "num_segments": 9}
{"id": "sakura_emotion_38_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_38_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "disgust", "fear", "happy"], "answer": "angry", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_38.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[605, 2030], [2338, 4934], [5141, 6319], [6508, 7512], [8483, 10404], [10597, 12453], [13349, 15595], [15795, 18035], [18699, 19615], [19863, 24687], [25640, 33323], [33550, 34936], [35229, 36379], [36387, 39668], [39837, 42126]], "num_segments": 15}
{"id": "sakura_emotion_39_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_39_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Suggest an activity to keep the positive energy flowing.", "Offer reassurance and remind them they are safe.", "Give them space to cool off before engaging further.", "Avoid discussing further and respect their aversion to the topic."], "answer": "Offer reassurance and remind them they are safe.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_39.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[16, 2206], [2517, 3522], [3824, 5510], [5601, 8825], [8891, 11203], [12061, 14445], [14563, 15511], [15514, 17024], [18275, 19147], [19238, 27056], [27546, 28629], [28648, 31441], [32071, 33507]], "num_segments": 13}
{"id": "sakura_emotion_40_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_40_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["This situation is really starting to piss me off!", "I\u2019m just so happy I could burst!", "I feel so empty, like nothing matters anymore.", "I feel like I\u2019m in danger, and I don\u2019t know what to do."], "answer": "This situation is really starting to piss me off!", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_40.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[651, 1840], [1840, 3086], [3194, 6024], [6307, 7519], [8694, 13192], [14082, 15375], [16087, 20135], [20444, 23670], [23952, 28128], [29966, 31133], [31334, 32347], [32390, 34384], [34598, 38127], [38576, 39830], [39896, 42864], [42988, 45469]], "num_segments": 16}
{"id": "sakura_emotion_40_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_40_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "disgust", "angry", "fear"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_40.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[431, 2330], [2548, 3518], [3630, 5149], [6378, 7555], [7773, 9315], [9629, 11699], [13652, 14557], [14929, 17493], [17812, 24898], [24961, 25776], [26190, 27925], [28264, 32641], [33570, 35543], [36313, 39633], [40927, 41940], [43179, 44222], [44334, 45912]], "num_segments": 17}
{"id": "sakura_emotion_38_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_38_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Reacting to a foul odor in a room.", "Preparing for a high-stakes exam with anxiety.", "Reading a heartfelt goodbye letter.", "Slamming a door after a disagreement."], "answer": "Slamming a door after a disagreement.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_38.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1868, 3367], [3496, 5077], [5238, 9950], [11005, 12114], [12118, 13116], [13802, 15293], [15674, 19684], [20026, 25591], [26515, 28591], [29102, 34971], [36809, 40514], [41040, 41973]], "num_segments": 12}
{"id": "sakura_emotion_42_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_42_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Averted gaze with a grimacing mouth", "Wrinkled forehead and a forlorn expression", "Clenched teeth with side facial muscles showing tension.", "A radiant expression with raised cheeks"], "answer": "Wrinkled forehead and a forlorn expression", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_42.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[788, 2285], [2954, 3828], [4039, 5243], [5423, 9697], [10686, 18308], [19371, 21314], [22199, 23596], [23753, 27935], [28560, 29860], [30318, 32773], [32923, 33880]], "num_segments": 11}
{"id": "sakura_emotion_42_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_42_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "happy", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_42.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[673, 8510], [9044, 10166], [10580, 11752], [12059, 13091], [13890, 17584], [17632, 18669], [20004, 23776], [24595, 31054], [31594, 33853]], "num_segments": 9}
{"id": "sakura_emotion_33_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_33_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Rejecting a tasteless meal with a grimace.", "A person smiling after receiving good news.", "Reacting to a sudden loud noise in an empty house.", "Throwing an object in frustration."], "answer": "Throwing an object in frustration.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_33.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[285, 6414], [7704, 9695], [9971, 10905], [11236, 13333], [13804, 15340], [15718, 16766], [16939, 18286], [18860, 19746], [19901, 21310], [21525, 22995], [24061, 31768], [31886, 34068], [35289, 37030], [37696, 43743], [45298, 46233]], "num_segments": 15}
{"id": "sakura_emotion_33_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_33_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "disgust", "happy", "sad"], "answer": "angry", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_33.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[439, 8025], [8227, 9565], [10479, 17385], [17839, 22555], [23327, 29119], [29839, 31152], [31255, 32331], [33069, 34365], [34475, 40275], [41192, 45715]], "num_segments": 10}
{"id": "sakura_emotion_41_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_41_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Stay calm and provide support to ease their anxiety.", "Suggest spending some time together to cheer them up.", "Avoid discussing further and respect their aversion to the topic.", "Give them space to cool off before engaging further."], "answer": "Avoid discussing further and respect their aversion to the topic.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_41.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[67, 1743], [1854, 2810], [5559, 13300], [13699, 15630], [16031, 17377], [17542, 23192], [24425, 27636], [28709, 31571], [32734, 33920], [35131, 41249], [41859, 49265], [49880, 50707]], "num_segments": 12}
{"id": "sakura_emotion_41_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_41_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["sad", "fear", "happy", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_41.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[13, 1565], [1616, 7769], [7879, 15133], [15563, 16580], [17080, 18688], [19275, 23838], [24378, 30973], [31067, 32017], [32675, 34135], [35127, 39629], [40034, 47286], [47817, 49807], [49867, 52251]], "num_segments": 13}
{"id": "sakura_emotion_36_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_36_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Reacting to a sudden loud noise in an empty house.", "A parent scolding their child for misbehavior.", "Seeing an unpleasant image online.", "A person smiling after receiving good news."], "answer": "A parent scolding their child for misbehavior.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_36.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[283, 1418], [1471, 3351], [3440, 4858], [5019, 7783], [9251, 10378], [10835, 12267], [12423, 15872], [15983, 17032], [17828, 18841], [19125, 20218], [20499, 21561], [21789, 23897], [24128, 25081], [25157, 27499], [28054, 29646], [30030, 33886], [34558, 35673], [36722, 38774], [39923, 40874], [41017, 41851], [42263, 43543]], "num_segments": 21}
{"id": "sakura_emotion_36_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_36_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "disgust", "angry", "sad"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_36.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1635, 4401], [5011, 9457], [9851, 11011], [11736, 13348], [13457, 16065], [16237, 17606], [17709, 23454], [24701, 28547], [29688, 31785], [32880, 33770], [34298, 35552], [36589, 39180], [39453, 41322], [42051, 43313]], "num_segments": 14}
{"id": "sakura_emotion_43_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_43_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["sad", "fear", "happy", "disgust"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_43.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[421, 1448], [1730, 3952], [4572, 10563], [11782, 12970], [13581, 16522], [16694, 19633], [19724, 26887], [26973, 28684]], "num_segments": 8}
{"id": "sakura_emotion_43_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_43_masked_100pct.wav", "question": "Which of the following sentences would most likely reflect the emotional state of people experiencing the same emotion as the speaker?", "choices": ["I\u2019m really scared about what might happen next.", "I feel so empty, like nothing matters anymore.", "That\u2019s just revolting, I can\u2019t believe it.", "I\u2019m just so happy I could burst!"], "answer": "I\u2019m just so happy I could burst!", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_43.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[553, 1391], [1979, 9040], [9205, 10029], [10178, 11962], [13140, 16141], [16497, 17457], [17609, 19347], [20612, 26291], [27513, 28765]], "num_segments": 9}
{"id": "sakura_emotion_44_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_44_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["sad", "happy", "angry", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_44.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[418, 2543], [2706, 3603], [4215, 6701], [7196, 8442], [8829, 9982], [10224, 17738], [17820, 22272], [22275, 23681], [24554, 30261], [32123, 33002], [33705, 35357], [35654, 37187], [37263, 39762], [40024, 41070], [41160, 42340], [42530, 44488], [45475, 46292]], "num_segments": 17}
{"id": "sakura_emotion_46_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_46_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["fear", "happy", "angry", "disgust"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_46.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[138, 1273], [1394, 2724], [2890, 10867], [11540, 14357], [14587, 15612], [15763, 18539], [19860, 21104], [21844, 27672], [28404, 29384], [29883, 31078], [31632, 32703], [32754, 38328], [39236, 40326]], "num_segments": 13}
{"id": "sakura_emotion_44_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_44_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["Eyes gazing downward with trembling lips", "Squinted eyes and a pinched nose", "Tightly pressed lips with glaring eyes", "Wide-open eyes with raised eyebrows and slightly parted lips."], "answer": "Wide-open eyes with raised eyebrows and slightly parted lips.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_44.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[831, 5577], [5687, 9918], [10227, 12699], [13055, 13927], [15299, 17574], [17919, 21289], [21518, 23329], [23348, 31276], [32169, 33539], [33636, 39497], [40086, 40911], [42025, 44363], [45055, 46279]], "num_segments": 13}
{"id": "sakura_emotion_47_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_47_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Saying goodbye at an airport.", "Laughing at a funny joke in a conversation.", "A person yelling after being cut off in traffic.", "Turning away from spoiled food."], "answer": "Turning away from spoiled food.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_47.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[534, 3043], [3073, 4668], [5030, 7261], [8730, 10523], [12099, 13391], [13912, 15558], [16014, 23375], [23469, 26066], [26103, 31852], [33172, 36813], [36854, 40178]], "num_segments": 11}
{"id": "sakura_emotion_47_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_47_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "disgust", "fear", "sad"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_47.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[288, 1760], [2077, 4919], [6639, 10050], [10558, 11601], [12971, 14239], [14341, 15234], [15344, 18050], [18160, 19701], [20140, 21122], [21128, 25478], [25823, 27291], [27962, 31521], [32281, 33401], [33881, 34896], [35237, 40307]], "num_segments": 15}
{"id": "sakura_emotion_45_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_45_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Saying goodbye at an airport.", "Turning away from spoiled food.", "Preparing for a high-stakes exam with anxiety.", "A person smiling after receiving good news."], "answer": "Preparing for a high-stakes exam with anxiety.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_45.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[162, 1323], [1576, 3312], [3559, 4540], [4582, 5742], [6620, 7644], [7833, 15783], [16256, 18149], [19049, 21165], [21441, 23953], [24612, 26042], [27256, 32567], [33674, 39132], [39949, 41701], [41727, 43236]], "num_segments": 14}
{"id": "sakura_emotion_45_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_45_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "happy", "fear", "angry"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_45.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[367, 1501], [1723, 3003], [3878, 8530], [8852, 14740], [15565, 17996], [19629, 26309], [26409, 27324], [28106, 29118], [30669, 31602], [32750, 34347], [34409, 37182], [38026, 40293], [41219, 42368]], "num_segments": 13}
{"id": "sakura_emotion_46_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_46_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Laughing at a funny joke in a conversation.", "Reacting to a sudden loud noise in an empty house.", "Throwing an object in frustration.", "Reading a heartfelt goodbye letter."], "answer": "Throwing an object in frustration.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_46.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[405, 1499], [2399, 7018], [7265, 9150], [10449, 13284], [13297, 18635], [18819, 20101], [20938, 25329], [26585, 27547], [27794, 29511], [29621, 33402], [33448, 37697], [38826, 39909]], "num_segments": 12}
{"id": "sakura_emotion_50_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_50_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "fear", "angry", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_50.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[920, 3146], [4234, 7324], [8684, 11329], [11817, 13039], [13045, 18185], [18543, 21143], [21616, 29397], [30141, 32166], [32560, 34105], [34379, 35782], [36056, 37108], [37282, 38132]], "num_segments": 12}
{"id": "sakura_emotion_49_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_49_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["fear", "angry", "disgust", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_49.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[164, 1097], [1745, 6059], [6468, 8983], [9174, 12792], [12797, 15393], [15791, 20758], [21203, 22106], [22198, 25058], [25110, 27126], [27774, 29802]], "num_segments": 10}
{"id": "sakura_emotion_48_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_48_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "disgust", "angry", "happy"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_48.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[50, 5529], [7272, 10783], [11402, 16740], [17916, 21434], [22393, 30331], [30993, 33274], [33632, 34496]], "num_segments": 7}
{"id": "sakura_emotion_49_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_49_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["A person smiling after receiving good news.", "Seeing an unpleasant image online.", "A heated argument between colleagues.", "Reading a heartfelt goodbye letter."], "answer": "A person smiling after receiving good news.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_49.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1569, 5409], [5988, 6942], [6967, 9137], [9628, 14571], [14984, 19518], [20221, 25120], [25797, 29810]], "num_segments": 7}
{"id": "sakura_emotion_51_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_51_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "fear", "happy", "sad"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_51.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[105, 2161], [2185, 8119], [9623, 16053], [16467, 17595], [18271, 21366], [21367, 22883], [23066, 25010], [25097, 26175], [26253, 29703], [30804, 35922]], "num_segments": 10}
{"id": "sakura_emotion_51_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_51_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["I feel so grateful and full of joy right now.", "I just can\u2019t stop thinking about all those bad memories.", "That\u2019s just revolting, I can\u2019t believe it.", "I can\u2019t shake the feeling that something bad is coming."], "answer": "I can\u2019t shake the feeling that something bad is coming.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_51.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[233, 2236], [2656, 3793], [4170, 12011], [12993, 14232], [15234, 16680], [17298, 24269], [25343, 27454], [28278, 31449], [32665, 34163], [34300, 36304]], "num_segments": 10}
{"id": "sakura_emotion_52_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_52_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Hugging a loved one after a long separation.", "A person crying after a breakup.", "Watching a horror movie alone in the dark.", "Hearing a shocking and offensive statement."], "answer": "A person crying after a breakup.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_52.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[664, 5578], [5958, 6891], [8129, 9062], [9381, 15764], [16670, 19897], [20896, 22101], [23321, 27636], [27997, 30052], [30437, 36124]], "num_segments": 9}
{"id": "sakura_emotion_50_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_50_masked_100pct.wav", "question": "Which of the following sentences would most likely reflect the emotional state of people experiencing the same emotion as the speaker?", "choices": ["This thing looks absolutely gross and dirty; I can\u2019t stand it!", "Stop making excuses; this is entirely your fault!", "I\u2019m really scared about what might happen next.", "I feel so empty, like nothing matters anymore."], "answer": "I feel so empty, like nothing matters anymore.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_50.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1221, 2334], [2887, 8099], [9606, 10736], [10811, 12231], [12613, 19532], [20246, 25466], [26498, 28096], [28637, 33336], [34337, 35287], [35668, 38004]], "num_segments": 10}
{"id": "sakura_emotion_52_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_52_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "happy", "disgust", "angry"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_52.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1400, 2420], [4619, 12113], [12518, 13807], [13861, 14809], [15359, 23110], [23324, 24778], [26622, 32271], [32678, 36872]], "num_segments": 8}
{"id": "sakura_emotion_48_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_48_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Turning away from spoiled food.", "Laughing at a funny joke in a conversation.", "Watching a touching but sorrowful movie scene.", "Watching a horror movie alone in the dark."], "answer": "Turning away from spoiled food.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_48.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[283, 4735], [5553, 6671], [7306, 8481], [8734, 10450], [10547, 11354], [11479, 17653], [18158, 24626], [26010, 33554]], "num_segments": 8}
{"id": "sakura_emotion_54_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_54_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I\u2019m feeling so down, like nothing can lift my spirits.", "I feel like I\u2019m in danger, and I don\u2019t know what to do.", "This is the best day ever, I feel on top of the world!", "This makes me feel sick to my stomach."], "answer": "I\u2019m feeling so down, like nothing can lift my spirits.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_54.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[357, 5662], [7004, 9115], [9689, 10629], [11488, 15318], [15452, 16325], [16375, 18409], [18866, 24716], [24776, 30228], [30485, 32740]], "num_segments": 9}
{"id": "sakura_emotion_54_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_54_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "angry", "sad", "fear"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_54.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[40, 4356], [5959, 7779], [7842, 12537], [12731, 14228], [14271, 19068], [19665, 21908], [22100, 24611], [25868, 32328]], "num_segments": 8}
{"id": "sakura_emotion_53_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_53_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Avoid discussing further and respect their aversion to the topic.", "Calmly acknowledge their frustration and suggest a solution.", "Offer a comforting hug or words of reassurance.", "Suggest an activity to keep the positive energy flowing."], "answer": "Avoid discussing further and respect their aversion to the topic.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_53.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1574, 5875], [6372, 14037], [14329, 15507], [15708, 16534], [17010, 18498], [19120, 21951], [23609, 26107], [26636, 30418], [31063, 32019], [32414, 38041], [38433, 40345], [41114, 42039]], "num_segments": 12}
{"id": "sakura_emotion_55_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_55_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["sad", "disgust", "fear", "angry"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_55.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[636, 2033], [2723, 3561], [3725, 5611], [5736, 6836], [8213, 9051], [10079, 11526], [12897, 14480], [14490, 15855], [16050, 20194], [20561, 26589], [26826, 27739], [27811, 28938], [28961, 30600], [31139, 35272], [35536, 36901], [37107, 41284], [42199, 46871], [46957, 51576], [51593, 52744], [53010, 53964], [55263, 56377], [56459, 57393]], "num_segments": 22}
{"id": "sakura_emotion_53_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_53_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["disgust", "angry", "fear", "happy"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_53.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1124, 2475], [2538, 6227], [6664, 9668], [10834, 13145], [13567, 16055], [16542, 19124], [20163, 21396], [22597, 29737], [30051, 34114], [34496, 38095], [38422, 39775], [40329, 41728]], "num_segments": 12}
{"id": "sakura_emotion_55_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_55_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Express genuine excitement for their good news or achievement.", "Offer a comforting hug or words of reassurance.", "Reassure them and offer a way to move past the uncomfortable    situation.", "Encourage them to take deep breaths to relax."], "answer": "Offer a comforting hug or words of reassurance.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_55.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1445, 4773], [5071, 12402], [12939, 14672], [14856, 16854], [17106, 20754], [21755, 23993], [24673, 30721], [31815, 32786], [33670, 41307], [42021, 44380], [45190, 47525], [47528, 49488], [50643, 57331]], "num_segments": 13}
{"id": "sakura_emotion_56_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_56_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "sad", "angry", "fear"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_56.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[5, 1810], [3025, 10872], [11116, 14193], [14930, 18137], [18214, 19550], [19595, 20824], [20935, 22125], [22791, 26902], [27429, 29407], [29427, 31734], [32935, 36196]], "num_segments": 11}
{"id": "sakura_emotion_57_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_57_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["This makes me feel sick to my stomach.", "I just can\u2019t stop thinking about all those bad memories.", "This is terrifying, I can\u2019t stop thinking about it.", "I\u2019m just so happy I could burst!"], "answer": "I just can\u2019t stop thinking about all those bad memories.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_57.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[329, 1202], [1482, 6030], [6785, 10345], [11200, 14551], [15871, 16997], [17348, 19979], [21568, 23445], [23860, 25368], [25408, 26229], [26265, 30705], [30946, 32615], [33821, 35413], [35955, 41089], [41230, 42626], [42808, 45423], [45699, 47597], [47721, 48981], [49073, 54726]], "num_segments": 18}
{"id": "sakura_emotion_57_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_57_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "fear", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_57.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1014, 5352], [5895, 7548], [7556, 8572], [9270, 10302], [10358, 15285], [15966, 16823], [17645, 23284], [24213, 26064], [26353, 34238], [34386, 35564], [36252, 40866], [41075, 43008], [43484, 44383], [44636, 45787], [46086, 47081], [47527, 49927], [50361, 54167], [54267, 55468]], "num_segments": 18}
{"id": "sakura_emotion_56_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_56_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["A person yelling after being cut off in traffic.", "Walking alone in a dark alley at night.", "A person smiling after receiving good news.", "Attending a close friend's funeral."], "answer": "A person smiling after receiving good news.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_56.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[113, 3659], [3828, 5450], [5554, 7493], [7691, 9144], [9431, 16401], [16793, 17963], [17970, 18836], [18841, 19855], [20125, 25237], [26905, 29853], [30119, 31442], [31939, 35085], [35147, 36261]], "num_segments": 13}
{"id": "sakura_emotion_60_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_60_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "fear", "angry", "happy"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_60.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[412, 1301], [1400, 2333], [3669, 4792], [4862, 6206], [6695, 12305], [12672, 18780], [19872, 23680], [24398, 25795], [26360, 30804], [31988, 32954], [33068, 38910], [40225, 41321], [41483, 48994], [50615, 51861]], "num_segments": 14}
{"id": "sakura_emotion_59_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_59_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "fear", "disgust", "happy"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_59.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[871, 2510], [2669, 3771], [4951, 8339], [8340, 9239], [10010, 11177], [11375, 17586], [18357, 19598], [20141, 21009], [21361, 23350], [24004, 25540], [25642, 26540], [26813, 27673], [27894, 29033], [30135, 35985], [36368, 37233], [37289, 39911], [40628, 41502], [42015, 45957], [46440, 51506], [51512, 52453], [54028, 60722], [60848, 64571]], "num_segments": 22}
{"id": "sakura_emotion_61_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_61_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "happy", "sad", "angry"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_61.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[341, 1415], [2679, 3515], [4526, 7191], [8379, 13063], [13276, 15439], [15508, 18395], [18886, 19883], [20465, 21708], [23347, 24244], [24763, 26624], [26720, 33713], [34208, 35069], [36036, 38456], [38489, 43614], [43972, 44903], [45300, 46805], [46950, 48545], [48909, 53658], [53690, 54492]], "num_segments": 19}
{"id": "sakura_emotion_59_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_59_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Hold their hand or offer some physical reassurance.", "Give them space to cool off before engaging further.", "Express understanding calmly and suggest leaving the unpleasant environment.", "Offer a comforting hug or words of reassurance."], "answer": "Hold their hand or offer some physical reassurance.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_59.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1440, 2392], [4010, 9866], [10228, 16964], [18001, 19679], [19701, 25090], [25889, 27097], [27660, 31320], [31320, 34072], [35136, 37540], [37552, 40907], [41255, 42069], [42185, 43386], [44404, 47452], [48474, 55202], [55782, 56697], [57575, 62723], [63320, 64318], [64477, 65473]], "num_segments": 18}
{"id": "sakura_emotion_61_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_61_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Give them space to cool off before engaging further.", "Offer a comforting hug or words of reassurance.", "Celebrate their joy with a cheerful response.", "Offer reassurance and remind them they are safe."], "answer": "Offer reassurance and remind them they are safe.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_61.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[120, 1254], [1312, 3345], [4616, 6456], [6698, 9048], [10006, 15491], [16621, 20758], [21492, 27824], [28643, 30322], [30826, 33036], [33089, 38529], [38713, 39710], [40878, 42433], [43655, 44911], [46154, 49498], [50148, 53963]], "num_segments": 15}
{"id": "sakura_emotion_58_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_58_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Smile and engage positively in the conversation.", "Hold their hand or offer some physical reassurance.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Offer a comforting hug or words of reassurance."], "answer": "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_58.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[793, 1769], [1787, 6979], [7449, 8979], [9340, 11489], [11979, 14872], [15131, 22773], [23974, 28558], [29449, 30525], [30752, 32901], [33452, 37616], [39642, 40995], [41426, 43113], [43516, 48342], [49784, 50903]], "num_segments": 14}
{"id": "sakura_emotion_60_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_60_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["This is the best day ever, I feel on top of the world!", "I can\u2019t believe this is happening, I\u2019m so furious!", "This makes me feel sick to my stomach.", "I\u2019m really scared about what might happen next."], "answer": "I can\u2019t believe this is happening, I\u2019m so furious!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_60.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[93, 5319], [6668, 7969], [7993, 10964], [12354, 14113], [14330, 20389], [20446, 22864], [23110, 25118], [25446, 26599], [26911, 28260], [28338, 30921], [31165, 32338], [32664, 35149], [35185, 38392], [38417, 39327], [40010, 43538], [43721, 44685], [44709, 46686], [47226, 52521]], "num_segments": 18}
{"id": "sakura_emotion_58_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_58_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "happy", "fear", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_58.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[644, 7183], [8200, 10598], [11220, 13964], [14227, 21335], [21658, 28503], [29490, 30826], [32168, 33391], [33749, 39484], [39921, 40760], [41164, 48462], [48795, 50519]], "num_segments": 11}
{"id": "sakura_emotion_64_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_64_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "angry", "fear", "happy"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_64.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[57, 1780], [1944, 3057], [3110, 4544], [5144, 6011], [6190, 7375], [7655, 9010], [9120, 10500], [10543, 11603], [11797, 12974], [13325, 15647], [16037, 20407], [21013, 26229], [27829, 28849], [30282, 36350], [37071, 38712], [39117, 42357], [43142, 43949]], "num_segments": 17}
{"id": "sakura_emotion_65_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_65_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Downturned mouth and teary eyes", "Wide-open eyes with raised eyebrows and slightly parted lips.", "A warm, genuine smile with slightly tilted head", "Tightly pressed lips with glaring eyes"], "answer": "A warm, genuine smile with slightly tilted head", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_65.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[315, 1126], [1134, 3238], [3441, 5051], [5888, 9770], [10884, 12465], [13184, 14434], [14761, 16278], [16777, 17828], [18156, 19114], [19253, 23161], [23375, 25404], [25918, 27470], [28059, 30441], [30842, 32107], [32625, 34469], [35574, 39044], [39693, 43136], [44729, 46168], [46258, 47650], [48575, 52013], [52405, 53524], [53601, 54418]], "num_segments": 22}
{"id": "sakura_emotion_66_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_66_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["sad", "happy", "disgust", "fear"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_66.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[69, 2047], [2403, 3209], [3583, 4554], [4709, 5564], [5930, 10728], [10780, 12266], [13213, 16708], [16870, 22345], [23726, 25200], [25270, 26732], [26903, 28344]], "num_segments": 11}
{"id": "sakura_emotion_66_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_66_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Saying goodbye at an airport.", "Rejecting a tasteless meal with a grimace.", "A heated argument between colleagues.", "Celebrating a birthday with friends and family."], "answer": "Saying goodbye at an airport.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_66.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1115, 2696], [2717, 6462], [6556, 10836], [11182, 12471], [12761, 13770], [14502, 15536], [15702, 17107], [18376, 23506], [24426, 25288], [25751, 26807], [26918, 28437]], "num_segments": 11}
{"id": "sakura_emotion_65_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_65_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "fear", "disgust", "sad"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_65.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[46, 1010], [1463, 5488], [6132, 13131], [13695, 14571], [14725, 16973], [18600, 26375], [27432, 29794], [30895, 37745], [39331, 42479], [42556, 45425], [46421, 52462], [53413, 54362]], "num_segments": 12}
{"id": "sakura_emotion_63_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_63_masked_100pct.wav", "question": "Based on the emotion identified in the audio, which of these facial expressions is most likely to match the speaker's emotional state?", "choices": ["Squinted eyes and a pinched nose", "Eyes gazing downward with trembling lips", "Eyes crinkling with an open-mouthed laugh", "Tightly furrowed brow with trembling lips"], "answer": "Tightly furrowed brow with trembling lips", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_63.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[706, 8698], [8842, 10033], [11092, 13485], [15211, 19981], [20368, 21945], [22120, 25795], [26830, 30551], [31686, 33076], [34379, 41538], [41543, 42617], [43170, 45659], [45905, 46706], [46889, 47883]], "num_segments": 13}
{"id": "sakura_emotion_67_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_67_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "sad", "happy", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_67.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[885, 3001], [3226, 4527], [4759, 8115], [8145, 12737], [13147, 17278], [17345, 20455], [21426, 22314], [23056, 25531], [25892, 30744], [31077, 32091], [32212, 34716], [35709, 36547], [36841, 37784]], "num_segments": 13}
{"id": "sakura_emotion_63_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_63_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "disgust", "sad", "angry"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_63.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[393, 3648], [4832, 9501], [11610, 19133], [19669, 20472], [20694, 28398], [28732, 29665], [30739, 36593], [37094, 38191], [38941, 41906], [42607, 47794]], "num_segments": 10}
{"id": "sakura_emotion_68_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_68_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["happy", "sad", "fear", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_68.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[83, 2023], [2025, 6019], [6121, 7231], [7533, 11513], [11577, 14695], [15092, 20444], [21473, 22610], [22889, 29384], [29815, 30946], [31425, 35324], [35952, 37517], [37598, 38630], [39501, 44589]], "num_segments": 13}
{"id": "sakura_emotion_67_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_67_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Tightly pressed lips with glaring eyes", "Wrinkled forehead and a forlorn expression", "Averted gaze with a grimacing mouth", "Relaxed facial muscles with a cheerful grin"], "answer": "Averted gaze with a grimacing mouth", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_67.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[466, 7290], [7995, 9422], [10014, 11920], [12323, 15022], [16652, 18424], [18599, 21172], [21927, 22878], [23230, 24110], [25180, 32610], [32993, 35660], [36284, 37172]], "num_segments": 11}
{"id": "sakura_emotion_69_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_69_masked_100pct.wav", "question": "From the provided sentences, which one best matches the emotional state of individuals who are experiencing the same emotion as the speaker?", "choices": ["I don\u2019t know how to move on from this loss.", "I can\u2019t stop smiling, everything feels so right.", "It\u2019s so dirty! Please clean it as quick as possible.", "How dare they treat me so unfairly like this!"], "answer": "It\u2019s so dirty! Please clean it as quick as possible.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_69.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[59, 2298], [2610, 3560], [3590, 7533], [8857, 14587], [15711, 17226], [18275, 19519], [19959, 20767], [20815, 23620], [23822, 25580], [26037, 27091], [27397, 28334]], "num_segments": 11}
{"id": "sakura_emotion_68_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_68_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["I\u2019m so excited, I just can\u2019t contain my happiness!", "It\u2019s hard to imagine things ever getting better.", "I feel like I\u2019m in danger, and I don\u2019t know what to do.", "Stop making excuses; this is entirely your fault!"], "answer": "Stop making excuses; this is entirely your fault!", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_68.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[18, 2575], [2802, 3734], [4350, 5352], [5658, 7035], [7300, 14150], [14153, 15545], [15861, 20107], [21069, 22050], [22876, 23816], [24648, 31315], [31516, 32498], [33348, 34239], [35698, 37238], [37246, 43598]], "num_segments": 14}
{"id": "sakura_emotion_70_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_70_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "angry", "fear", "sad"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_70.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2135, 3936], [5087, 8388], [8951, 10746], [10824, 12006], [12083, 12890], [13660, 14739], [14981, 18326], [18421, 19708], [19960, 22096], [22636, 26529], [27218, 29830], [30072, 33093], [33107, 33917], [34520, 37096], [37738, 39421]], "num_segments": 15}
{"id": "sakura_emotion_69_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_69_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "happy", "fear", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_69.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[689, 1519], [1527, 6105], [6110, 10290], [11456, 14793], [15141, 16304], [16578, 17672], [18076, 24136], [24156, 25854], [26225, 29096]], "num_segments": 9}
{"id": "sakura_emotion_62_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_62_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "disgust", "angry", "sad"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_62.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[668, 4633], [4982, 6290], [7022, 12599], [12774, 17566], [18687, 23165], [23514, 27101], [27332, 33129], [33190, 34765], [34928, 36581], [38073, 44767]], "num_segments": 10}
{"id": "sakura_emotion_70_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_70_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Smile and engage positively in the conversation.", "Listen empathetically and let them express their feelings.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Encourage them to take deep breaths to relax."], "answer": "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_70.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[536, 2202], [2612, 4841], [4995, 6088], [6781, 7745], [9113, 11660], [11796, 14558], [15326, 18142], [18161, 19062], [19837, 21914], [22562, 25406], [26815, 28499], [29040, 34221], [35254, 37906], [39481, 40484]], "num_segments": 14}
{"id": "sakura_emotion_64_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_64_masked_100pct.wav", "question": "From the provided sentences, which one best matches the emotional state of individuals who are experiencing the same emotion as the speaker?", "choices": ["I\u2019m so excited, I just can\u2019t contain my happiness!", "How dare they treat me so unfairly like this!", "This is terrifying, I can\u2019t stop thinking about it.", "I feel so empty, like nothing matters anymore."], "answer": "This is terrifying, I can\u2019t stop thinking about it.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_64.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[170, 1412], [1959, 6191], [6483, 7617], [7840, 8885], [9461, 10776], [12770, 18726], [19795, 20944], [21768, 24016], [24642, 28276], [29184, 30280], [30361, 37916], [38495, 39815], [39852, 42174], [42506, 44718]], "num_segments": 14}
{"id": "sakura_emotion_62_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_62_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["It\u2019s hard to imagine things ever getting better.", "I can\u2019t stop smiling, everything feels so right.", "This situation is really starting to piss me off!", "I can\u2019t even look at this without feeling uncomfortable."], "answer": "This situation is really starting to piss me off!", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_62.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[495, 5867], [6196, 7699], [8004, 12174], [12532, 13693], [14021, 15598], [15893, 17318], [17900, 24782], [24878, 26232], [26302, 27380], [27420, 29082], [29620, 30979], [31300, 32412], [33148, 34179], [34233, 40703], [41208, 42120], [42195, 43559]], "num_segments": 16}
{"id": "sakura_emotion_71_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_71_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Give them space to cool off before engaging further.", "Provide emotional support and avoid dismissing their sadness.", "Offer reassurance and remind them they are safe.", "Offer congratulations or compliments to share their happiness."], "answer": "Offer reassurance and remind them they are safe.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_71.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[138, 4978], [5081, 5963], [6139, 11641], [11883, 13016], [13717, 14600], [15102, 18078], [18262, 19676], [19770, 27405], [27555, 33006]], "num_segments": 9}
{"id": "sakura_emotion_71_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_71_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "sad", "angry", "disgust"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_71.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[0, 1071], [1388, 2566], [2794, 3875], [4399, 6445], [7204, 8434], [9232, 10057], [10789, 14520], [14917, 15928], [16522, 23625], [23625, 24754], [24830, 28972], [29888, 31858], [31948, 33413]], "num_segments": 13}
{"id": "sakura_emotion_72_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_72_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["fear", "sad", "happy", "angry"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_72.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1088, 4158], [5558, 9286], [9359, 13826], [14175, 15417], [15623, 17170], [17231, 20735], [21016, 21927], [22838, 28990], [29051, 29955], [30068, 31895], [32194, 37074], [38089, 39134]], "num_segments": 12}
{"id": "sakura_emotion_73_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_73_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["disgust", "sad", "happy", "fear"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_73.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1003, 3584], [3842, 4716], [5089, 9940], [10179, 11317], [11368, 16942], [17689, 21198], [21359, 23232], [23276, 28626], [28830, 36094], [36866, 44552], [44632, 45622]], "num_segments": 11}
{"id": "sakura_emotion_72_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_72_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["I can\u2019t even look at this without feeling uncomfortable.", "It\u2019s hard to imagine things ever getting better.", "I can\u2019t shake the feeling that something bad is coming.", "I can\u2019t believe this is happening, I\u2019m so furious!"], "answer": "It\u2019s hard to imagine things ever getting better.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_72.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1859, 2849], [3840, 4963], [6146, 13865], [14181, 18274], [18366, 19509], [21027, 23799], [25535, 29539], [30164, 32149], [32539, 33517], [33598, 35909], [37123, 38403]], "num_segments": 11}
{"id": "sakura_emotion_73_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_73_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["It\u2019s hard to imagine things ever getting better.", "I\u2019ve had enough of this nonsense.", "This makes me feel sick to my stomach.", "I feel so grateful and full of joy right now."], "answer": "This makes me feel sick to my stomach.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_73.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[498, 2595], [3267, 5001], [5588, 7887], [9099, 11273], [11864, 16284], [17005, 17811], [18304, 19169], [19651, 21604], [22561, 23774], [23992, 30461], [30817, 32405], [32565, 36665], [37842, 42750], [42961, 45067]], "num_segments": 14}
{"id": "sakura_emotion_74_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_74_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["happy", "disgust", "sad", "angry"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_74.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[115, 3473], [3956, 6977], [8453, 10460], [11201, 13885], [14496, 19921], [20760, 22520], [23161, 26189], [27514, 29589], [30539, 31786], [31975, 33953], [34168, 35138], [36329, 37191]], "num_segments": 12}
{"id": "sakura_emotion_75_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_75_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "angry", "fear", "happy"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_75.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1110, 2290], [2552, 4671], [5985, 7379], [8280, 11096], [11210, 14543], [15432, 16634], [16856, 18570], [19028, 20033], [21582, 22738], [22860, 24481], [25249, 27341], [27378, 32433], [32856, 33859]], "num_segments": 13}
{"id": "sakura_emotion_74_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_74_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["I feel so grateful and full of joy right now.", "How dare they treat me so unfairly like this!", "I feel so empty, like nothing matters anymore.", "I can\u2019t shake the feeling that something bad is coming."], "answer": "I feel so empty, like nothing matters anymore.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_74.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[633, 1952], [2741, 6522], [7106, 8102], [8698, 9499], [9847, 12924], [13437, 14707], [15206, 16203], [16363, 21844], [22199, 24508], [24603, 28899], [29609, 31994], [32696, 33506], [34240, 35462]], "num_segments": 13}
{"id": "sakura_emotion_75_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_75_masked_100pct.wav", "question": "Considering the emotion expressed in the audio, which of the following facial expressions would align most closely with it?", "choices": ["Eyes crinkling with an open-mouthed laugh", "Averted gaze with a grimacing mouth", "A sharp, piercing gaze and compressed lips", "Downturned mouth and teary eyes"], "answer": "A sharp, piercing gaze and compressed lips", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_75.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[874, 5923], [6344, 8373], [8436, 13227], [13896, 21176], [22034, 23203], [23263, 25580], [25713, 29351], [29467, 31776], [32749, 34006]], "num_segments": 9}
{"id": "sakura_emotion_76_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_76_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "happy", "sad", "angry"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_76.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[416, 4968], [5779, 7676], [8178, 9040], [9793, 11229], [12413, 13630], [13693, 20547], [20835, 22704], [23159, 25695], [26150, 27252], [28542, 31337], [31702, 32622], [32767, 33947], [34423, 38694], [39840, 43408], [44686, 45591]], "num_segments": 15}
{"id": "sakura_emotion_76_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_76_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Suggest an activity to keep the positive energy flowing.", "Listen attentively without interrupting to let them vent.", "Stay calm and provide support to ease their anxiety.", "Provide emotional support and avoid dismissing their sadness."], "answer": "Stay calm and provide support to ease their anxiety.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_76.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1631, 3855], [4128, 5029], [5398, 11429], [11878, 12714], [13105, 15423], [16385, 17254], [17856, 18920], [18996, 21225], [21412, 22958], [23156, 24100], [24477, 26041], [26428, 30663], [31207, 34396], [34970, 36784], [37513, 39093], [39137, 40563], [40811, 45010]], "num_segments": 17}
{"id": "sakura_emotion_78_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_78_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "disgust", "happy", "angry"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_78.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[610, 1692], [1798, 3339], [4087, 10720], [10980, 12144], [12293, 13736], [13968, 19959], [20030, 23035], [24173, 25112], [26193, 28119], [29991, 30989], [31501, 35379], [37065, 39139], [39781, 42601], [42884, 43861]], "num_segments": 14}
{"id": "sakura_emotion_77_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_77_masked_100pct.wav", "question": "Which facial expression best matches the emotion in the audio?", "choices": ["Raised eyebrows with a scowl", "Squinted eyes and a pinched nose", "A heavy sigh with a frown and slumped posture", "Relaxed facial muscles with a cheerful grin"], "answer": "Raised eyebrows with a scowl", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_77.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[672, 1511], [1585, 2667], [3974, 6196], [6866, 14059], [14473, 15805], [16079, 18740], [19565, 20450], [20901, 28443], [30008, 37988], [38301, 39255], [39646, 45228], [45884, 46856], [48413, 49226], [49593, 52011], [53074, 61022], [61194, 62374]], "num_segments": 16}
{"id": "sakura_emotion_79_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_79_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Rejecting a tasteless meal with a grimace.", "Watching a touching but sorrowful movie scene.", "Walking alone in a dark alley at night.", "A person yelling after being cut off in traffic."], "answer": "A person yelling after being cut off in traffic.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_79.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[690, 1570], [2150, 6096], [6226, 7143], [7895, 15500], [15675, 16657], [16916, 17865], [18151, 19583], [19626, 20673], [21294, 23541], [24974, 26788], [28034, 29948], [30392, 31432]], "num_segments": 12}
{"id": "sakura_emotion_79_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_79_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "disgust", "angry", "sad"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_79.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1324, 3731], [4274, 6201], [7547, 8871], [9854, 11072], [11131, 12166], [12479, 15979], [16085, 17487], [17588, 18660], [19144, 22430], [23495, 31444]], "num_segments": 10}
{"id": "sakura_emotion_77_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_77_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "angry", "disgust", "sad"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_77.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[717, 5739], [5953, 8448], [9004, 14143], [14523, 18679], [20130, 27420], [28644, 31876], [32025, 34091], [34939, 38242], [38517, 45134], [45904, 46941], [47782, 53023], [53516, 54454], [55518, 58049], [58373, 60246], [60330, 61537]], "num_segments": 15}
{"id": "sakura_emotion_78_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_78_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Calmly acknowledge their frustration and suggest a solution.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Express genuine excitement for their good news or achievement.", "Encourage them to take deep breaths to relax."], "answer": "Express genuine excitement for their good news or achievement.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_78.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[729, 5120], [5478, 7109], [7271, 9023], [10109, 11989], [13347, 17554], [17580, 20140], [20196, 22316], [22958, 24436], [24765, 25619], [26337, 28829], [29570, 30724], [30845, 31663], [33049, 37111], [37237, 38989], [39002, 39895], [40990, 42599], [42649, 43700]], "num_segments": 17}
{"id": "sakura_emotion_80_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_80_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["Squinted eyes and a pinched nose", "Wide-open eyes with raised eyebrows and slightly parted lips.", "A sharp, piercing gaze and compressed lips", "Relaxed facial muscles with a cheerful grin"], "answer": "Relaxed facial muscles with a cheerful grin", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_80.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[396, 3822], [4101, 8732], [9137, 16981], [17376, 20557], [21255, 24937], [25442, 28478], [28487, 29599], [29932, 30841], [31418, 35996], [37647, 38480], [38836, 40561], [40806, 44275], [44445, 45727]], "num_segments": 13}
{"id": "sakura_emotion_80_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_80_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "fear", "disgust", "sad"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_80.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[860, 3162], [3386, 4315], [4445, 5384], [6701, 8559], [9017, 10326], [10437, 11820], [12156, 16484], [16833, 21688], [21733, 23460], [24151, 25418], [25527, 28492], [29651, 34669], [34718, 36065], [36095, 38422], [38978, 41654], [42637, 45098]], "num_segments": 16}
{"id": "sakura_emotion_81_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_81_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "happy", "sad", "fear"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_81.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[951, 2171], [2605, 3872], [4285, 6037], [6883, 11577], [12667, 14124], [14436, 16501], [16736, 18002], [19029, 21240], [21818, 24486], [24644, 27561], [28148, 29280], [29347, 31092], [32154, 35575], [35992, 37112], [37648, 38656]], "num_segments": 15}
{"id": "sakura_emotion_81_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_81_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Express understanding calmly and suggest leaving the unpleasant environment.", "Offer congratulations or compliments to share their happiness.", "Apologize and admit your mistake, if appropriate.", "Hold their hand or offer some physical reassurance."], "answer": "Offer congratulations or compliments to share their happiness.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_81.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[475, 4029], [4145, 6428], [6715, 11795], [13496, 14420], [14980, 15823], [16135, 23502], [24043, 24878], [25072, 27872], [28343, 29801], [29893, 32996], [33412, 34418], [34549, 35974], [36854, 38231]], "num_segments": 13}
{"id": "sakura_emotion_82_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_82_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["This situation is really starting to piss me off!", "I can\u2019t breathe, I\u2019m just so afraid right now.", "I\u2019m so excited, I just can\u2019t contain my happiness!", "I can\u2019t even look at this without feeling uncomfortable."], "answer": "I can\u2019t even look at this without feeling uncomfortable.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_82.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[938, 6795], [7356, 8786], [8786, 10069], [11008, 16416], [17189, 18256], [18737, 23709], [24881, 29005], [29644, 33197], [33465, 34475], [34581, 36006]], "num_segments": 10}
{"id": "sakura_emotion_82_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_82_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["angry", "disgust", "fear", "sad"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_82.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[890, 6818], [8231, 11680], [12765, 18945], [18975, 20391], [20735, 24377], [24564, 27681], [28582, 29392], [29406, 30550], [30793, 31601], [32227, 35064], [35132, 36185]], "num_segments": 11}
{"id": "sakura_emotion_83_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_83_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "sad", "disgust", "happy"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_83.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1064, 2238], [2620, 4025], [4033, 5343], [5348, 7729], [7879, 9442], [10001, 10932], [11574, 17847], [18681, 22107], [22251, 23083], [24488, 30057], [31983, 33837], [33892, 35799], [36004, 37167], [37676, 38643], [38669, 41638], [41761, 42679]], "num_segments": 16}
{"id": "sakura_emotion_83_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_83_masked_100pct.wav", "question": "Which facial expression best matches the emotion in the audio?", "choices": ["A heavy sigh with a frown and slumped posture", "Frozen facial expression with trembling lips and quickened breathing.", "Clenched teeth with side facial muscles showing tension.", "Retracted chin with one corner of the mouth twitching, as if intolerable."], "answer": "Retracted chin with one corner of the mouth twitching, as if intolerable.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_83.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1263, 7635], [7642, 9299], [10147, 11823], [12039, 13234], [13238, 20122], [20278, 21276], [21631, 24136], [25683, 33135], [33710, 40875], [41444, 42687]], "num_segments": 10}
{"id": "sakura_emotion_84_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_84_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["sad", "disgust", "angry", "happy"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_84.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[775, 4400], [4980, 5834], [6401, 13657], [13729, 14978], [15228, 18864], [20063, 23503], [24545, 29608]], "num_segments": 7}
{"id": "sakura_emotion_85_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_85_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "disgust", "sad", "fear"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_85.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[766, 3499], [3914, 11823], [12328, 13354], [14223, 15953], [16155, 22718], [23399, 29214], [30122, 32206], [32972, 35688]], "num_segments": 8}
{"id": "sakura_emotion_84_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_84_masked_100pct.wav", "question": "Which situation best corresponds to the emotion conveyed in the speech?", "choices": ["Seeing an unpleasant image online.", "Hugging a loved one after a long separation.", "Saying goodbye at an airport.", "Facing an aggressive dog on the street."], "answer": "Seeing an unpleasant image online.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_84.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[835, 2099], [2184, 8454], [8803, 10970], [11271, 12121], [13234, 14218], [14515, 15618], [16496, 18262], [18523, 19512], [20297, 21155], [21191, 23192], [24251, 25461], [25662, 26850], [27614, 29642]], "num_segments": 13}
{"id": "sakura_emotion_85_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_85_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I feel so empty, like nothing matters anymore.", "I feel like I\u2019m in danger, and I don\u2019t know what to do.", "That\u2019s just revolting, I can\u2019t believe it.", "I feel so grateful and full of joy right now."], "answer": "That\u2019s just revolting, I can\u2019t believe it.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_85.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[656, 4871], [4999, 5892], [6061, 13208], [13394, 15187], [15648, 16553], [17085, 18435], [19281, 23528], [24131, 25227], [25527, 26427], [27896, 28714], [29072, 34157], [34952, 36332]], "num_segments": 12}
{"id": "sakura_emotion_86_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_86_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "angry", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_86.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[965, 2439], [2743, 6739], [7232, 11308], [12535, 13691], [13700, 15084], [15119, 16096], [16750, 18489], [19221, 20349], [20580, 21753], [22023, 22872], [23162, 29396], [29578, 30481], [31690, 34150], [34224, 35777], [37221, 44349]], "num_segments": 15}
{"id": "sakura_emotion_88_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_88_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "sad", "disgust", "happy"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_88.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[213, 1311], [2078, 9233], [10289, 16878], [17550, 19285], [19643, 20533], [20644, 23487], [23694, 24721], [24832, 29835]], "num_segments": 8}
{"id": "sakura_emotion_86_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_86_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["A person crying after a breakup.", "Laughing at a funny joke in a conversation.", "A heated argument between colleagues.", "Preparing for a high-stakes exam with anxiety."], "answer": "A person crying after a breakup.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_86.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[266, 1876], [1992, 8525], [9217, 12179], [12758, 15664], [15788, 17473], [17857, 21229], [21470, 23708], [23951, 24826], [24885, 30356], [31043, 36006], [37236, 40185], [40643, 42070], [42747, 44217]], "num_segments": 13}
{"id": "sakura_emotion_87_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_87_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "disgust", "fear", "angry"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_87.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[873, 2689], [2990, 3971], [4112, 8301], [8946, 10088], [10453, 12209], [12424, 13562], [13966, 17141], [17486, 18822], [18978, 26885], [27409, 30877], [31567, 32439], [32691, 33537]], "num_segments": 12}
{"id": "sakura_emotion_89_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_89_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "sad", "happy", "disgust"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_89.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[43, 1171], [1335, 8983], [9057, 10394], [10423, 11352], [11529, 12502], [13705, 20035], [20963, 25028], [25101, 28458], [28610, 29478]], "num_segments": 9}
{"id": "sakura_emotion_88_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_88_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Express understanding calmly and suggest leaving the unpleasant environment.", "Apologize and admit your mistake, if appropriate.", "Express genuine excitement for their good news or achievement.", "Hold their hand or offer some physical reassurance."], "answer": "Express understanding calmly and suggest leaving the unpleasant environment.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_88.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[191, 5180], [5396, 6800], [6820, 9975], [10105, 14288], [14870, 19417], [20745, 22333], [23722, 27883], [27995, 30322]], "num_segments": 8}
{"id": "sakura_emotion_89_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_89_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Give them space to cool off before engaging further.", "Offer congratulations or compliments to share their happiness.", "Provide emotional support and avoid dismissing their sadness.", "Reassure them and offer a way to move past the uncomfortable    situation."], "answer": "Offer congratulations or compliments to share their happiness.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_89.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[339, 3478], [5408, 9902], [10699, 12465], [12687, 17106], [17505, 20806], [20887, 22127], [22449, 24924], [24933, 25748], [26299, 27191], [27495, 29885]], "num_segments": 10}
{"id": "sakura_emotion_90_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_90_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["disgust", "sad", "fear", "angry"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_90.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[868, 2755], [3031, 7945], [8432, 15797], [16221, 17493], [17728, 18704], [19783, 24319], [24587, 28910], [29387, 31216], [31995, 34687], [34763, 37849], [37956, 40797]], "num_segments": 11}
{"id": "sakura_emotion_90_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_90_masked_100pct.wav", "question": "What facial expression most aligns with the emotion in the recording?", "choices": ["Relaxed facial muscles with a cheerful grin", "Head slightly pulled back with a terrified gaze, as if searching for an escape.", "Furrowed brows with slightly open mouth, as if about to shout.", "A wrinkled nose and raised upper lip"], "answer": "Head slightly pulled back with a terrified gaze, as if searching for an escape.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_90.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1244, 3037], [3388, 10900], [10956, 12006], [12062, 13923], [14371, 22127], [22999, 26072], [26244, 27686], [28855, 30609], [30613, 31738], [31907, 32721], [33197, 38200], [38716, 41108]], "num_segments": 12}
{"id": "sakura_emotion_87_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_87_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["I can\u2019t shake the feeling that something bad is coming.", "This is the best day ever, I feel on top of the world!", "I don\u2019t know how to move on from this loss.", "This makes me feel sick to my stomach."], "answer": "This makes me feel sick to my stomach.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_87.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[394, 3263], [3373, 5800], [6574, 7980], [8613, 14826], [15657, 17153], [17881, 23646], [23943, 27227], [27656, 29543], [30046, 33587]], "num_segments": 9}
{"id": "sakura_emotion_91_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_91_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["disgust", "happy", "sad", "angry"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_91.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[637, 1476], [1739, 6785], [7002, 8380], [8741, 12037], [12285, 13799], [14397, 17058], [17298, 18532], [18557, 21372], [21816, 26096], [26131, 32809], [34154, 35756], [35828, 37196], [38313, 45788], [46114, 47392], [48630, 50801], [50931, 52122], [52218, 54473]], "num_segments": 17}
{"id": "sakura_emotion_92_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_92_masked_100pct.wav", "question": "From the provided sentences, which one best matches the emotional state of individuals who are experiencing the same emotion as the speaker?", "choices": ["I feel so empty, like nothing matters anymore.", "I\u2019m really scared about what might happen next.", "That\u2019s just revolting, I can\u2019t believe it.", "I\u2019m just so happy I could burst!"], "answer": "I\u2019m just so happy I could burst!", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_92.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[533, 1483], [1951, 2944], [3153, 6515], [7258, 8843], [9234, 11433], [12037, 13487], [13579, 15410], [15776, 17874], [18592, 22884], [23400, 28710], [29273, 30280], [30693, 32734], [33022, 34329], [34426, 35950], [36485, 37430], [37579, 38612], [39613, 42241], [43495, 44962]], "num_segments": 18}
{"id": "sakura_emotion_94_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_94_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "disgust", "happy", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_94.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[201, 3478], [3553, 4709], [5008, 6656], [8329, 10889], [10957, 13359], [13446, 15709], [16822, 22153], [23207, 29687], [30656, 33683], [33687, 34623], [34623, 36079], [36163, 41107]], "num_segments": 12}
{"id": "sakura_emotion_91_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_91_masked_100pct.wav", "question": "What facial expression most aligns with the emotion in the recording?", "choices": ["Eyes crinkling with an open-mouthed laugh", "Squinted eyes and a pinched nose", "Tightly pressed lips with glaring eyes", "Wrinkled forehead and a forlorn expression"], "answer": "Wrinkled forehead and a forlorn expression", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_91.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[489, 1940], [2652, 3888], [4190, 6694], [6888, 9131], [9290, 12241], [12486, 15206], [15908, 18007], [18238, 22528], [23278, 24205], [25176, 28800], [28942, 33816], [34315, 35955], [36150, 38083], [38386, 39230], [39380, 40250], [41090, 42109], [42282, 43125], [44007, 46049], [46816, 50990], [51481, 54369], [54858, 55660]], "num_segments": 21}
{"id": "sakura_emotion_93_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_93_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "sad", "angry", "happy"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_93.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1644, 6041], [6628, 12390], [13254, 15797], [16749, 17593], [17985, 19520], [19821, 21901], [22641, 23940], [24981, 25978], [26726, 33512], [33525, 35677], [35966, 38467], [39024, 39995]], "num_segments": 12}
{"id": "sakura_emotion_95_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_95_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Calmly acknowledge their frustration and suggest a solution.", "Suggest an activity to keep the positive energy flowing.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Provide emotional support and avoid dismissing their sadness."], "answer": "Suggest an activity to keep the positive energy flowing.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_95.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[511, 2835], [3118, 4366], [4665, 11603], [11773, 14630], [14812, 16196], [17138, 24398], [24572, 30912], [30967, 33713]], "num_segments": 8}
{"id": "sakura_emotion_94_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_94_masked_100pct.wav", "question": "Considering the emotion expressed in the audio, which of the following facial expressions would align most closely with it?", "choices": ["A heavy sigh with a frown and slumped posture", "Wide-open eyes with raised eyebrows and slightly parted lips.", "A warm, genuine smile with slightly tilted head", "Squinted eyes and a pinched nose"], "answer": "Wide-open eyes with raised eyebrows and slightly parted lips.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_94.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[255, 3184], [4199, 7254], [8560, 14170], [15863, 22350], [23836, 27895], [28082, 28907], [29712, 32020], [33110, 38128], [38554, 40521]], "num_segments": 9}
{"id": "sakura_emotion_92_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_92_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "angry", "fear", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_92.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1398, 3217], [3233, 4668], [5715, 7248], [8448, 10759], [11705, 19569], [20822, 21760], [22538, 23917], [24642, 25507], [25738, 26976], [26984, 29449], [30735, 33918], [34529, 41115], [42364, 44897]], "num_segments": 13}
{"id": "sakura_emotion_93_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_93_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["A sharp, piercing gaze and compressed lips", "Squinted eyes and a pinched nose", "A heavy sigh with a frown and slumped posture", "Relaxed facial muscles with a cheerful grin"], "answer": "A sharp, piercing gaze and compressed lips", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_93.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[876, 2342], [2356, 3436], [3689, 10528], [10569, 12986], [13068, 14006], [14040, 14922], [16428, 20553], [21083, 22674], [22767, 24235], [24770, 26600], [26796, 28108], [29000, 30196], [30325, 35870], [36059, 39932]], "num_segments": 14}
{"id": "sakura_emotion_96_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_96_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["disgust", "happy", "angry", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_96.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[428, 2054], [2524, 6023], [6712, 8068], [8313, 12566], [13441, 15154], [15919, 20031], [20581, 22995], [23000, 29491], [29694, 32954], [33312, 34600], [34995, 36479], [36866, 40379]], "num_segments": 12}
{"id": "sakura_emotion_95_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_95_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "angry", "fear", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_95.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[61, 1171], [1285, 3351], [3924, 4926], [5156, 10759], [10783, 13889], [14610, 16064], [16106, 21920], [23138, 24166], [25088, 28079], [28497, 30176], [30226, 31795], [32560, 33596]], "num_segments": 12}
{"id": "sakura_emotion_96_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_96_masked_100pct.wav", "question": "Which situation best corresponds to the emotion conveyed in the speech?", "choices": ["Attending a close friend's funeral.", "Winning a long-anticipated award or prize.", "Walking alone in a dark alley at night.", "A heated argument between colleagues."], "answer": "Walking alone in a dark alley at night.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_96.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[446, 1911], [2315, 10061], [11221, 14541], [14646, 16023], [16337, 17152], [17358, 19609], [20874, 28569], [28612, 29908], [29990, 34481], [35194, 36169], [37160, 39032], [40073, 40883]], "num_segments": 12}
{"id": "sakura_emotion_97_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_97_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "fear", "happy", "sad"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_97.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[411, 2407], [2472, 5018], [5501, 7133], [8210, 13190], [13600, 16088], [16848, 17748], [18808, 19876], [20401, 23057], [24153, 25316], [25778, 30352], [30420, 31808], [32062, 33264], [33920, 35501], [35540, 36689]], "num_segments": 14}
{"id": "sakura_emotion_98_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_98_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "happy", "sad", "fear"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_98.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[982, 1987], [2113, 6511], [6585, 12388], [13114, 15781], [16585, 20496], [20921, 22669], [23415, 24612], [24901, 30652], [30837, 31949], [32338, 33873]], "num_segments": 10}
{"id": "sakura_emotion_97_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_97_masked_100pct.wav", "question": "What facial expression most aligns with the emotion in the recording?", "choices": ["Frozen facial expression with trembling lips and quickened breathing.", "A warm, genuine smile with slightly tilted head", "Flared nostrils with a tense expression", "A heavy sigh with a frown and slumped posture"], "answer": "A warm, genuine smile with slightly tilted head", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_97.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[21, 988], [1898, 3407], [4432, 8558], [9901, 13672], [14684, 17579], [18070, 19151], [20244, 26470], [26663, 28318], [28887, 30632], [30742, 31899], [32100, 33344], [33645, 34977], [35065, 36341]], "num_segments": 13}
{"id": "sakura_emotion_99_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_99_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Calmly acknowledge their frustration and suggest a solution.", "Listen empathetically and let them express their feelings.", "Hold their hand or offer some physical reassurance.", "Avoid discussing further and respect their aversion to the topic."], "answer": "Hold their hand or offer some physical reassurance.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_99.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[40, 951], [1396, 4316], [4416, 5909], [6291, 9619], [10377, 11626], [12305, 18036], [18842, 19655], [19826, 25666], [27063, 28872], [30046, 35957]], "num_segments": 10}
{"id": "sakura_emotion_98_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_98_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Hold their hand or offer some physical reassurance.", "Avoid discussing further and respect their aversion to the topic.", "Provide emotional support and avoid dismissing their sadness.", "Apologize and admit your mistake, if appropriate."], "answer": "Provide emotional support and avoid dismissing their sadness.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_98.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[337, 2267], [2337, 4334], [5347, 12422], [12533, 16510], [17963, 20015], [21172, 22886], [23115, 30588], [30773, 32069], [32425, 34084]], "num_segments": 9}
{"id": "sakura_emotion_100_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_100_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "disgust", "fear", "angry"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_100.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[79, 1538], [2165, 3044], [3057, 5864], [7770, 11974], [12344, 13512], [13821, 20654], [21037, 21983], [22600, 24988], [25094, 29474], [30143, 31000], [31154, 32020], [32826, 39504], [40143, 42203], [43746, 46014], [47304, 48857]], "num_segments": 15}
{"id": "sakura_emotion_99_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_99_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["sad", "happy", "fear", "angry"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_99.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[294, 6240], [6661, 9604], [10385, 12970], [13496, 14650], [14699, 15998], [16349, 20097], [20753, 22527], [23019, 24930], [25556, 32356], [32543, 34195], [34238, 35271]], "num_segments": 11}
{"id": "sakura_emotion_102_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_102_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "fear", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_102.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[276, 1449], [1513, 3337], [3917, 9128], [10100, 15400], [15451, 16462], [16929, 19331], [20568, 21544], [21828, 23161], [23613, 24483], [24887, 29676], [30554, 31504], [32795, 34830], [35301, 36454]], "num_segments": 13}
{"id": "sakura_emotion_101_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_101_masked_100pct.wav", "question": "Which situation best corresponds to the emotion conveyed in the speech?", "choices": ["Slamming a door after a disagreement.", "Rejecting a tasteless meal with a grimace.", "Walking alone in a dark alley at night.", "Saying goodbye at an airport."], "answer": "Slamming a door after a disagreement.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_101.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[654, 5996], [6576, 7889], [8663, 10365], [10410, 17877], [18025, 19920], [20273, 23672], [24206, 31950], [31979, 33151], [33541, 34975]], "num_segments": 9}
{"id": "sakura_emotion_102_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_102_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["A person yelling after being cut off in traffic.", "Winning a long-anticipated award or prize.", "Watching a touching but sorrowful movie scene.", "Hearing a shocking and offensive statement."], "answer": "Watching a touching but sorrowful movie scene.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_102.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[588, 4185], [4281, 6388], [7790, 8766], [9199, 14541], [15244, 16486], [16689, 17494], [19000, 21578], [22227, 28795], [29392, 31284], [31339, 35691], [35922, 36823]], "num_segments": 11}
{"id": "sakura_emotion_100_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_100_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Encourage them to take deep breaths to relax.", "Calmly acknowledge their frustration and suggest a solution.", "Smile and engage positively in the conversation.", "Listen empathetically and let them express their feelings."], "answer": "Listen empathetically and let them express their feelings.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_100.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[473, 1680], [1722, 2886], [3531, 5292], [5982, 7817], [8170, 10324], [10341, 11364], [11599, 17786], [18194, 19408], [21154, 22606], [23074, 24098], [24457, 28674], [29915, 31138], [32248, 33096], [34300, 35480], [36184, 38693], [38753, 44827], [45668, 48688]], "num_segments": 17}
{"id": "sakura_emotion_101_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_101_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["sad", "disgust", "happy", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_101.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[468, 3883], [4243, 6812], [6942, 13811], [13849, 14868], [15367, 17831], [17889, 19024], [19085, 25172], [26221, 30416], [30518, 32062], [32748, 33578], [33728, 35128]], "num_segments": 11}
{"id": "sakura_emotion_103_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_103_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["This is terrifying, I can\u2019t stop thinking about it.", "Stop making excuses; this is entirely your fault!", "This is the best day ever, I feel on top of the world!", "I don\u2019t know how to move on from this loss."], "answer": "Stop making excuses; this is entirely your fault!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_103.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[262, 1343], [1553, 2893], [3667, 4602], [4723, 6086], [6218, 8159], [9019, 10639], [11326, 13887], [15166, 19512], [19666, 26025], [26038, 27356], [27450, 29003], [29407, 32557]], "num_segments": 12}
{"id": "sakura_emotion_103_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_103_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "disgust", "angry", "happy"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_103.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1367, 5898], [7003, 8072], [8403, 11963], [11985, 13148], [13457, 15255], [16047, 22978], [23028, 23916], [24667, 25913], [26240, 27646], [27753, 32058]], "num_segments": 10}
{"id": "sakura_emotion_104_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_104_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Express genuine excitement for their good news or achievement.", "Stay calm and provide support to ease their anxiety.", "Avoid discussing further and respect their aversion to the topic.", "Give them space to cool off before engaging further."], "answer": "Express genuine excitement for their good news or achievement.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_104.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1273, 2589], [2739, 8231], [8433, 9540], [9746, 12557], [13409, 18522], [19371, 20468], [20842, 27027], [27668, 30836], [31323, 32145], [32700, 35471], [35641, 37571]], "num_segments": 11}
{"id": "sakura_emotion_104_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_104_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["disgust", "happy", "sad", "angry"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_104.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[339, 1523], [1768, 2760], [2786, 5995], [7121, 8502], [8975, 9997], [10498, 16979], [17679, 18804], [18949, 20071], [20951, 21752], [22819, 25152], [25812, 26835], [27192, 32484], [34007, 37006], [37196, 38299]], "num_segments": 14}
{"id": "sakura_emotion_105_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_105_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Throwing an object in frustration.", "Watching a horror movie alone in the dark.", "Saying goodbye at an airport.", "Hearing a shocking and offensive statement."], "answer": "Hearing a shocking and offensive statement.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_105.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[450, 5350], [5812, 7141], [7480, 9923], [10040, 17354], [17405, 21572], [21677, 26116], [26837, 28829], [30625, 31547], [31819, 35365], [35421, 42654], [44040, 45472], [46123, 47046]], "num_segments": 12}
{"id": "sakura_emotion_106_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_106_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["disgust", "angry", "sad", "happy"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_106.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[63, 1060], [1344, 3130], [3573, 6263], [6893, 8538], [9727, 13706], [14106, 20640], [20942, 22603], [22737, 23760], [24341, 25471], [25586, 30125], [31232, 32117], [32562, 37468], [37673, 42704], [44156, 46473]], "num_segments": 14}
{"id": "sakura_emotion_105_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_105_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "happy", "angry", "fear"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_105.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[865, 1957], [2099, 3212], [4049, 8199], [8359, 9312], [9846, 13197], [14763, 18907], [19022, 21404], [21577, 25670], [26102, 27991], [28448, 29385], [29644, 31318], [31554, 32423], [32448, 37944], [38790, 39897], [41399, 42326], [42689, 43513], [44604, 46645]], "num_segments": 17}
{"id": "sakura_emotion_106_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_106_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Provide emotional support and avoid dismissing their sadness.", "Hold their hand or offer some physical reassurance.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Give them space to cool off before engaging further."], "answer": "Provide emotional support and avoid dismissing their sadness.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_106.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[495, 2677], [2985, 7675], [7810, 8768], [9196, 10374], [10700, 13224], [13409, 17625], [18811, 19778], [19815, 22255], [22674, 23654], [23977, 25041], [25889, 31995], [33410, 37816], [38324, 39515], [39542, 44594], [45815, 46621]], "num_segments": 15}
{"id": "sakura_emotion_108_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_108_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["A wrinkled nose and raised upper lip", "A sharp, piercing gaze and compressed lips", "Head slightly pulled back with a terrified gaze, as if searching for an escape.", "A broad smile with sparkling eyes"], "answer": "A broad smile with sparkling eyes", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_108.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[366, 1273], [1872, 2681], [2820, 4351], [4543, 5739], [6184, 7481], [7952, 14902], [15821, 19893], [21256, 22708], [22788, 26060], [27455, 28376], [28452, 35915], [36592, 39695], [40295, 41740], [42838, 44833]], "num_segments": 14}
{"id": "sakura_emotion_108_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_108_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "happy", "sad", "angry"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_108.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[54, 2474], [3362, 6731], [6756, 7733], [8495, 11942], [12883, 15623], [17327, 19052], [19482, 25592], [26693, 27865], [28174, 29259], [29289, 31219], [32880, 35531], [36370, 44146], [44155, 44972]], "num_segments": 13}
{"id": "sakura_emotion_109_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_109_masked_100pct.wav", "question": "Which facial expression best fits the emotion heard in the audio?", "choices": ["A wrinkled nose and raised upper lip", "Tightly furrowed brow with trembling lips", "A sharp, piercing gaze and compressed lips", "A warm, genuine smile with slightly tilted head"], "answer": "Tightly furrowed brow with trembling lips", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_109.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[447, 5677], [5939, 6749], [6864, 11777], [13219, 14606], [14717, 15711], [15740, 17935], [18662, 20249], [20864, 21676], [22034, 24792], [24896, 26934], [28476, 30213], [30267, 32806], [33722, 37842], [38724, 40220]], "num_segments": 14}
{"id": "sakura_emotion_111_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_111_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "angry", "fear", "happy"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_111.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[608, 2907], [3908, 10726], [11598, 13460], [13851, 16450], [17679, 20259], [21422, 25080], [26845, 29847], [29968, 31309], [31548, 39212]], "num_segments": 9}
{"id": "sakura_emotion_111_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_111_masked_100pct.wav", "question": "Based on the emotion identified in the audio, which of these facial expressions is most likely to match the speaker's emotional state?", "choices": ["A drooping gaze with a slack jaw", "Wide-open eyes with raised eyebrows and slightly parted lips.", "Furrowed brows with slightly open mouth, as if about to shout.", "Squinted eyes and a pinched nose"], "answer": "Wide-open eyes with raised eyebrows and slightly parted lips.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_111.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1127, 8065], [8827, 10750], [11190, 12736], [12929, 17991], [18639, 23975], [24643, 25663], [25684, 26859], [27043, 34864], [35125, 40162]], "num_segments": 9}
{"id": "sakura_emotion_109_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_109_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["sad", "happy", "disgust", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_109.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[774, 2286], [2300, 4333], [4766, 8179], [8554, 12439], [13366, 14470], [14641, 17620], [18871, 20546], [20725, 21794], [21977, 25754], [26404, 27759], [27872, 28980], [29124, 33243], [34104, 36332], [36477, 37516], [38167, 39991]], "num_segments": 15}
{"id": "sakura_emotion_110_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_110_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["This situation is really starting to piss me off!", "I feel so empty, like nothing matters anymore.", "I feel so grateful and full of joy right now.", "This thing looks absolutely gross and dirty; I can\u2019t stand it!"], "answer": "This thing looks absolutely gross and dirty; I can\u2019t stand it!", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_110.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1436, 5256], [6134, 6987], [7141, 12491], [12554, 13624], [13764, 15476], [16285, 19539], [19633, 20778], [21013, 23655], [23728, 25516], [25649, 26600], [27257, 29284], [30070, 32990], [33447, 35337]], "num_segments": 13}
{"id": "sakura_emotion_110_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_110_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "disgust", "happy", "fear"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_110.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[120, 1144], [1590, 8376], [8846, 9876], [10068, 15858], [16128, 17289], [17365, 18598], [18796, 20204], [20324, 21812], [22369, 25811], [26252, 28712], [29190, 30351], [30630, 32249], [32934, 35325]], "num_segments": 13}
{"id": "sakura_emotion_113_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_113_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["disgust", "fear", "angry", "happy"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_113.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[139, 2774], [3816, 11402], [11727, 12870], [13772, 14864], [16318, 21883], [22619, 23852], [24834, 27085], [27099, 30143], [30635, 37445], [37460, 38976], [39351, 44807], [45299, 46205]], "num_segments": 12}
{"id": "sakura_emotion_112_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_112_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "happy", "disgust", "sad"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_112.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[20, 1419], [1869, 6663], [6842, 8331], [9346, 10454], [10745, 12793], [13198, 14600], [14918, 17401], [17787, 18730], [19682, 20945], [22056, 24965], [25806, 26719], [26838, 27962], [27993, 35659]], "num_segments": 13}
{"id": "sakura_emotion_107_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_107_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Furrowed brows with slightly open mouth, as if about to shout.", "A wrinkled nose and raised upper lip", "Frozen facial expression with trembling lips and quickened breathing.", "A drooping gaze with a slack jaw"], "answer": "A drooping gaze with a slack jaw", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_107.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[335, 5034], [5077, 7144], [7388, 13121], [13910, 15106], [15450, 16840], [17151, 19018], [19486, 20821], [20841, 21828], [22111, 29986], [31866, 32884], [34254, 37701], [37772, 39456], [40027, 43873], [44185, 49823], [50263, 51773]], "num_segments": 15}
{"id": "sakura_emotion_112_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_112_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Wide-open eyes with raised eyebrows and slightly parted lips.", "Averted gaze with a grimacing mouth", "Flared nostrils with a tense expression", "Eyes crinkling with an open-mouthed laugh"], "answer": "Wide-open eyes with raised eyebrows and slightly parted lips.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_112.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[548, 4338], [4785, 5686], [6198, 7162], [7724, 9223], [9979, 12122], [13448, 17762], [18782, 26177], [27598, 29903], [29942, 31232], [32052, 35454]], "num_segments": 10}
{"id": "sakura_emotion_107_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_107_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["fear", "disgust", "angry", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_107.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1265, 2557], [3397, 7972], [8298, 9410], [10377, 13133], [13663, 18166], [18362, 19881], [21195, 23244], [23982, 30450], [31333, 32668], [34003, 38117], [38164, 38973], [39390, 41178], [41297, 46566], [46754, 48699], [49411, 50238]], "num_segments": 15}
{"id": "sakura_emotion_114_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_114_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Winning a long-anticipated award or prize.", "Rejecting a tasteless meal with a grimace.", "Walking alone in a dark alley at night.", "Attending a close friend's funeral."], "answer": "Walking alone in a dark alley at night.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_114.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[313, 1776], [3245, 5615], [6243, 7287], [7304, 12943], [13685, 16008], [16140, 17532], [17812, 19782], [21052, 22110], [22625, 26873], [26987, 29358], [30108, 31457], [31676, 38335], [38386, 40055]], "num_segments": 13}
{"id": "sakura_emotion_114_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_114_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["angry", "fear", "happy", "sad"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_114.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[531, 1575], [1787, 5480], [5588, 6754], [7212, 11191], [11256, 13591], [13733, 14653], [15126, 22345], [22347, 23407], [23703, 26176], [26794, 29094], [30179, 31568], [31571, 39022], [39157, 40328]], "num_segments": 13}
{"id": "sakura_emotion_113_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_113_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["A drooping gaze with a slack jaw", "Frozen facial expression with trembling lips and quickened breathing.", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "Eyes crinkling with an open-mouthed laugh"], "answer": "Retracted chin with one corner of the mouth twitching, as if intolerable.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_113.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[478, 1279], [1539, 2399], [2886, 7755], [8148, 9151], [10441, 11269], [12585, 13938], [14589, 16955], [18004, 19963], [20074, 22126], [22263, 23346], [23723, 28163], [28533, 29636], [30232, 32030], [32067, 38879], [39193, 41890], [42138, 45124]], "num_segments": 16}
{"id": "sakura_emotion_116_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_116_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "sad", "fear", "disgust"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_116.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1400, 7780], [8727, 9868], [9894, 11956], [12033, 13057], [13426, 21208], [21275, 23828], [24046, 26493], [27443, 28340], [28865, 32623], [33442, 34306]], "num_segments": 10}
{"id": "sakura_emotion_115_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_115_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["sad", "disgust", "happy", "angry"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_115.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[527, 1712], [2747, 10526], [12748, 14670], [14996, 20379], [20407, 25249], [25694, 27479], [28011, 29441], [30457, 34517], [35103, 35979], [37384, 38533], [39383, 40349]], "num_segments": 11}
{"id": "sakura_emotion_115_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_115_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Suggest an activity to keep the positive energy flowing.", "Suggest spending some time together to cheer them up.", "Give them space to cool off before engaging further.", "Offer reassurance and remind them they are safe."], "answer": "Suggest an activity to keep the positive energy flowing.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_115.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[183, 2359], [2985, 3822], [3860, 5005], [5635, 11258], [12415, 13321], [13621, 20153], [20286, 22655], [22724, 29757], [29798, 31687], [32993, 38085], [38619, 39840]], "num_segments": 11}
{"id": "sakura_emotion_119_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_119_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["sad", "fear", "disgust", "happy"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_119.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[477, 3572], [3767, 5854], [6190, 8205], [8793, 10607], [11659, 17596], [18215, 22298], [23174, 24015], [24597, 26602], [26761, 32522], [32744, 33616], [33698, 35045], [35435, 36277], [36423, 39666], [40329, 42084], [42296, 43668]], "num_segments": 15}
{"id": "sakura_emotion_116_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_116_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["This thing looks absolutely gross and dirty; I can\u2019t stand it!", "I\u2019m so excited, I just can\u2019t contain my happiness!", "I can\u2019t breathe, I\u2019m just so afraid right now.", "I don\u2019t know how to move on from this loss."], "answer": "I can\u2019t breathe, I\u2019m just so afraid right now.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_116.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1139, 3097], [4422, 6819], [7446, 13971], [14644, 15635], [15772, 17013], [17247, 18379], [18469, 19512], [19542, 20837], [21391, 22380], [22537, 24980], [25180, 28042], [28401, 29494], [30063, 32864], [33285, 34131]], "num_segments": 14}
{"id": "sakura_emotion_118_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_118_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "sad", "disgust", "happy"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_118.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[56, 1516], [1948, 2781], [3416, 5931], [7397, 8544], [8680, 13446], [14202, 16155], [17360, 18338], [19057, 23524], [23851, 25921], [26033, 27011], [27308, 30833], [31710, 38281]], "num_segments": 12}
{"id": "sakura_emotion_118_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_118_masked_100pct.wav", "question": "Which situation best corresponds to the emotion conveyed in the speech?", "choices": ["Walking alone in a dark alley at night.", "Watching a touching but sorrowful movie scene.", "Seeing an unpleasant image online.", "A person smiling after receiving good news."], "answer": "Seeing an unpleasant image online.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_118.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[246, 3311], [4491, 5701], [6195, 7243], [7381, 11847], [12880, 18184], [18916, 22331], [23006, 24774], [24975, 25888], [26513, 28767], [30140, 31001], [31099, 33194], [33401, 34409], [35803, 38544]], "num_segments": 13}
{"id": "sakura_emotion_117_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_117_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["This is the best day ever, I feel on top of the world!", "I don\u2019t know how to move on from this loss.", "I can\u2019t even look at this without feeling uncomfortable.", "This situation is really starting to piss me off!"], "answer": "I can\u2019t even look at this without feeling uncomfortable.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_117.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1682, 4368], [4882, 6119], [6687, 8656], [9225, 10296], [11833, 16907], [17625, 20217], [20913, 22562], [22758, 27395], [27941, 30084], [30387, 31272], [31606, 32651], [33549, 37866], [38882, 39977], [41728, 44414], [45192, 48828], [50085, 51013]], "num_segments": 16}
{"id": "sakura_emotion_120_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_120_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I\u2019m feeling so down, like nothing can lift my spirits.", "How dare they treat me so unfairly like this!", "This is the best day ever, I feel on top of the world!", "This is terrifying, I can\u2019t stop thinking about it."], "answer": "This is the best day ever, I feel on top of the world!", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_120.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[462, 8282], [8665, 14888], [15170, 22038], [22231, 23775], [23934, 30015], [31028, 37312], [37443, 38595], [38875, 39876], [40063, 40946]], "num_segments": 9}
{"id": "sakura_emotion_117_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_117_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "angry", "fear", "sad"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_117.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[417, 2703], [4250, 5426], [6443, 7319], [7406, 9184], [9302, 14333], [14651, 15533], [16510, 19473], [20525, 24421], [24707, 27040], [27539, 28526], [28644, 30538], [30734, 32705], [33908, 35709], [36570, 38116], [38824, 43077], [43496, 48292], [48897, 51146]], "num_segments": 17}
{"id": "sakura_emotion_119_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_119_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Laughing at a funny joke in a conversation.", "Saying goodbye at an airport.", "Slamming a door after a disagreement.", "Walking alone in a dark alley at night."], "answer": "Saying goodbye at an airport.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_119.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[798, 1749], [1776, 3651], [4767, 6329], [6554, 11729], [12248, 15907], [17368, 18575], [18807, 23511], [24307, 26628], [27669, 30050], [30752, 31699], [31788, 36943], [37651, 39550], [40846, 43193]], "num_segments": 13}
{"id": "sakura_emotion_122_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_122_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "angry", "disgust", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_122.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[685, 2565], [2936, 4173], [4690, 9356], [9807, 13448], [13866, 19964], [20014, 22087], [22232, 23225], [24345, 29829], [29869, 30683], [31454, 32733], [33048, 34039], [34718, 39855]], "num_segments": 12}
{"id": "sakura_emotion_122_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_122_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["A wrinkled nose and raised upper lip", "A warm, genuine smile with slightly tilted head", "Raised eyebrows with a scowl", "Downturned mouth and teary eyes"], "answer": "A warm, genuine smile with slightly tilted head", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_122.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[746, 2001], [2453, 3467], [3836, 8757], [8838, 10311], [10822, 12640], [12991, 15741], [16185, 18081], [18559, 20090], [20405, 25333], [25718, 26600], [27528, 32653], [32659, 34167], [34366, 39287]], "num_segments": 13}
{"id": "sakura_emotion_120_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_120_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "disgust", "fear", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_120.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[441, 7227], [7246, 8364], [9802, 15101], [15165, 17219], [17400, 18415], [18631, 21362], [21804, 23878], [24168, 25349], [26797, 28456], [28570, 30344], [30497, 36299], [36732, 37610], [38607, 40729]], "num_segments": 13}
{"id": "sakura_emotion_124_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_124_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["fear", "sad", "angry", "disgust"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_124.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[476, 1529], [1788, 3987], [4381, 10494], [10640, 13569], [13622, 17950], [18421, 19542], [20649, 27610], [28340, 29580], [30073, 37636]], "num_segments": 9}
{"id": "sakura_emotion_125_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_125_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "disgust", "angry", "happy"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_125.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[406, 7012], [7242, 9605], [10864, 14943], [15594, 17876], [18035, 18957], [19045, 19938], [19979, 21787], [21922, 23724], [24227, 25336], [26840, 31093], [31105, 34036]], "num_segments": 11}
{"id": "sakura_emotion_123_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_123_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["happy", "fear", "angry", "disgust"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_123.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[535, 2421], [2674, 4908], [5737, 7928], [8655, 14781], [14890, 19248], [19303, 20105], [20293, 23521], [24799, 26885], [27003, 32801], [33903, 36108], [36778, 40189]], "num_segments": 11}
{"id": "sakura_emotion_121_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_121_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["sad", "disgust", "fear", "happy"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_121.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[302, 1463], [2074, 7469], [7650, 11444], [11658, 15565], [15687, 16942], [16961, 21917], [22680, 23907], [23950, 24859], [25332, 26752], [27189, 28022], [28106, 30267], [31572, 39481], [40282, 42831], [42886, 46062]], "num_segments": 14}
{"id": "sakura_emotion_121_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_121_masked_100pct.wav", "question": "Which of the following sentences would most likely reflect the emotional state of people experiencing the same emotion as the speaker?", "choices": ["I\u2019m really scared about what might happen next.", "This thing looks absolutely gross and dirty; I can\u2019t stand it!", "I feel so empty, like nothing matters anymore.", "I can\u2019t believe this is happening, I\u2019m so furious!"], "answer": "I feel so empty, like nothing matters anymore.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_121.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[762, 2873], [3398, 4296], [4650, 10954], [12976, 20469], [20797, 23929], [24273, 27167], [27529, 29447], [30158, 31995], [32167, 36089], [36378, 40023], [40747, 43533], [43916, 45354]], "num_segments": 12}
{"id": "sakura_emotion_124_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_124_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Reacting to a sudden loud noise in an empty house.", "Seeing an unpleasant image online.", "Laughing at a funny joke in a conversation.", "Attending a close friend's funeral."], "answer": "Reacting to a sudden loud noise in an empty house.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_124.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1121, 2144], [2781, 4515], [5480, 8676], [9273, 10225], [10612, 18200], [19675, 20822], [20983, 22692], [23825, 27255], [27990, 34125], [34178, 36511], [37475, 38460]], "num_segments": 11}
{"id": "sakura_emotion_125_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_125_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Celebrating a birthday with friends and family.", "A parent scolding their child for misbehavior.", "Attending a close friend's funeral.", "Preparing for a high-stakes exam with anxiety."], "answer": "Preparing for a high-stakes exam with anxiety.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_125.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[258, 1184], [1685, 4155], [5091, 6357], [6956, 11316], [11505, 12856], [13276, 14304], [14775, 18987], [19663, 21547], [22370, 24620], [25470, 27333], [28376, 32009], [32423, 33303], [33489, 34485]], "num_segments": 13}
{"id": "sakura_emotion_127_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_127_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["angry", "sad", "disgust", "fear"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_127.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[393, 4218], [4233, 5210], [6130, 9209], [10070, 16599], [16745, 18740], [18852, 20591], [20664, 23172], [23689, 26935], [28446, 29584]], "num_segments": 9}
{"id": "sakura_emotion_123_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_123_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["I\u2019m just so happy I could burst!", "I feel like I\u2019m in danger, and I don\u2019t know what to do.", "This situation is really starting to piss me off!", "This makes me feel sick to my stomach."], "answer": "I feel like I\u2019m in danger, and I don\u2019t know what to do.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_123.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[15, 1242], [2238, 4838], [4947, 5903], [6289, 7154], [7367, 8490], [9010, 11380], [11588, 14406], [14433, 15827], [16212, 19015], [19074, 20035], [20428, 21340], [21692, 22555], [22597, 23515], [23613, 25148], [25876, 27607], [28216, 29418], [29538, 37150], [37744, 39748]], "num_segments": 18}
{"id": "sakura_emotion_126_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_126_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Walking alone in a dark alley at night.", "Hugging a loved one after a long separation.", "Attending a close friend's funeral.", "Rejecting a tasteless meal with a grimace."], "answer": "Attending a close friend's funeral.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_126.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[829, 3050], [3175, 7864], [9380, 11187], [11566, 13967], [14892, 16679], [17145, 18144], [18312, 19293], [19784, 20594], [20995, 21882], [22284, 24019], [24748, 25641], [27172, 31178]], "num_segments": 12}
{"id": "sakura_emotion_126_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_126_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "sad", "disgust", "fear"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_126.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[743, 1705], [2185, 6054], [6700, 7713], [8073, 11596], [11751, 16922], [16985, 18578], [18740, 20429], [21131, 25687], [26516, 28161], [29351, 32069]], "num_segments": 10}
{"id": "sakura_emotion_127_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_127_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Stay calm and provide support to ease their anxiety.", "Express understanding calmly and suggest leaving the unpleasant environment.", "Calmly acknowledge their frustration and suggest a solution.", "Suggest spending some time together to cheer them up."], "answer": "Suggest spending some time together to cheer them up.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_127.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[641, 2198], [2539, 4140], [5207, 6413], [6937, 8718], [9056, 10024], [10252, 11806], [12006, 13166], [13198, 15617], [15675, 18490], [18862, 21840], [22865, 28689], [28970, 30220]], "num_segments": 12}
{"id": "sakura_emotion_129_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_129_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "disgust", "sad", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_129.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[493, 1785], [2162, 3376], [3518, 6500], [7114, 8892], [10302, 12505], [12563, 14340], [15121, 17675], [17782, 19038], [19303, 20233], [20241, 23922], [24040, 24939], [24941, 27770], [28141, 29279]], "num_segments": 13}
{"id": "sakura_emotion_128_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_128_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "disgust", "happy", "sad"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_128.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[622, 2362], [2527, 6545], [7050, 8293], [8679, 10389], [10484, 12425], [13656, 14583], [14858, 22829], [22899, 26920], [26988, 33170], [34196, 35580], [35825, 38214], [40046, 41721], [42425, 43303]], "num_segments": 13}
{"id": "sakura_emotion_131_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_131_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "happy", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_131.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[379, 4036], [4240, 6546], [8051, 9290], [9731, 11596], [12075, 13253], [14307, 18284], [18504, 20099], [20317, 21874], [22125, 23084], [23112, 24774], [25045, 27724], [28051, 31569], [31730, 33013], [33985, 35311]], "num_segments": 14}
{"id": "sakura_emotion_129_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_129_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Seeing an unpleasant image online.", "A person yelling after being cut off in traffic.", "Saying goodbye at an airport.", "Facing an aggressive dog on the street."], "answer": "Facing an aggressive dog on the street.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_129.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[634, 1680], [3658, 5313], [5387, 6201], [6372, 7461], [8116, 9178], [10164, 12409], [12803, 18209], [19147, 26491], [27547, 29283]], "num_segments": 9}
{"id": "sakura_emotion_128_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_128_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Preparing for a high-stakes exam with anxiety.", "Hugging a loved one after a long separation.", "A heated argument between colleagues.", "Rejecting a tasteless meal with a grimace."], "answer": "Rejecting a tasteless meal with a grimace.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_128.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[110, 2007], [3245, 8203], [9027, 10492], [10516, 13625], [14452, 20915], [22505, 23617], [24040, 24936], [25176, 27976], [28551, 29599], [30240, 31795], [33116, 37447], [37447, 38362], [39306, 41925], [42522, 44172]], "num_segments": 14}
{"id": "sakura_emotion_131_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_131_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Reacting to a foul odor in a room.", "A person smiling after receiving good news.", "Reading a heartfelt goodbye letter.", "Preparing for a high-stakes exam with anxiety."], "answer": "Reading a heartfelt goodbye letter.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_131.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[162, 2752], [3073, 4008], [4435, 7360], [8018, 9902], [9910, 11157], [11303, 14796], [15144, 23055], [23672, 25240], [25983, 31041], [31212, 32039], [32463, 33979], [34208, 35909]], "num_segments": 12}
{"id": "sakura_emotion_130_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_130_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "disgust", "happy", "sad"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_130.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[90, 1131], [1996, 2821], [2835, 4276], [4277, 6085], [6422, 7634], [7799, 9634], [9732, 15948], [16606, 19279], [20465, 25742], [25832, 26836], [27056, 29898], [29979, 31441], [32047, 39225], [39334, 40703], [40987, 41807], [42122, 43169]], "num_segments": 16}
{"id": "sakura_emotion_132_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_132_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "disgust", "fear", "sad"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_132.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[759, 6678], [6839, 12319], [13223, 16957], [17708, 18938], [20302, 21372], [21487, 28442], [29524, 31697]], "num_segments": 7}
{"id": "sakura_emotion_133_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_133_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Attending a close friend's funeral.", "Winning a long-anticipated award or prize.", "Slamming a door after a disagreement.", "Reacting to a sudden loud noise in an empty house."], "answer": "Attending a close friend's funeral.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_133.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[36, 3391], [3417, 4520], [4548, 9193], [9441, 11635], [12395, 13209], [13670, 18168], [19121, 25539], [26300, 29027], [29300, 34244], [34247, 35333], [35382, 36410], [37191, 41775], [41837, 43017]], "num_segments": 13}
{"id": "sakura_emotion_130_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_130_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Celebrate their joy with a cheerful response.", "Hold their hand or offer some physical reassurance.", "Calmly acknowledge their frustration and suggest a solution.", "Avoid discussing further and respect their aversion to the topic."], "answer": "Avoid discussing further and respect their aversion to the topic.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_130.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[709, 2429], [2517, 8044], [8928, 13086], [13254, 14322], [14491, 17674], [17698, 18594], [18736, 21567], [21586, 22824], [22917, 28728], [30093, 31218], [31325, 32587], [33151, 34492], [35455, 39904], [40120, 41076], [41202, 42098]], "num_segments": 15}
{"id": "sakura_emotion_133_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_133_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "angry", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_133.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1053, 6710], [6855, 8709], [8763, 10594], [10610, 13841], [14559, 15644], [15692, 17638], [17721, 19038], [19396, 22283], [22620, 23902], [24048, 29169], [29349, 31911], [32335, 34392], [35108, 37863], [38131, 39440], [39521, 41582]], "num_segments": 15}
{"id": "sakura_emotion_135_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_135_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "sad", "fear", "happy"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_135.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[659, 1654], [1925, 5594], [5939, 9439], [11008, 16480], [16482, 17425], [17448, 21203], [21766, 26610], [27887, 28895], [30684, 31535], [32125, 33218], [34559, 37707], [39416, 41984], [42030, 46422]], "num_segments": 13}
{"id": "sakura_emotion_132_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_132_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Avoid discussing further and respect their aversion to the topic.", "Encourage them to take deep breaths to relax.", "Provide emotional support and avoid dismissing their sadness.", "Offer congratulations or compliments to share their happiness."], "answer": "Offer congratulations or compliments to share their happiness.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_132.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[347, 4625], [5121, 9654], [10070, 11214], [11683, 12588], [13363, 14172], [14261, 19851], [19898, 20893], [21114, 24759], [25847, 31332], [31416, 32769]], "num_segments": 10}
{"id": "sakura_emotion_135_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_135_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["Relaxed facial muscles with a cheerful grin", "A wrinkled nose and raised upper lip", "Wrinkled forehead and a forlorn expression", "Head slightly pulled back with a terrified gaze, as if searching for an escape."], "answer": "A wrinkled nose and raised upper lip", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_135.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[339, 1193], [1628, 9604], [10947, 12875], [14769, 16620], [17460, 18519], [18629, 22943], [23022, 24124], [24793, 32782], [33547, 35701], [36863, 43593], [44265, 46655], [47063, 47984]], "num_segments": 12}
{"id": "sakura_emotion_134_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_134_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "angry", "fear", "sad"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_134.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[638, 1623], [2105, 5475], [7536, 9255], [10318, 11300], [11560, 12730], [13423, 17091], [17863, 18812], [18925, 22760], [23691, 25106], [25961, 27251], [28286, 29754], [30210, 32898], [34085, 35651], [36255, 42269], [43264, 50675]], "num_segments": 15}
{"id": "sakura_emotion_134_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_134_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["This situation is really starting to piss me off!", "This makes me feel sick to my stomach.", "I\u2019m really scared about what might happen next.", "I\u2019m just so happy I could burst!"], "answer": "This situation is really starting to piss me off!", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_134.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[325, 3375], [4466, 5536], [6546, 9793], [9905, 12506], [13939, 16464], [17833, 20440], [21411, 23505], [24456, 25359], [27098, 30021], [31372, 38911], [40441, 42010], [42961, 48758], [48962, 50089]], "num_segments": 13}
{"id": "sakura_emotion_137_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_137_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "happy", "sad", "fear"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_137.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1075, 4175], [4556, 9503], [10207, 15436], [16028, 17972], [19109, 20442], [20862, 22669], [24010, 27352], [27647, 28654], [29347, 30175], [30201, 31213], [31812, 33571], [34536, 36473], [37689, 39050], [40033, 42323], [42375, 50051], [50281, 51895], [52219, 54296]], "num_segments": 17}
{"id": "sakura_emotion_136_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_136_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "happy", "sad", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_136.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1493, 7189], [8338, 14177], [14666, 15594], [16610, 18706], [19035, 20039], [21214, 24792], [25075, 29508], [30074, 33458], [33466, 34605], [34836, 37415], [38064, 39587]], "num_segments": 11}
{"id": "sakura_emotion_139_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_139_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "sad", "happy", "angry"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_139.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1084, 1987], [2690, 3669], [3883, 6916], [7864, 9150], [9434, 11775], [11885, 12821], [12870, 14393], [15170, 16406], [16672, 18026], [18647, 19787], [19938, 23428], [23849, 24821], [24888, 28620], [28689, 29585], [30219, 31412]], "num_segments": 15}
{"id": "sakura_emotion_136_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_136_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["This makes me feel sick to my stomach.", "I\u2019m just so happy I could burst!", "I can\u2019t shake the feeling that something bad is coming.", "Stop making excuses; this is entirely your fault!"], "answer": "Stop making excuses; this is entirely your fault!", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_136.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[108, 5479], [5949, 12774], [13818, 15012], [15817, 16801], [17534, 20508], [21960, 27200], [27410, 28721], [28775, 31289], [31346, 32178], [33292, 37169], [37815, 39428]], "num_segments": 11}
{"id": "sakura_emotion_138_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_138_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["sad", "disgust", "angry", "happy"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_138.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1048, 2115], [3408, 6311], [6746, 8084], [8215, 10221], [10773, 13943], [14895, 16459], [16654, 20851], [20853, 23503], [23985, 25147], [25771, 27192], [27257, 34112], [35836, 42241], [43002, 45627]], "num_segments": 13}
{"id": "sakura_emotion_140_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_140_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["disgust", "sad", "fear", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_140.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[974, 3685], [3853, 5894], [5959, 7300], [7554, 10464], [10998, 12018], [12130, 14255], [15257, 17468], [17737, 22649], [23641, 24718], [24815, 25654], [25913, 26969], [27340, 29826]], "num_segments": 12}
{"id": "sakura_emotion_137_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_137_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Celebrate their joy with a cheerful response.", "Apologize and admit your mistake, if appropriate.", "Hold their hand or offer some physical reassurance.", "Express understanding calmly and suggest leaving the unpleasant environment."], "answer": "Express understanding calmly and suggest leaving the unpleasant environment.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_137.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[922, 2759], [3385, 5756], [5980, 6812], [7082, 13846], [14808, 17958], [18494, 19879], [20033, 21391], [22205, 23679], [23837, 27681], [28283, 29519], [30304, 35467], [35843, 36922], [37053, 38008], [38319, 46193], [47057, 48291], [48778, 53574], [53617, 54541]], "num_segments": 17}
{"id": "sakura_emotion_139_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_139_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["I\u2019m feeling so down, like nothing can lift my spirits.", "How dare they treat me so unfairly like this!", "I can\u2019t even look at this without feeling uncomfortable.", "I\u2019m so excited, I just can\u2019t contain my happiness!"], "answer": "I can\u2019t even look at this without feeling uncomfortable.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_139.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[50, 1072], [2094, 8018], [8850, 9702], [10078, 11097], [12283, 15036], [16236, 17505], [17689, 18719], [18728, 21301], [21569, 22679], [23485, 25055], [25199, 26888], [26995, 27873], [29097, 30049], [30077, 31329]], "num_segments": 14}
{"id": "sakura_emotion_138_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_138_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Clenched teeth with side facial muscles showing tension.", "Wide-open eyes with raised eyebrows and slightly parted lips.", "Wrinkled forehead and a forlorn expression", "Eyes crinkling with an open-mouthed laugh"], "answer": "Wrinkled forehead and a forlorn expression", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_138.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[547, 1629], [2221, 3897], [4162, 5439], [6282, 9541], [9856, 11805], [11956, 12816], [13455, 18680], [18720, 21183], [21416, 22363], [23901, 27517], [28695, 34714], [34846, 35903], [36741, 41466], [42441, 45177], [45205, 46130]], "num_segments": 15}
{"id": "sakura_emotion_140_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_140_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Listen empathetically and let them express their feelings.", "Offer congratulations or compliments to share their happiness.", "Offer reassurance and remind them they are safe.", "Give them space to cool off before engaging further."], "answer": "Offer congratulations or compliments to share their happiness.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_140.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[900, 3260], [3845, 5563], [6706, 9120], [9476, 16997], [17640, 19379], [19526, 21938], [22613, 29668]], "num_segments": 7}
{"id": "sakura_emotion_142_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_142_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["disgust", "fear", "happy", "sad"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_142.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[655, 3465], [3935, 5027], [5194, 7986], [8471, 9374], [9982, 11979], [12274, 13167], [13703, 18077], [18296, 25080], [25713, 31729], [32649, 34421]], "num_segments": 10}
{"id": "sakura_emotion_141_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_141_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["I just can\u2019t stop thinking about all those bad memories.", "I\u2019ve had enough of this nonsense.", "I can\u2019t stop smiling, everything feels so right.", "I feel like I\u2019m in danger, and I don\u2019t know what to do."], "answer": "I\u2019ve had enough of this nonsense.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_141.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[628, 3047], [4283, 5517], [6561, 7387], [7470, 10013], [10203, 12118], [12217, 13040], [14030, 19899], [19970, 21826], [22211, 23748], [23934, 24819], [24988, 31525], [31834, 33801], [34044, 35262], [35474, 41736]], "num_segments": 14}
{"id": "sakura_emotion_141_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_141_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "disgust", "angry", "fear"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_141.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[29, 1174], [2069, 8120], [8599, 9925], [10720, 17233], [19089, 21321], [22753, 24536], [25617, 30290], [30592, 33413], [33627, 38787], [39523, 41045], [41491, 42692]], "num_segments": 11}
{"id": "sakura_emotion_144_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_144_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["disgust", "angry", "fear", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_144.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1084, 8848], [9258, 11812], [12426, 13270], [13316, 15925], [17232, 24777], [25683, 27654], [27694, 28501], [28581, 29399], [29500, 31993]], "num_segments": 9}
{"id": "sakura_emotion_144_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_144_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["This makes me feel sick to my stomach.", "I just can\u2019t stop thinking about all those bad memories.", "I feel so grateful and full of joy right now.", "I feel like I\u2019m in danger, and I don\u2019t know what to do."], "answer": "I feel so grateful and full of joy right now.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_144.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[364, 7302], [8304, 9829], [10820, 12110], [12600, 16318], [17827, 18756], [18812, 25639], [25658, 26542], [27165, 28011], [28904, 29712], [29854, 31973]], "num_segments": 10}
{"id": "sakura_emotion_142_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_142_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Offer congratulations or compliments to share their happiness.", "Calmly acknowledge their frustration and suggest a solution.", "Avoid discussing further and respect their aversion to the topic.", "Offer reassurance and remind them they are safe."], "answer": "Offer congratulations or compliments to share their happiness.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_142.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[27, 2675], [2705, 8742], [9262, 15090], [15140, 16248], [16866, 18450], [19139, 21687], [22859, 25105], [25148, 26176], [26438, 33520], [33546, 35053]], "num_segments": 10}
{"id": "sakura_emotion_145_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_145_masked_100pct.wav", "question": "Which facial expression best matches the emotion in the audio?", "choices": ["Relaxed facial muscles with a cheerful grin", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "Wrinkled forehead and a forlorn expression", "Furrowed brows with slightly open mouth, as if about to shout."], "answer": "Retracted chin with one corner of the mouth twitching, as if intolerable.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_145.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[244, 2969], [3686, 7717], [8047, 12545], [13542, 14354], [14392, 16522], [17074, 21058], [21363, 23126], [23802, 30401], [32329, 37894], [38100, 41897]], "num_segments": 10}
{"id": "sakura_emotion_146_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_146_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "happy", "angry", "disgust"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_146.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[232, 1612], [1807, 3811], [4067, 6399], [7887, 11299], [11868, 13570], [13964, 16422], [17041, 22891], [23820, 25827], [26740, 27967]], "num_segments": 9}
{"id": "sakura_emotion_143_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_143_masked_100pct.wav", "question": "Which facial expression best fits the emotion heard in the audio?", "choices": ["Wrinkled forehead and a forlorn expression", "Eyes crinkling with an open-mouthed laugh", "Frozen facial expression with trembling lips and quickened breathing.", "Averted gaze with a grimacing mouth"], "answer": "Frozen facial expression with trembling lips and quickened breathing.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_143.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[251, 1650], [2539, 8728], [10517, 11517], [12581, 16608], [16801, 18051], [18955, 20552], [20571, 21411], [21536, 25632], [27053, 31334], [31344, 32551]], "num_segments": 10}
{"id": "sakura_emotion_143_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_143_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "sad", "happy", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_143.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[17, 1936], [1960, 4514], [5478, 13278], [13415, 14599], [14737, 22711], [23072, 23872], [23921, 25021], [25953, 32219]], "num_segments": 8}
{"id": "sakura_emotion_145_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_145_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "disgust", "fear", "angry"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_145.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[300, 1904], [1938, 3418], [4729, 6145], [6943, 7786], [8830, 11193], [12181, 17781], [18937, 19751], [19895, 21144], [21380, 23663], [23793, 25206], [26572, 29750], [30388, 32342], [32464, 33348], [33884, 37754], [37870, 41132], [41340, 42217]], "num_segments": 16}
{"id": "sakura_emotion_146_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_146_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Express genuine excitement for their good news or achievement.", "Hold their hand or offer some physical reassurance.", "Express understanding calmly and suggest leaving the unpleasant environment.", "Calmly acknowledge their frustration and suggest a solution."], "answer": "Express genuine excitement for their good news or achievement.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_146.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[292, 2218], [2372, 4295], [4296, 5985], [6171, 14008], [14675, 15929], [17179, 18656], [18719, 24271], [24605, 25742], [25809, 27123]], "num_segments": 9}
{"id": "sakura_emotion_147_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_147_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "angry", "fear", "disgust"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_147.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[75, 4485], [5150, 7499], [7534, 9001], [9093, 11814], [11951, 14622], [14933, 15822], [16805, 23750], [24392, 27362], [27459, 29691], [30009, 33375]], "num_segments": 10}
{"id": "sakura_emotion_147_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_147_masked_100pct.wav", "question": "Which situation best corresponds to the emotion conveyed in the speech?", "choices": ["A person crying after a breakup.", "A heated argument between colleagues.", "Celebrating a birthday with friends and family.", "Reacting to a foul odor in a room."], "answer": "A person crying after a breakup.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_147.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[302, 2715], [2848, 7416], [8114, 8946], [8973, 10165], [10224, 15000], [15378, 16535], [16799, 18445], [19527, 22988], [23173, 24946], [25075, 30909], [31447, 33538]], "num_segments": 11}
{"id": "sakura_emotion_148_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_148_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Celebrating a birthday with friends and family.", "A person crying after a breakup.", "Rejecting a tasteless meal with a grimace.", "Reacting to a sudden loud noise in an empty house."], "answer": "Reacting to a sudden loud noise in an empty house.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_148.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[50, 1360], [2088, 8209], [9209, 16958], [17067, 18078], [18164, 19672], [19686, 20775], [20895, 22118], [23283, 27445], [28276, 29200], [29278, 30216], [30719, 32394], [33006, 34726], [34969, 36034]], "num_segments": 13}
{"id": "sakura_emotion_148_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_148_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "happy", "sad", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_148.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[88, 1996], [2016, 5246], [5472, 7862], [9230, 10232], [11057, 14459], [14904, 16439], [16563, 18486], [18711, 19968], [20617, 23398], [23978, 26154], [26421, 29827], [30349, 31630], [31867, 32804], [33003, 35680]], "num_segments": 14}
{"id": "sakura_emotion_149_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_149_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["angry", "fear", "sad", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_149.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[315, 1374], [1773, 6995], [7003, 9483], [9649, 11581], [12460, 18292], [18669, 20859], [20970, 22544], [22936, 29653], [30013, 31287], [31450, 34321], [34448, 38045], [38071, 40459], [40667, 41808], [42074, 42943]], "num_segments": 14}
{"id": "sakura_emotion_149_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_149_masked_100pct.wav", "question": "What facial expression most aligns with the emotion in the recording?", "choices": ["Averted gaze with a grimacing mouth", "A sharp, piercing gaze and compressed lips", "A broad smile with sparkling eyes", "Eyes gazing downward with trembling lips"], "answer": "A broad smile with sparkling eyes", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_149.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[381, 1750], [2155, 8240], [9195, 10243], [10862, 12689], [13507, 16191], [17122, 18117], [18228, 20068], [21947, 26973], [27382, 29855], [30201, 31300], [31436, 37881], [39463, 40395], [41241, 42757]], "num_segments": 13}
{"id": "sakura_emotion_150_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_150_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["Watching a touching but sorrowful movie scene.", "A heated argument between colleagues.", "Facing an aggressive dog on the street.", "Laughing at a funny joke in a conversation."], "answer": "Laughing at a funny joke in a conversation.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_150.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[180, 5591], [6948, 8434], [8783, 9969], [11031, 14095], [14511, 20591], [20718, 21566], [21779, 23122], [23347, 29186]], "num_segments": 8}
{"id": "sakura_emotion_150_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_150_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "happy", "fear", "angry"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_150.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[142, 5113], [5750, 7365], [7382, 9757], [9968, 10903], [12057, 12865], [14304, 15761], [16844, 17803], [17871, 23399], [24864, 29220], [29258, 30413]], "num_segments": 10}
{"id": "sakura_emotion_152_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_152_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "happy", "angry", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_152.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[716, 1676], [3193, 4819], [5235, 6301], [7788, 9653], [10958, 17008], [17387, 18578], [19037, 24082], [24432, 25782], [26349, 28254], [28950, 31390], [31779, 32631], [32961, 34264], [34833, 37029], [38020, 39437], [39653, 41188], [41419, 46505], [46671, 47979]], "num_segments": 17}
{"id": "sakura_emotion_152_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_152_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["A heavy sigh with a frown and slumped posture", "Raised eyebrows with a scowl", "Squinted eyes and a pinched nose", "Tightly furrowed brow with trembling lips"], "answer": "A heavy sigh with a frown and slumped posture", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_152.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[300, 3450], [4045, 5159], [5209, 8885], [9322, 12090], [12106, 15853], [17081, 19564], [20137, 21340], [21961, 25177], [25713, 31954], [32982, 36426], [36654, 39306], [39457, 41036], [41748, 46214], [46455, 47739]], "num_segments": 14}
{"id": "sakura_emotion_153_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_153_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Offer congratulations or compliments to share their happiness.", "Hold their hand or offer some physical reassurance.", "Reassure them and offer a way to move past the uncomfortable    situation.", "Give them space to cool off before engaging further."], "answer": "Offer congratulations or compliments to share their happiness.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_153.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[793, 2053], [2835, 7208], [8195, 10017], [10449, 11648], [12262, 17833], [19094, 23324], [23581, 26395], [27346, 30333], [30649, 31823], [31973, 34132], [35033, 37891], [38311, 40080], [40711, 42113]], "num_segments": 13}
{"id": "sakura_emotion_153_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_153_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "angry", "sad", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_153.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[44, 1322], [1363, 4965], [5772, 9583], [10143, 11284], [11769, 12783], [13665, 19560], [20228, 21045], [22632, 29494], [29738, 36235], [36987, 39072], [39132, 40231], [40240, 42000]], "num_segments": 12}
{"id": "sakura_emotion_154_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_154_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["sad", "angry", "disgust", "fear"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_154.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[899, 2935], [3647, 5017], [6343, 8779], [9774, 11831], [12957, 14035], [14120, 16581], [17010, 21563], [21650, 22580], [23106, 24153], [24666, 29835], [30042, 31138], [31174, 36777], [38141, 39641], [40213, 41192], [42396, 44531], [44965, 46094], [46250, 48807], [48998, 51364]], "num_segments": 18}
{"id": "sakura_emotion_151_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_151_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["A person crying after a breakup.", "A heated argument between colleagues.", "Hearing a shocking and offensive statement.", "Celebrating a birthday with friends and family."], "answer": "A heated argument between colleagues.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_151.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[661, 1865], [2386, 9103], [9668, 11478], [11653, 12713], [13765, 20886], [21258, 28049], [28245, 29108], [30005, 31325], [32551, 34593], [34981, 36312], [36590, 37441], [37974, 45945], [46024, 47589], [48139, 49451]], "num_segments": 14}
{"id": "sakura_emotion_151_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_151_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "angry", "sad", "fear"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_151.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[864, 1732], [2017, 3704], [3849, 4722], [5140, 6554], [7024, 9368], [9636, 11990], [12487, 14415], [14528, 15753], [16170, 18772], [20588, 25183], [26646, 29505], [30299, 31281], [32440, 34575], [35149, 36500], [36753, 43367], [43866, 45247], [45617, 46804], [46854, 47698], [48450, 49561]], "num_segments": 19}
{"id": "sakura_emotion_155_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_155_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["happy", "fear", "disgust", "angry"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_155.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[807, 4428], [4491, 5778], [6084, 6982], [7701, 10356], [10815, 12077], [12213, 15006], [15118, 17967], [18028, 25655], [26433, 27525], [27839, 28757], [28978, 36417], [36629, 37429]], "num_segments": 12}
{"id": "sakura_emotion_154_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_154_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Listen empathetically and let them express their feelings.", "Reassure them and offer a way to move past the uncomfortable    situation.", "Smile and engage positively in the conversation.", "Give them space to cool off before engaging further."], "answer": "Listen empathetically and let them express their feelings.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_154.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[604, 2701], [2780, 4563], [6070, 8039], [8396, 9205], [9212, 10373], [11169, 15959], [16767, 21457], [22383, 23762], [23849, 27641], [28017, 34594], [36137, 41983], [42860, 43746], [44930, 49200], [50410, 51371]], "num_segments": 14}
{"id": "sakura_emotion_155_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_155_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Calmly acknowledge their frustration and suggest a solution.", "Suggest an activity to keep the positive energy flowing.", "Stay calm and provide support to ease their anxiety.", "Reassure them and offer a way to move past the uncomfortable    situation."], "answer": "Suggest an activity to keep the positive energy flowing.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_155.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[404, 3672], [3849, 9952], [11101, 12091], [13220, 20235], [20275, 21236], [21851, 25329], [25418, 32716], [33657, 36805]], "num_segments": 8}
{"id": "sakura_emotion_156_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_156_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "fear", "angry", "sad"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_156.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1076, 5776], [5923, 10463], [10728, 12554], [13067, 16908], [17097, 18111], [20310, 21707], [22440, 27719], [27807, 28978], [29050, 32877], [33214, 36051], [37725, 38623], [38803, 39686], [39870, 45240], [45952, 46863], [47109, 49557], [50140, 51516]], "num_segments": 16}
{"id": "sakura_emotion_156_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_156_masked_100pct.wav", "question": "What facial expression most aligns with the emotion in the recording?", "choices": ["A warm, genuine smile with slightly tilted head", "Tightly furrowed brow with trembling lips", "A heavy sigh with a frown and slumped posture", "Furrowed brows with slightly open mouth, as if about to shout."], "answer": "A warm, genuine smile with slightly tilted head", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_156.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[852, 1972], [2096, 4518], [4900, 5924], [6412, 7604], [9254, 12814], [13941, 16560], [17913, 20891], [21202, 22538], [23316, 24593], [26019, 27277], [28027, 29259], [30477, 34851], [35637, 40976], [41598, 43568], [44042, 47885], [49264, 50811]], "num_segments": 16}
{"id": "sakura_emotion_158_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_158_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["Reacting to a sudden loud noise in an empty house.", "Celebrating a birthday with friends and family.", "A heated argument between colleagues.", "Reading a heartfelt goodbye letter."], "answer": "Reacting to a sudden loud noise in an empty house.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_158.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[476, 3523], [4269, 5701], [6120, 9298], [10211, 16197], [16200, 17432], [17824, 20386], [21230, 22408], [22472, 23279], [23564, 29855], [30724, 33938], [33944, 35989], [37192, 40338], [40434, 42541]], "num_segments": 13}
{"id": "sakura_emotion_158_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_158_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["fear", "happy", "sad", "disgust"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_158.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[671, 5325], [5597, 7231], [7842, 9664], [10105, 10953], [11153, 15945], [16946, 24307], [24315, 25343], [25747, 29436], [30272, 35992], [36472, 37574], [37881, 39957], [40307, 42447]], "num_segments": 12}
{"id": "sakura_emotion_157_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_157_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "disgust", "sad", "fear"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_157.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1073, 2302], [3171, 9657], [9866, 11486], [12306, 13945], [14653, 21595], [22086, 25134], [25145, 27221], [27444, 28481]], "num_segments": 8}
{"id": "sakura_emotion_159_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_159_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["sad", "angry", "happy", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_159.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1410, 2815], [3028, 3877], [4108, 6131], [6580, 10032], [10318, 11365], [11400, 12420], [12691, 14104], [14389, 15549], [15931, 19703], [20491, 25805], [25942, 26815], [28185, 31998], [32219, 33163], [33505, 35510], [35681, 36526], [37022, 38436], [38445, 39256], [40679, 46989], [47068, 48447]], "num_segments": 19}
{"id": "sakura_emotion_157_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_157_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Offer a comforting hug or words of reassurance.", "Smile and engage positively in the conversation.", "Stay calm and provide support to ease their anxiety.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable."], "answer": "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_157.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1360, 3556], [3603, 4894], [5094, 10027], [10076, 11470], [11566, 12415], [12518, 19534], [19599, 21347], [21927, 24347], [24488, 25858], [26605, 28789]], "num_segments": 10}
{"id": "sakura_emotion_160_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_160_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["fear", "sad", "disgust", "happy"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_160.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[20, 1639], [1895, 2897], [3050, 8668], [8676, 10124], [10563, 17618], [18502, 19405], [20740, 24588], [25706, 29229]], "num_segments": 8}
{"id": "sakura_emotion_159_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_159_masked_100pct.wav", "question": "Which of the following sentences would most likely reflect the emotional state of people experiencing the same emotion as the speaker?", "choices": ["This makes me feel sick to my stomach.", "I\u2019m so excited, I just can\u2019t contain my happiness!", "I feel like I\u2019m in danger, and I don\u2019t know what to do.", "This situation is really starting to piss me off!"], "answer": "I feel like I\u2019m in danger, and I don\u2019t know what to do.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_159.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[660, 3107], [3783, 4803], [5526, 7380], [7449, 13296], [14352, 15185], [15921, 22778], [22985, 26533], [27691, 28682], [30089, 33376], [33803, 40205], [41423, 42383], [43382, 44199], [44373, 45714], [46096, 47759]], "num_segments": 14}
{"id": "sakura_emotion_162_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_162_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Give them space to cool off before engaging further.", "Provide emotional support and avoid dismissing their sadness.", "Reassure them and offer a way to move past the uncomfortable    situation.", "Express genuine excitement for their good news or achievement."], "answer": "Reassure them and offer a way to move past the uncomfortable    situation.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_162.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[117, 1871], [2270, 3084], [3108, 4116], [4366, 7421], [8341, 15475], [15988, 17766], [19054, 21150], [21990, 23168], [23596, 27340], [28430, 29943], [30186, 32787], [32983, 34999], [35282, 36420], [36559, 38012], [38277, 40226], [40343, 41752], [42108, 45733]], "num_segments": 17}
{"id": "sakura_emotion_161_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_161_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["sad", "fear", "angry", "happy"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_161.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1166, 7835], [9822, 13942], [14113, 15014], [15538, 20464], [21193, 25117], [26753, 30483], [31421, 32701], [32701, 33573], [34814, 38836]], "num_segments": 9}
{"id": "sakura_emotion_160_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_160_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["It\u2019s so dirty! Please clean it as quick as possible.", "I\u2019m feeling so down, like nothing can lift my spirits.", "I can\u2019t breathe, I\u2019m just so afraid right now.", "Stop making excuses; this is entirely your fault!"], "answer": "I\u2019m feeling so down, like nothing can lift my spirits.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_160.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1123, 3884], [4001, 5145], [6576, 7708], [7904, 9014], [9163, 11286], [11388, 12304], [12314, 13755], [14007, 18460], [19556, 20675], [21492, 23214], [23589, 25792], [26675, 28783]], "num_segments": 12}
{"id": "sakura_emotion_162_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_162_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "fear", "happy", "sad"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_162.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[984, 8864], [9024, 13591], [14344, 16655], [17189, 18182], [18431, 19618], [19787, 21770], [22477, 24532], [24704, 25583], [25760, 32102], [32581, 34373], [34866, 37635], [37908, 44882]], "num_segments": 12}
{"id": "sakura_emotion_161_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_161_masked_100pct.wav", "question": "What facial expression most aligns with the emotion in the recording?", "choices": ["Wrinkled forehead and a forlorn expression", "Raised eyebrows with a scowl", "Squinted eyes and a pinched nose", "A radiant expression with raised cheeks"], "answer": "Raised eyebrows with a scowl", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_161.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1436, 2276], [3028, 4995], [5669, 13655], [13932, 17702], [18105, 19294], [20037, 22008], [22020, 23114], [23595, 24684], [25300, 27704], [27808, 29252], [30881, 33092], [35334, 37246], [37574, 38567]], "num_segments": 13}
{"id": "sakura_emotion_163_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_163_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Hearing a shocking and offensive statement.", "Reacting to a sudden loud noise in an empty house.", "Throwing an object in frustration.", "Watching a touching but sorrowful movie scene."], "answer": "Reacting to a sudden loud noise in an empty house.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_163.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1429, 4099], [5488, 6671], [8399, 14557], [14670, 15481], [15566, 16539], [16748, 17903], [18072, 19299], [19598, 20756], [21709, 23008], [23780, 25024], [25676, 31973], [32635, 33480], [33870, 35661], [36399, 37791], [37885, 41245]], "num_segments": 15}
{"id": "sakura_emotion_164_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_164_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["sad", "fear", "disgust", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_164.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[381, 1707], [2340, 3913], [4520, 5419], [5790, 6949], [7474, 10351], [11020, 12086], [12097, 14331], [14877, 18575], [19500, 20587], [21479, 24281], [25273, 26680], [26936, 28498]], "num_segments": 12}
{"id": "sakura_emotion_163_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_163_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "fear", "angry", "disgust"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_163.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[738, 2765], [3154, 4086], [4112, 5251], [5988, 11513], [13039, 14624], [14910, 15875], [16114, 17113], [17302, 24883], [25902, 30772], [31986, 35404], [36536, 37661], [38276, 39290], [39299, 41355]], "num_segments": 13}
{"id": "sakura_emotion_164_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_164_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["Furrowed brows with slightly open mouth, as if about to shout.", "Wide-open eyes with raised eyebrows and slightly parted lips.", "Squinted eyes and a pinched nose", "A radiant expression with raised cheeks"], "answer": "A radiant expression with raised cheeks", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_164.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[99, 1082], [1410, 3166], [4618, 6316], [6655, 13331], [13466, 19518], [19594, 21404], [22010, 26463], [26488, 27627], [27748, 28593]], "num_segments": 9}
{"id": "sakura_emotion_166_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_166_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "happy", "angry", "sad"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_166.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[66, 3300], [3735, 5888], [6146, 10308], [10997, 17522], [18009, 24563], [25337, 26562], [27452, 28726], [28868, 30520], [31289, 32232]], "num_segments": 9}
{"id": "sakura_emotion_165_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_165_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "sad", "angry", "fear"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_165.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[371, 1734], [2364, 3324], [3837, 4691], [4861, 6077], [6210, 7190], [8019, 9324], [9465, 15069], [15121, 15954], [16696, 17751], [18048, 23234], [23490, 24347], [24612, 26412], [27115, 28170], [28178, 31297], [31318, 32190]], "num_segments": 15}
{"id": "sakura_emotion_167_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_167_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "disgust", "happy", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_167.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1236, 3695], [4631, 6463], [7350, 9441], [10153, 13209], [13277, 14525], [15118, 17921], [18454, 19729], [20717, 21624], [22227, 27840], [27882, 28684], [29482, 31410], [31765, 32980], [34318, 35597], [36461, 38436]], "num_segments": 14}
{"id": "sakura_emotion_166_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_166_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["How dare they treat me so unfairly like this!", "I\u2019m really scared about what might happen next.", "I\u2019m so excited, I just can\u2019t contain my happiness!", "I just can\u2019t stop thinking about all those bad memories."], "answer": "I\u2019m so excited, I just can\u2019t contain my happiness!", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_166.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[36, 988], [1512, 2351], [2625, 7862], [8428, 9261], [9264, 10491], [10518, 12920], [13199, 18041], [18472, 21416], [21592, 23008], [23054, 24337], [24496, 25420], [25836, 26892], [26945, 28185], [28444, 31827]], "num_segments": 14}
{"id": "sakura_emotion_168_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_168_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Suggest an activity to keep the positive energy flowing.", "Express understanding calmly and suggest leaving the unpleasant environment.", "Listen attentively without interrupting to let them vent.", "Suggest spending some time together to cheer them up."], "answer": "Suggest an activity to keep the positive energy flowing.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_168.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[779, 3619], [3972, 4820], [4997, 11901], [12351, 15215], [15284, 16152], [16400, 19121], [19297, 22705], [24232, 28676], [28793, 32972], [33902, 34776], [35840, 37173], [37178, 38956], [39080, 42712]], "num_segments": 13}
{"id": "sakura_emotion_168_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_168_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "disgust", "fear", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_168.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[0, 843], [1656, 2712], [3907, 6175], [6271, 10617], [10732, 11593], [12023, 19621], [20169, 23762], [24534, 25684], [26216, 29636], [29996, 31739], [32631, 35909], [35970, 37829], [37836, 39565], [39681, 43113]], "num_segments": 14}
{"id": "sakura_emotion_169_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_169_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["A parent scolding their child for misbehavior.", "Watching a horror movie alone in the dark.", "Watching a touching but sorrowful movie scene.", "Seeing an unpleasant image online."], "answer": "A parent scolding their child for misbehavior.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_169.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1048, 5012], [5821, 7167], [7925, 10704], [11639, 15513], [15880, 18013], [19093, 20855], [20942, 26668], [26733, 31323], [31375, 32929], [33461, 36891], [37123, 38169], [38382, 39763], [40352, 47781]], "num_segments": 13}
{"id": "sakura_emotion_165_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_165_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["That\u2019s just revolting, I can\u2019t believe it.", "Stop making excuses; this is entirely your fault!", "I\u2019m feeling so down, like nothing can lift my spirits.", "I can\u2019t breathe, I\u2019m just so afraid right now."], "answer": "Stop making excuses; this is entirely your fault!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_165.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[263, 1560], [2189, 3394], [3404, 11276], [11849, 18061], [18998, 22886], [23496, 26508], [27344, 28998], [29186, 30038], [30355, 31702]], "num_segments": 9}
{"id": "sakura_emotion_169_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_169_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["disgust", "fear", "angry", "happy"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_169.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[337, 1279], [2817, 4256], [4897, 8503], [8963, 15255], [16419, 17983], [19021, 21820], [22718, 25155], [25156, 26095], [26814, 28600], [29877, 31471], [31867, 33196], [33367, 39752], [39851, 42159], [42258, 45308], [45639, 47268]], "num_segments": 15}
{"id": "sakura_emotion_167_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_167_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Watching a touching but sorrowful movie scene.", "A person yelling after being cut off in traffic.", "Facing an aggressive dog on the street.", "Laughing at a funny joke in a conversation."], "answer": "Facing an aggressive dog on the street.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_167.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[319, 1170], [1370, 3543], [3574, 4483], [4863, 5923], [5930, 11695], [12019, 14947], [15677, 17887], [17945, 23998], [25663, 26649], [27380, 33782], [34997, 38049]], "num_segments": 11}
{"id": "sakura_emotion_170_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_170_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["I feel so grateful and full of joy right now.", "Stop making excuses; this is entirely your fault!", "I can\u2019t even look at this without feeling uncomfortable.", "I\u2019m feeling so down, like nothing can lift my spirits."], "answer": "Stop making excuses; this is entirely your fault!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_170.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[620, 1834], [2662, 7439], [7576, 10164], [10342, 11595], [12371, 13261], [13769, 16172], [16714, 17770], [17776, 18830], [18954, 25759], [25924, 27542], [28165, 32289], [32496, 33573], [34752, 36364], [36465, 37832]], "num_segments": 14}
{"id": "sakura_emotion_171_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_171_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["happy", "angry", "fear", "disgust"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_171.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[812, 1647], [1837, 3142], [3546, 10914], [11032, 17420], [17552, 18690], [18728, 20144], [20251, 28076], [28827, 30336]], "num_segments": 8}
{"id": "sakura_emotion_170_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_170_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["sad", "angry", "disgust", "fear"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_170.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[704, 1764], [1770, 3001], [3264, 9191], [10461, 13388], [13721, 14683], [15900, 20943], [21396, 22324], [22473, 25172], [25333, 32160], [33498, 34741], [35082, 37111]], "num_segments": 11}
{"id": "sakura_emotion_171_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_171_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I don\u2019t know how to move on from this loss.", "I can\u2019t shake the feeling that something bad is coming.", "This is the best day ever, I feel on top of the world!", "This situation is really starting to piss me off!"], "answer": "This is the best day ever, I feel on top of the world!", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_171.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[375, 1178], [1361, 2681], [3548, 4508], [5249, 8956], [9179, 10730], [11346, 14178], [14533, 17754], [18169, 19146], [19488, 25423], [26033, 27492], [27555, 28557], [29362, 31412]], "num_segments": 12}
{"id": "sakura_emotion_172_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_172_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "sad", "happy", "angry"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_172.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[325, 5260], [5731, 8337], [8696, 11482], [11534, 12680], [12757, 14611], [15266, 22381], [23193, 25570], [25610, 27406], [27409, 31394], [31844, 33544], [33792, 34649], [35150, 35996]], "num_segments": 12}
{"id": "sakura_emotion_173_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_173_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "sad", "fear", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_173.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[415, 2231], [3153, 5942], [6955, 8072], [8380, 9922], [10278, 11102], [11540, 12615], [12849, 14990], [15502, 16769], [17093, 20275], [20968, 22040], [22504, 24003], [24186, 28778], [29365, 33249], [33578, 36036], [36491, 37768]], "num_segments": 15}
{"id": "sakura_emotion_173_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_173_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["A person yelling after being cut off in traffic.", "Winning a long-anticipated award or prize.", "Reacting to a foul odor in a room.", "Reacting to a sudden loud noise in an empty house."], "answer": "A person yelling after being cut off in traffic.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_173.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[757, 5458], [5878, 7173], [8091, 13291], [13294, 14378], [15392, 21398], [21439, 24746], [25190, 27495], [27960, 29226], [30088, 32848], [33211, 34128], [34487, 36323], [36977, 37812]], "num_segments": 12}
{"id": "sakura_emotion_172_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_172_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Provide emotional support and avoid dismissing their sadness.", "Offer reassurance and remind them they are safe.", "Apologize and admit your mistake, if appropriate."], "answer": "Provide emotional support and avoid dismissing their sadness.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_172.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1140, 4521], [4858, 6190], [6452, 10809], [11874, 16983], [17316, 20494], [20973, 23395], [23641, 26109], [26629, 28770], [29932, 35694]], "num_segments": 9}
{"id": "sakura_emotion_174_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_174_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["A heavy sigh with a frown and slumped posture", "Relaxed facial muscles with a cheerful grin", "Raised eyebrows with a scowl", "Head slightly pulled back with a terrified gaze, as if searching for an escape."], "answer": "Raised eyebrows with a scowl", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_174.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[371, 2033], [2138, 3228], [3327, 4848], [5405, 6281], [6532, 7726], [8131, 11014], [11097, 12564], [13159, 16073], [16758, 23742], [24310, 25299], [25651, 27316], [27520, 34990], [35429, 36404]], "num_segments": 13}
{"id": "sakura_emotion_174_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_174_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "angry", "disgust", "fear"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_174.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1015, 2078], [2722, 6631], [7342, 9180], [9725, 10588], [10841, 12784], [13360, 14599], [14699, 16421], [17134, 17952], [18643, 21404], [21778, 23729], [23742, 26288], [26535, 27520], [27694, 29358], [29417, 30667], [30842, 33235], [34088, 36089]], "num_segments": 16}
{"id": "sakura_emotion_177_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_177_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "fear", "disgust", "angry"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_177.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[538, 1926], [2060, 3611], [3858, 4772], [4878, 6516], [6750, 9556], [9767, 10915], [10974, 14297], [14768, 16641], [17009, 18282], [18479, 21904], [22196, 29892], [30366, 34799], [35336, 36242]], "num_segments": 13}
{"id": "sakura_emotion_176_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_176_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["sad", "angry", "happy", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_176.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[764, 4065], [5628, 6866], [7006, 9488], [9890, 11950], [12301, 14216], [14324, 17718], [18620, 19657], [20145, 21155], [22359, 23366], [24207, 25590], [25963, 30071], [30281, 31294], [31399, 33042]], "num_segments": 13}
{"id": "sakura_emotion_178_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_178_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Tightly furrowed brow with trembling lips", "A sharp, piercing gaze and compressed lips", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "A radiant expression with raised cheeks"], "answer": "A sharp, piercing gaze and compressed lips", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_178.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[89, 968], [1352, 3371], [3464, 6689], [7300, 8438], [9673, 16791], [16808, 18860], [18965, 19948], [20564, 22949], [23022, 24371], [24468, 25429], [26132, 27454], [27467, 30634], [31543, 35940], [36015, 37370], [38008, 41032], [41391, 43180]], "num_segments": 16}
{"id": "sakura_emotion_177_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_177_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Watching a horror movie alone in the dark.", "Watching a touching but sorrowful movie scene.", "Seeing an unpleasant image online.", "A person yelling after being cut off in traffic."], "answer": "Seeing an unpleasant image online.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_177.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[123, 1142], [1449, 6854], [6993, 7909], [8591, 9691], [10076, 16907], [16964, 17842], [17951, 21741], [21864, 22957], [23623, 25345], [25389, 32757], [33418, 35437]], "num_segments": 11}
{"id": "sakura_emotion_176_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_176_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["I\u2019m so excited, I just can\u2019t contain my happiness!", "I feel so empty, like nothing matters anymore.", "It\u2019s so dirty! Please clean it as quick as possible.", "I\u2019m really scared about what might happen next."], "answer": "I\u2019m really scared about what might happen next.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_176.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1169, 6603], [7316, 8809], [9596, 12377], [12577, 13381], [13392, 17221], [17754, 24290], [24961, 29952], [30204, 31094], [31223, 33373]], "num_segments": 9}
{"id": "sakura_emotion_178_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_178_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["disgust", "sad", "happy", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_178.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[852, 1832], [2177, 6000], [7473, 8461], [8585, 12253], [12776, 13670], [14395, 16745], [17208, 19756], [19897, 20786], [20931, 25983], [26181, 27489], [28013, 33074], [33419, 34567], [35137, 39411], [39607, 40824], [40833, 42834]], "num_segments": 15}
{"id": "sakura_emotion_179_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_179_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["sad", "fear", "happy", "angry"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_179.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[84, 943], [1154, 6106], [6402, 11276], [11378, 15999], [16288, 18470], [19400, 22363], [22905, 25541], [25636, 27079], [27619, 33576], [33981, 35165], [35294, 37546], [37858, 45543], [46119, 50200], [50217, 51134], [51622, 53786]], "num_segments": 15}
{"id": "sakura_emotion_180_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_180_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["disgust", "angry", "sad", "happy"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_180.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[801, 4013], [5401, 8799], [9340, 10255], [10429, 13067], [13311, 16783], [18036, 18860], [18894, 21380], [21727, 25080], [25799, 26894], [26988, 34057], [34280, 39771], [40623, 41799], [42761, 43586], [43862, 44746], [44997, 45802]], "num_segments": 15}
{"id": "sakura_emotion_175_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_175_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "sad", "happy", "fear"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_175.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[184, 1109], [1511, 2349], [2522, 3429], [3499, 6376], [6481, 7600], [8226, 14102], [14310, 15299], [15451, 16743], [18598, 19605], [20021, 22028], [23411, 31132], [31879, 32691], [32856, 34627]], "num_segments": 13}
{"id": "sakura_emotion_179_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_179_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Listen attentively without interrupting to let them vent.", "Express understanding calmly and suggest leaving the unpleasant environment.", "Stay calm and provide support to ease their anxiety.", "Offer a comforting hug or words of reassurance."], "answer": "Offer a comforting hug or words of reassurance.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_179.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[730, 1534], [1606, 9335], [10503, 12850], [13281, 15988], [17066, 19497], [19827, 21684], [22005, 23138], [24929, 25738], [26877, 34461], [35707, 38482], [39075, 41876], [41930, 44136], [44315, 45550], [46455, 47366], [47492, 50385], [50770, 51608], [51726, 53018]], "num_segments": 17}
{"id": "sakura_emotion_175_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_175_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["I can\u2019t breathe, I\u2019m just so afraid right now.", "I can\u2019t stop smiling, everything feels so right.", "I\u2019m feeling so down, like nothing can lift my spirits.", "I can\u2019t even look at this without feeling uncomfortable."], "answer": "I can\u2019t even look at this without feeling uncomfortable.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_175.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[625, 7201], [7886, 12960], [13171, 16195], [17291, 25063], [25436, 26316], [26685, 28210], [28649, 30394], [30828, 32791], [33193, 34652]], "num_segments": 9}
{"id": "sakura_emotion_182_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_182_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "angry", "fear", "sad"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_182.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[327, 2872], [3815, 5590], [6628, 7687], [8502, 9589], [10203, 11894], [12052, 13402], [13463, 15952], [16091, 23566], [23954, 26436], [27125, 30320], [30474, 31280]], "num_segments": 11}
{"id": "sakura_emotion_182_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_182_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["Downturned mouth and teary eyes", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "A warm, genuine smile with slightly tilted head", "Tightly furrowed brow with trembling lips"], "answer": "A warm, genuine smile with slightly tilted head", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_182.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1175, 3131], [4671, 8100], [9498, 10955], [11559, 18680], [19328, 20743], [21827, 22983], [23012, 23946], [24162, 30897]], "num_segments": 8}
{"id": "sakura_emotion_183_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_183_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "sad", "happy", "angry"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_183.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[296, 1124], [1534, 6707], [8126, 11378], [12317, 15370], [16047, 17995], [18782, 19939], [21234, 28636], [29208, 32915], [34019, 35103], [35116, 37312], [38853, 39728], [39797, 40719], [42461, 48608], [48894, 51034], [51441, 53117], [54093, 55484]], "num_segments": 16}
{"id": "sakura_emotion_180_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_180_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Offer congratulations or compliments to share their happiness.", "Express understanding calmly and suggest leaving the unpleasant environment.", "Apologize and admit your mistake, if appropriate.", "Provide emotional support and avoid dismissing their sadness."], "answer": "Apologize and admit your mistake, if appropriate.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_180.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1164, 2940], [3088, 4162], [4578, 5932], [7029, 9557], [9768, 12074], [13146, 16408], [16627, 23313], [24027, 27945], [28194, 30930], [31827, 37031], [37249, 39309], [40422, 41312], [41345, 43067], [43176, 45834]], "num_segments": 14}
{"id": "sakura_emotion_184_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_184_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["sad", "fear", "angry", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_184.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[129, 4090], [4688, 10432], [10901, 12431], [13346, 15815], [16052, 16868], [17361, 19224], [19806, 20746], [20761, 25000], [25218, 28783], [29102, 30191], [30233, 31255], [32304, 39796], [40661, 42082], [42096, 43074], [43132, 44243], [44659, 47339], [47573, 50036]], "num_segments": 17}
{"id": "sakura_emotion_181_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_181_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["angry", "fear", "happy", "disgust"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_181.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[437, 1306], [2662, 9861], [10689, 12042], [12394, 14187], [15755, 17767], [18101, 19991], [20171, 20997], [21331, 22347], [22751, 26761], [27595, 34838], [35457, 36811]], "num_segments": 11}
{"id": "sakura_emotion_183_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_183_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Head slightly pulled back with a terrified gaze, as if searching for an escape.", "Tightly pressed lips with glaring eyes", "Downturned mouth and teary eyes", "A warm, genuine smile with slightly tilted head"], "answer": "Downturned mouth and teary eyes", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_183.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[226, 1158], [2722, 3540], [4401, 10331], [10818, 14510], [15817, 21622], [22703, 24596], [25050, 26256], [26498, 27797], [27929, 32708], [34103, 41185], [41791, 42703], [42705, 48179], [48657, 51813], [53005, 55269]], "num_segments": 14}
{"id": "sakura_emotion_181_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_181_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Reading a heartfelt goodbye letter.", "Celebrating a birthday with friends and family.", "Reacting to a sudden loud noise in an empty house.", "A person yelling after being cut off in traffic."], "answer": "Reacting to a sudden loud noise in an empty house.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_181.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[597, 3407], [3557, 8485], [8858, 11525], [12937, 19614], [20589, 25497], [25714, 26540], [26894, 28523], [30245, 33214], [33273, 34217], [34719, 35690]], "num_segments": 10}
{"id": "sakura_emotion_184_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_184_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["Eyes gazing downward with trembling lips", "Averted gaze with a grimacing mouth", "Frozen facial expression with trembling lips and quickened breathing.", "A radiant expression with raised cheeks"], "answer": "Averted gaze with a grimacing mouth", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_184.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[188, 1398], [1643, 3366], [4340, 5162], [5705, 7833], [9812, 10856], [11118, 13634], [15500, 18945], [19279, 25492], [26310, 27958], [28098, 29632], [29713, 35225], [36297, 37291], [37301, 38840], [38963, 39794], [39904, 42165], [42236, 44779], [45623, 46655], [47201, 48655], [48996, 50314]], "num_segments": 19}
{"id": "sakura_emotion_186_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_186_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "disgust", "happy", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_186.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[42, 2035], [2515, 4543], [4850, 7260], [7582, 8643], [9624, 16626], [17328, 21135], [21700, 23073], [24019, 27501], [27619, 28601]], "num_segments": 9}
{"id": "sakura_emotion_185_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_185_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Eyes crinkling with an open-mouthed laugh", "A heavy sigh with a frown and slumped posture", "Tightly furrowed brow with trembling lips", "A sharp, piercing gaze and compressed lips"], "answer": "A heavy sigh with a frown and slumped posture", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_185.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[423, 1307], [2077, 3538], [4773, 8969], [9021, 10941], [11406, 14963], [15134, 19650], [19903, 21749], [22119, 25835], [26938, 31061], [31404, 32428], [32554, 33779], [34484, 35938], [36958, 38480], [38664, 41802], [41891, 43181], [43509, 44875], [45152, 49142]], "num_segments": 17}
{"id": "sakura_emotion_187_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_187_masked_100pct.wav", "question": "Based on the emotion identified in the audio, which of these facial expressions is most likely to match the speaker's emotional state?", "choices": ["Frozen facial expression with trembling lips and quickened breathing.", "A broad smile with sparkling eyes", "Eyes gazing downward with trembling lips", "Furrowed brows with slightly open mouth, as if about to shout."], "answer": "A broad smile with sparkling eyes", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_187.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[179, 2651], [2723, 10117], [11705, 13389], [14639, 21453], [21940, 22981], [23444, 28639], [29773, 33309], [33369, 34216]], "num_segments": 8}
{"id": "sakura_emotion_186_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_186_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["A sharp, piercing gaze and compressed lips", "Wide-open eyes with raised eyebrows and slightly parted lips.", "Relaxed facial muscles with a cheerful grin", "A heavy sigh with a frown and slumped posture"], "answer": "Wide-open eyes with raised eyebrows and slightly parted lips.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_186.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1088, 7879], [8148, 10757], [10827, 11880], [13030, 18261], [18299, 19139], [19325, 24286], [25545, 27909]], "num_segments": 7}
{"id": "sakura_emotion_185_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_185_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "disgust", "angry", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_185.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1744, 3951], [3961, 11362], [11865, 12753], [13252, 15511], [15538, 16967], [17108, 23774], [23970, 24943], [26155, 28153], [29371, 36195], [36411, 37540], [37693, 43664], [43777, 46222], [46448, 49019], [49077, 50098]], "num_segments": 14}
{"id": "sakura_emotion_188_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_188_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "sad", "disgust", "happy"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_188.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[830, 6029], [6036, 8036], [8986, 10701], [10773, 13271], [13568, 19859], [20615, 22898], [23514, 29365], [30782, 31593], [31622, 33091], [33402, 35343], [36212, 37976], [39340, 41878]], "num_segments": 12}
{"id": "sakura_emotion_188_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_188_masked_100pct.wav", "question": "Which of the following sentences would most likely reflect the emotional state of people experiencing the same emotion as the speaker?", "choices": ["I don\u2019t know how to move on from this loss.", "I can\u2019t stop smiling, everything feels so right.", "I can\u2019t breathe, I\u2019m just so afraid right now.", "I can\u2019t believe this is happening, I\u2019m so furious!"], "answer": "I don\u2019t know how to move on from this loss.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_188.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[271, 1430], [1438, 2747], [3139, 4372], [4762, 7979], [8905, 14409], [14802, 16532], [16594, 22545], [22985, 27027], [27035, 27837], [28349, 30551], [31078, 36021], [36973, 38267], [38474, 40660]], "num_segments": 13}
{"id": "sakura_emotion_187_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_187_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "happy", "disgust", "fear"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_187.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[952, 3960], [4119, 4924], [5673, 11991], [12134, 15157], [15566, 21481], [22584, 25330], [25349, 26803], [27324, 28454], [28505, 33150], [33674, 34616]], "num_segments": 10}
{"id": "sakura_emotion_189_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_189_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Provide emotional support and avoid dismissing their sadness.", "Express genuine excitement for their good news or achievement.", "Apologize and admit your mistake, if appropriate.", "Express understanding calmly and suggest leaving the unpleasant environment."], "answer": "Express genuine excitement for their good news or achievement.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_189.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[244, 1130], [1451, 8057], [8315, 9123], [9331, 11059], [11127, 12267], [12267, 13645], [13990, 16460], [16542, 18482], [19221, 24260], [24387, 26012], [26038, 26951], [26961, 30017], [30500, 36313], [36347, 37292], [37363, 42527], [43155, 44497], [44929, 46835], [47303, 49223]], "num_segments": 18}
{"id": "sakura_emotion_189_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_189_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "happy", "sad", "disgust"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_189.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[104, 1028], [1921, 2922], [3264, 9995], [11159, 13287], [14458, 17170], [17643, 21563], [21589, 25294], [26347, 32292], [32712, 34437], [35196, 36109], [36167, 38012], [38114, 43449], [43872, 46640], [47253, 49606]], "num_segments": 14}
{"id": "sakura_emotion_191_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_191_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["disgust", "happy", "angry", "sad"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_191.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[555, 6234], [6437, 12733], [13241, 18177], [18397, 20611], [20960, 22236], [22441, 23638], [25039, 28626], [29568, 31587], [31626, 32501], [32537, 33792], [33924, 36126], [36394, 37783], [37944, 38769]], "num_segments": 13}
{"id": "sakura_emotion_190_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_190_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "sad", "angry", "happy"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_190.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[634, 1599], [1844, 3997], [4080, 5418], [5733, 7946], [10115, 11182], [12533, 14057], [15169, 16378], [16937, 19194], [19737, 20741], [20917, 21738], [22113, 22921], [23729, 24818], [25314, 28967], [29442, 30330], [30815, 38616], [38762, 40324], [41192, 43620], [44510, 47208], [47373, 49300], [49407, 50543], [50925, 52063], [52664, 60453]], "num_segments": 22}
{"id": "sakura_emotion_191_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_191_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Give them space to cool off before engaging further.", "Reassure them and offer a way to move past the uncomfortable    situation.", "Listen empathetically and let them express their feelings.", "Express genuine excitement for their good news or achievement."], "answer": "Give them space to cool off before engaging further.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_191.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[474, 1398], [2254, 3158], [3484, 5209], [5394, 8654], [8774, 12292], [13339, 15272], [15277, 21965], [22373, 24054], [24341, 25157], [25507, 26934], [27932, 30433], [31835, 35909], [37103, 38816]], "num_segments": 13}
{"id": "sakura_emotion_190_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_190_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I feel so grateful and full of joy right now.", "It\u2019s hard to imagine things ever getting better.", "That\u2019s just revolting, I can\u2019t believe it.", "This is terrifying, I can\u2019t stop thinking about it."], "answer": "It\u2019s hard to imagine things ever getting better.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_190.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1432, 3175], [3609, 5571], [5739, 9486], [9490, 11557], [12013, 13235], [13320, 15770], [15893, 22254], [23248, 27707], [28723, 29540], [29895, 31220], [31276, 35381], [35919, 36779], [37896, 40718], [40832, 41690], [41810, 43984], [44473, 45529], [46076, 51239], [51608, 54143], [54490, 56487], [57714, 60046]], "num_segments": 20}
{"id": "sakura_emotion_192_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_192_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["sad", "angry", "fear", "happy"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_192.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1650, 3825], [4325, 5234], [5268, 6498], [6855, 8620], [10291, 11310], [12316, 15031], [15519, 16367], [16651, 23660], [24255, 25548], [26028, 31390], [32305, 33459], [33616, 36694], [37971, 39127]], "num_segments": 13}
{"id": "sakura_emotion_192_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_192_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I can\u2019t even look at this without feeling uncomfortable.", "I don\u2019t know how to move on from this loss.", "I\u2019ve had enough of this nonsense.", "I\u2019m so excited, I just can\u2019t contain my happiness!"], "answer": "I\u2019ve had enough of this nonsense.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_192.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[553, 1719], [1851, 7242], [7918, 8987], [9291, 13099], [13588, 16141], [17374, 20533], [21017, 23784], [24748, 29859], [30359, 31166], [31237, 33268], [33582, 35527], [35836, 38564]], "num_segments": 12}
{"id": "sakura_emotion_196_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_196_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["disgust", "happy", "fear", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_196.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[337, 2229], [2316, 3263], [4344, 12124], [12252, 13192], [13318, 19557], [19969, 25697], [26278, 27149], [27415, 30550], [30927, 32167], [32949, 35189], [35274, 36497], [36670, 37786]], "num_segments": 12}
{"id": "sakura_emotion_193_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_193_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Express genuine excitement for their good news or achievement.", "Stay calm and provide support to ease their anxiety.", "Listen empathetically and let them express their feelings.", "Avoid discussing further and respect their aversion to the topic."], "answer": "Avoid discussing further and respect their aversion to the topic.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_193.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[329, 2687], [3721, 4833], [6086, 9251], [9285, 14412], [14735, 16536], [17741, 21584], [21872, 23283], [23842, 25147], [25676, 27153], [27280, 28151], [28454, 29492], [30003, 31842], [32487, 36687], [36786, 38188], [38472, 42266], [43708, 46327], [46505, 47397], [48975, 51354], [53600, 61334]], "num_segments": 19}
{"id": "sakura_emotion_195_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_195_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["How dare they treat me so unfairly like this!", "I\u2019m so excited, I just can\u2019t contain my happiness!", "I can\u2019t breathe, I\u2019m just so afraid right now.", "I don\u2019t know how to move on from this loss."], "answer": "I\u2019m so excited, I just can\u2019t contain my happiness!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_195.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[931, 2566], [2744, 4227], [4868, 8740], [8897, 10600], [10675, 11679], [11913, 16843], [18139, 22743], [22783, 30070], [30244, 31110]], "num_segments": 9}
{"id": "sakura_emotion_193_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_193_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "sad", "disgust", "fear"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_193.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1191, 2082], [2135, 3454], [4456, 11911], [12351, 14169], [14288, 15512], [16191, 19041], [19470, 21575], [23657, 24695], [24939, 31487], [31724, 37059], [37218, 38441], [41404, 42387], [43027, 44672], [45618, 46580], [47980, 54584], [54870, 56087], [58275, 60210]], "num_segments": 17}
{"id": "sakura_emotion_195_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_195_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "happy", "sad", "angry"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_195.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[120, 1839], [2503, 6834], [7705, 15275], [15392, 21873], [21974, 27162], [27636, 28756], [29226, 31924]], "num_segments": 7}
{"id": "sakura_emotion_196_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_196_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["Reading a heartfelt goodbye letter.", "A person yelling after being cut off in traffic.", "Hearing a shocking and offensive statement.", "Watching a horror movie alone in the dark."], "answer": "Reading a heartfelt goodbye letter.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_196.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[569, 1716], [1972, 3423], [3692, 5700], [5761, 10232], [11030, 13234], [13558, 14869], [14900, 20217], [21401, 24755], [25325, 27714], [27932, 32276], [32802, 34389], [34766, 37136], [37602, 38592]], "num_segments": 13}
{"id": "sakura_emotion_194_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_194_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "disgust", "angry", "happy"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_194.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[724, 5651], [6845, 7964], [8533, 9762], [10454, 12056], [12146, 13482], [13777, 18151], [18306, 20226], [20727, 23016], [23608, 26959], [28180, 30920], [31145, 32087], [32406, 33387]], "num_segments": 12}
{"id": "sakura_emotion_194_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_194_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["Raised eyebrows with a scowl", "Wrinkled forehead and a forlorn expression", "Tightly furrowed brow with trembling lips", "A wrinkled nose and raised upper lip"], "answer": "A wrinkled nose and raised upper lip", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_194.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[398, 1552], [2791, 4309], [5899, 6794], [6903, 9032], [9407, 10217], [10374, 17523], [18248, 19679], [20391, 25738], [26590, 29232], [30295, 32139], [32225, 33525]], "num_segments": 11}
{"id": "sakura_emotion_197_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_197_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Frozen facial expression with trembling lips and quickened breathing.", "Eyes crinkling with an open-mouthed laugh", "A sharp, piercing gaze and compressed lips", "A wrinkled nose and raised upper lip"], "answer": "Frozen facial expression with trembling lips and quickened breathing.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_197.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[32, 4049], [4064, 6814], [7082, 9942], [10242, 14190], [14213, 15317], [16223, 18084], [18133, 18956], [19022, 20395], [20855, 21839], [22957, 25624], [26749, 30025], [30372, 31806], [32054, 37125], [37529, 39601], [40259, 41579]], "num_segments": 15}
{"id": "sakura_emotion_197_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_197_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["disgust", "happy", "fear", "sad"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_197.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1022, 5595], [5763, 8269], [8756, 10758], [10805, 11893], [12989, 14084], [14096, 15090], [15549, 17310], [17978, 18883], [18942, 20813], [20953, 22238], [23325, 25093], [25855, 30618], [30750, 34228], [35680, 37078], [37163, 41518]], "num_segments": 15}
{"id": "sakura_emotion_198_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_198_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Slamming a door after a disagreement.", "Preparing for a high-stakes exam with anxiety.", "Hearing a shocking and offensive statement.", "Celebrating a birthday with friends and family."], "answer": "Preparing for a high-stakes exam with anxiety.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_198.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[190, 1866], [2078, 4333], [5122, 8840], [9152, 10481], [10605, 12468], [12951, 14648], [15163, 16667], [16933, 20469], [21203, 22835], [24099, 28073], [28336, 30421], [30435, 37272], [37512, 40090]], "num_segments": 13}
{"id": "sakura_emotion_199_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_199_masked_100pct.wav", "question": "From the provided sentences, which one best matches the emotional state of individuals who are experiencing the same emotion as the speaker?", "choices": ["This situation is really starting to piss me off!", "It\u2019s hard to imagine things ever getting better.", "This makes me feel sick to my stomach.", "I feel like I\u2019m in danger, and I don\u2019t know what to do."], "answer": "This situation is really starting to piss me off!", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_199.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[991, 3682], [3903, 9850], [10322, 14763], [15448, 21749], [22635, 23813], [24978, 26248], [27646, 31157], [31635, 33879], [35428, 37308], [38487, 40323], [40955, 41790], [42470, 47826], [49604, 50787]], "num_segments": 13}
{"id": "sakura_emotion_198_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_198_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "disgust", "fear", "happy"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_198.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[707, 1563], [2049, 3929], [4074, 5584], [6400, 7997], [9731, 11199], [11413, 14427], [14658, 16240], [16548, 17428], [18354, 23565], [24687, 26141], [27435, 33727], [35254, 36536], [36925, 38113], [38147, 40327]], "num_segments": 14}
{"id": "sakura_emotion_200_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_200_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "angry", "disgust", "sad"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_200.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1151, 8860], [9700, 12707], [13854, 16325], [16501, 17654], [18424, 19584], [19609, 25549], [26140, 28571], [29603, 31941], [32216, 39062], [39145, 40221], [40582, 45953]], "num_segments": 11}
{"id": "sakura_emotion_199_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_199_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["sad", "disgust", "fear", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_199.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1299, 2207], [3021, 5045], [5224, 7156], [7415, 10384], [11016, 14692], [14711, 15813], [15844, 22720], [24669, 26301], [27349, 28715], [29372, 33151], [33158, 34034], [35154, 37876], [38155, 39093], [39276, 42014], [42516, 43391], [43418, 49932]], "num_segments": 16}
{"id": "sakura_emotion_200_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_200_masked_100pct.wav", "question": "Which situation best corresponds to the emotion conveyed in the speech?", "choices": ["Saying goodbye at an airport.", "Seeing an unpleasant image online.", "Walking alone in a dark alley at night.", "A person yelling after being cut off in traffic."], "answer": "Seeing an unpleasant image online.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_200.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[756, 3005], [3315, 4285], [4646, 7523], [7610, 13428], [13519, 14508], [15153, 16449], [16542, 18111], [19137, 20074], [20753, 24845], [25265, 26315], [26418, 27609], [27838, 31780], [32650, 35019], [35237, 39275], [39737, 40995], [41325, 43957], [44404, 45335]], "num_segments": 17}
{"id": "sakura_emotion_201_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_201_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["angry", "disgust", "sad", "happy"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_201.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1281, 3392], [4531, 6665], [7002, 8164], [8169, 12181], [12935, 13969], [14359, 18498], [18931, 21424], [22292, 23214], [24157, 26511], [26543, 29367], [29974, 30951], [30954, 31807], [32036, 33335], [34589, 35769]], "num_segments": 14}
{"id": "sakura_emotion_201_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_201_masked_100pct.wav", "question": "Which facial expression best matches the emotion in the audio?", "choices": ["Head slightly pulled back with a terrified gaze, as if searching for an escape.", "Eyes gazing downward with trembling lips", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "Raised eyebrows with a scowl"], "answer": "Eyes gazing downward with trembling lips", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_201.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[985, 1929], [1963, 3883], [4456, 7762], [8698, 16226], [16436, 20168], [21033, 22824], [23232, 24378], [25162, 26227], [26475, 28398], [28445, 33467], [34180, 36380]], "num_segments": 11}
{"id": "sakura_emotion_202_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_202_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "sad", "disgust", "fear"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_202.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[314, 3041], [3283, 10382], [11448, 12561], [14179, 18923], [19947, 20851], [22051, 23283], [24025, 28828], [29388, 30302], [30330, 34063], [34791, 36728], [36905, 40435], [40570, 42658], [44387, 45563]], "num_segments": 13}
{"id": "sakura_emotion_203_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_203_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["disgust", "sad", "fear", "happy"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_203.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[373, 1392], [1674, 2879], [3902, 5709], [6346, 11627], [11655, 14059], [14169, 16474], [16603, 17991], [18521, 19928], [20163, 21084], [21638, 28572], [28947, 29838], [30746, 33958], [34104, 35446], [35593, 39587]], "num_segments": 14}
{"id": "sakura_emotion_202_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_202_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["A heavy sigh with a frown and slumped posture", "A wrinkled nose and raised upper lip", "Wide-open eyes with raised eyebrows and slightly parted lips.", "Clenched teeth with side facial muscles showing tension."], "answer": "A wrinkled nose and raised upper lip", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_202.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[431, 1793], [1804, 2692], [4043, 5036], [5368, 6699], [6720, 8874], [9178, 11280], [11766, 13094], [13589, 17462], [18228, 19716], [20222, 22535], [23191, 24162], [24254, 25155], [25324, 29968], [30787, 33334], [34117, 40748], [42143, 43626], [44036, 44931]], "num_segments": 17}
{"id": "sakura_emotion_203_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_203_masked_100pct.wav", "question": "From the provided sentences, which one best matches the emotional state of individuals who are experiencing the same emotion as the speaker?", "choices": ["I\u2019m so excited, I just can\u2019t contain my happiness!", "I\u2019m feeling so down, like nothing can lift my spirits.", "I can\u2019t shake the feeling that something bad is coming.", "This makes me feel sick to my stomach."], "answer": "This makes me feel sick to my stomach.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_203.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[495, 1341], [2744, 6229], [7257, 8199], [9172, 11231], [11845, 16087], [16273, 17607], [18151, 19546], [20339, 21374], [21577, 25103], [26015, 27845], [27941, 28983], [28987, 31443], [32639, 36715], [37403, 40633]], "num_segments": 14}
{"id": "sakura_emotion_204_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_204_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["sad", "disgust", "happy", "angry"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_204.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[950, 6851], [7405, 13662], [15496, 23225], [23462, 24621], [24731, 25835], [25971, 30124], [31140, 36978], [37701, 38703]], "num_segments": 8}
{"id": "sakura_emotion_204_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_204_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Stay calm and provide support to ease their anxiety.", "Give them space to cool off before engaging further.", "Celebrate their joy with a cheerful response.", "Avoid discussing further and respect their aversion to the topic."], "answer": "Avoid discussing further and respect their aversion to the topic.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_204.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[794, 2326], [2935, 4479], [5111, 6823], [6831, 8524], [8701, 13141], [14485, 15991], [16125, 19650], [20098, 21217], [21726, 23227], [23357, 25544], [25834, 33113], [34419, 36446], [36541, 37489]], "num_segments": 13}
{"id": "sakura_emotion_205_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_205_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "fear", "happy", "sad"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_205.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[229, 4206], [4226, 7917], [9242, 10440], [11375, 12275], [13878, 17094], [17563, 18979], [20017, 21511], [21651, 26097], [26429, 27430], [27896, 29664], [30024, 33851], [34082, 35252], [35779, 37318], [37345, 40262], [40289, 41908], [42773, 45846]], "num_segments": 16}
{"id": "sakura_emotion_205_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_205_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Suggest spending some time together to cheer them up.", "Apologize and admit your mistake, if appropriate.", "Offer congratulations or compliments to share their happiness.", "Express understanding calmly and suggest leaving the unpleasant environment."], "answer": "Express understanding calmly and suggest leaving the unpleasant environment.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_205.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[446, 1729], [1790, 5211], [7037, 12157], [13383, 15332], [15583, 17207], [17215, 22476], [23339, 24301], [24559, 25477], [26354, 27679], [28889, 33129], [33142, 34759], [35783, 37728], [38548, 40437], [40590, 42030], [42920, 44236], [44236, 46090]], "num_segments": 16}
{"id": "sakura_emotion_207_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_207_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Calmly acknowledge their frustration and suggest a solution.", "Listen empathetically and let them express their feelings.", "Express genuine excitement for their good news or achievement.", "Reassure them and offer a way to move past the uncomfortable    situation."], "answer": "Listen empathetically and let them express their feelings.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_207.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[910, 7511], [9258, 11735], [11996, 12928], [13564, 21400], [21410, 23825], [24076, 25667], [26401, 27934], [27941, 29366], [29639, 31378], [31523, 32632]], "num_segments": 10}
{"id": "sakura_emotion_207_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_207_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["fear", "angry", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_207.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[35, 1025], [1632, 2791], [2894, 5121], [5132, 12237], [13516, 17855], [18294, 19927], [20082, 25761], [25799, 27018], [27747, 29381], [30493, 32782]], "num_segments": 10}
{"id": "sakura_emotion_206_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_206_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["happy", "angry", "sad", "fear"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_206.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[119, 1697], [1796, 9519], [9835, 11367], [11568, 12670], [12990, 19319], [19320, 20206], [20213, 26529], [27359, 29115]], "num_segments": 8}
{"id": "sakura_emotion_206_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_206_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Offer a comforting hug or words of reassurance.", "Encourage them to take deep breaths to relax.", "Avoid discussing further and respect their aversion to the topic.", "Give them space to cool off before engaging further."], "answer": "Offer a comforting hug or words of reassurance.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_206.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[979, 2878], [3294, 4498], [6026, 7310], [8276, 15185], [15278, 16745], [17405, 19913], [21295, 24834], [25693, 27758], [28176, 29202]], "num_segments": 9}
{"id": "sakura_emotion_208_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_208_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "angry", "fear", "happy"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_208.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1106, 5234], [5455, 6352], [6521, 8845], [9564, 10530], [11067, 12196], [12834, 13947], [15356, 21403], [22600, 24151], [24452, 25461], [26557, 27650], [29639, 36569], [38192, 44110], [45563, 46950], [47842, 49330], [49452, 54597], [54803, 59014], [59976, 61517], [61566, 63151], [63250, 64454]], "num_segments": 19}
{"id": "sakura_emotion_208_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_208_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Rejecting a tasteless meal with a grimace.", "Facing an aggressive dog on the street.", "A heated argument between colleagues.", "Reading a heartfelt goodbye letter."], "answer": "Rejecting a tasteless meal with a grimace.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_208.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[393, 1361], [2230, 3357], [4000, 7399], [7912, 9862], [10075, 13808], [15367, 22328], [22956, 25149], [25349, 26910], [27418, 29165], [29247, 34702], [35744, 36565], [36777, 37685], [37858, 41511], [42280, 48510], [49366, 51175], [51956, 54266], [55674, 56489], [56682, 58206], [58573, 61216], [62659, 64425], [64498, 65540]], "num_segments": 21}
{"id": "sakura_emotion_209_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_209_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["sad", "fear", "angry", "disgust"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_209.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[233, 1145], [1947, 6586], [8199, 10044], [10508, 11910], [12546, 14078], [15039, 20193], [20671, 24227], [24928, 29599], [29660, 31603], [32141, 35607]], "num_segments": 10}
{"id": "sakura_emotion_209_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_209_masked_100pct.wav", "question": "Based on the emotion identified in the audio, which of these facial expressions is most likely to match the speaker's emotional state?", "choices": ["Wide-open eyes with raised eyebrows and slightly parted lips.", "Downturned mouth and teary eyes", "A broad smile with sparkling eyes", "Tightly pressed lips with glaring eyes"], "answer": "Wide-open eyes with raised eyebrows and slightly parted lips.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_209.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[762, 5938], [6856, 12471], [12779, 13674], [14816, 18221], [18487, 24770], [25700, 27959], [28236, 31447], [31548, 33629], [33792, 35441]], "num_segments": 9}
{"id": "sakura_emotion_210_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_210_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["happy", "sad", "angry", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_210.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[438, 1300], [1974, 5987], [6541, 7966], [8736, 13037], [13853, 14821], [14901, 20607], [21750, 29379], [30905, 36196], [37030, 37975], [38896, 41609], [43058, 44975], [46431, 51958]], "num_segments": 12}
{"id": "sakura_emotion_211_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_211_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "sad", "angry", "fear"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_211.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[695, 1802], [2132, 3114], [3489, 4740], [5065, 6802], [6905, 10441], [12005, 14500], [14796, 16073], [16103, 18331], [19145, 20009], [20493, 21653], [22107, 22989], [23545, 27189], [29030, 30018], [30170, 31397], [31559, 32789], [33264, 35746], [36642, 37835], [38306, 39550], [40905, 42057], [42492, 46090], [46473, 53369]], "num_segments": 21}
{"id": "sakura_emotion_211_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_211_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["Clenched teeth with side facial muscles showing tension.", "Wide-open eyes with raised eyebrows and slightly parted lips.", "A wrinkled nose and raised upper lip", "A heavy sigh with a frown and slumped posture"], "answer": "A heavy sigh with a frown and slumped posture", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_211.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1206, 2274], [3190, 6278], [6314, 7645], [7819, 8720], [9521, 12203], [13139, 15847], [16872, 23215], [23234, 26030], [26667, 27594], [28657, 29721], [30528, 33477], [34450, 39584], [40798, 44216], [44875, 47421], [47529, 48612], [49078, 52888]], "num_segments": 16}
{"id": "sakura_emotion_210_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_210_masked_100pct.wav", "question": "Which facial expression best fits the emotion heard in the audio?", "choices": ["A broad smile with sparkling eyes", "Wide-open eyes with raised eyebrows and slightly parted lips.", "A heavy sigh with a frown and slumped posture", "Squinted eyes and a pinched nose"], "answer": "Wide-open eyes with raised eyebrows and slightly parted lips.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_210.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[588, 4850], [5094, 6534], [7625, 10045], [11008, 14132], [14448, 16742], [17303, 19190], [20746, 22060], [23680, 24815], [24931, 27303], [27772, 29173], [30096, 34995], [35280, 36114], [36218, 38052], [38369, 40128], [40807, 46602], [46885, 47685], [49596, 50444], [51440, 52552]], "num_segments": 18}
{"id": "sakura_emotion_213_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_213_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "angry", "disgust", "fear"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_213.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[998, 1953], [2521, 5272], [6377, 9373], [9733, 12921], [13096, 14723], [15790, 16632], [16745, 18987], [19493, 22534], [23699, 25151], [26072, 27785], [28579, 31036]], "num_segments": 11}
{"id": "sakura_emotion_213_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_213_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I can\u2019t believe this is happening, I\u2019m so furious!", "This is terrifying, I can\u2019t stop thinking about it.", "I can\u2019t even look at this without feeling uncomfortable.", "I just can\u2019t stop thinking about all those bad memories."], "answer": "I can\u2019t even look at this without feeling uncomfortable.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_213.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[190, 1503], [2394, 5161], [6367, 7619], [8617, 12141], [12292, 14154], [15296, 16628], [16728, 18483], [18578, 20973], [21692, 22801], [23829, 25677], [26428, 27891], [28235, 30212], [30284, 31196]], "num_segments": 13}
{"id": "sakura_emotion_212_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_212_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "sad", "angry", "fear"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_212.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[885, 1726], [1904, 3184], [3898, 5308], [5566, 11325], [11986, 13249], [13298, 18544], [19069, 25046], [25881, 27318], [27768, 29328], [29443, 36007], [36457, 37365], [37852, 38928], [39439, 41180], [41780, 45541], [45697, 46578], [47895, 54354]], "num_segments": 16}
{"id": "sakura_emotion_215_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_215_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "fear", "disgust", "sad"], "answer": "angry", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_215.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1919, 8643], [9519, 10677], [10860, 15414], [16063, 17119], [17255, 24820], [26307, 30106], [30479, 31397], [31564, 34127]], "num_segments": 8}
{"id": "sakura_emotion_214_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_214_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["sad", "angry", "happy", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_214.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[283, 3546], [5073, 6946], [7399, 13052], [13772, 14714], [14761, 17877], [18044, 21114], [22056, 23278], [23377, 24297], [24761, 26827], [27049, 28218], [28392, 33330], [34070, 34968]], "num_segments": 12}
{"id": "sakura_emotion_214_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_214_masked_100pct.wav", "question": "Which of the following sentences would most likely reflect the emotional state of people experiencing the same emotion as the speaker?", "choices": ["I don\u2019t know how to move on from this loss.", "I can\u2019t shake the feeling that something bad is coming.", "It\u2019s so dirty! Please clean it as quick as possible.", "This situation is really starting to piss me off!"], "answer": "It\u2019s so dirty! Please clean it as quick as possible.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_214.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[44, 1413], [1880, 3047], [3279, 6837], [7108, 8226], [8524, 15335], [15970, 16884], [17230, 25059], [26572, 30465], [31082, 32418], [33229, 34268]], "num_segments": 10}
{"id": "sakura_emotion_212_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_212_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["Downturned mouth and teary eyes", "Squinted eyes and a pinched nose", "Furrowed brows with slightly open mouth, as if about to shout.", "Relaxed facial muscles with a cheerful grin"], "answer": "Relaxed facial muscles with a cheerful grin", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_212.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[384, 1995], [2597, 8025], [8360, 9660], [10151, 12036], [13481, 14774], [15622, 17341], [18034, 19130], [20060, 21393], [22181, 29001], [29342, 30383], [30524, 35676], [35692, 37135], [37967, 44472], [45281, 51626], [52120, 54453]], "num_segments": 15}
{"id": "sakura_emotion_217_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_217_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["sad", "angry", "fear", "disgust"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_217.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1391, 2523], [2552, 3979], [4193, 6542], [7605, 14238], [14576, 18977], [19718, 21742], [22145, 24832], [24985, 26644], [26687, 29282]], "num_segments": 9}
{"id": "sakura_emotion_216_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_216_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "disgust", "fear", "sad"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_216.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[118, 1750], [3164, 7966], [9594, 14379], [15325, 16427], [17029, 21704], [22791, 23999], [24386, 26878], [28154, 29874], [30413, 35512]], "num_segments": 9}
{"id": "sakura_emotion_217_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_217_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Hugging a loved one after a long separation.", "Saying goodbye at an airport.", "Facing an aggressive dog on the street.", "A heated argument between colleagues."], "answer": "A heated argument between colleagues.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_217.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[104, 1142], [1535, 5766], [6286, 12726], [12772, 13743], [13987, 15333], [16331, 18958], [19008, 20343], [20389, 21483], [21936, 27193], [27346, 28463]], "num_segments": 10}
{"id": "sakura_emotion_216_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_216_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Offer congratulations or compliments to share their happiness.", "Offer reassurance and remind them they are safe.", "Suggest spending some time together to cheer them up.", "Apologize and admit your mistake, if appropriate."], "answer": "Offer congratulations or compliments to share their happiness.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_216.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[322, 6706], [7945, 13498], [14595, 15482], [15696, 21677], [22384, 24001], [24046, 25323], [25967, 30268], [30768, 35240]], "num_segments": 8}
{"id": "sakura_emotion_215_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_215_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["A person yelling after being cut off in traffic.", "Reacting to a sudden loud noise in an empty house.", "Winning a long-anticipated award or prize.", "Turning away from spoiled food."], "answer": "A person yelling after being cut off in traffic.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_215.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[835, 1797], [2417, 9535], [9785, 10649], [11158, 12334], [12926, 19621], [20745, 22348], [23497, 26397], [27803, 30305], [31522, 34680]], "num_segments": 9}
{"id": "sakura_emotion_218_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_218_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["fear", "disgust", "happy", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_218.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[891, 1741], [1800, 8373], [8503, 9342], [9707, 10565], [10695, 16734], [17034, 18141], [18664, 19623], [19707, 21139], [21499, 28903], [29281, 30880], [31385, 32923]], "num_segments": 11}
{"id": "sakura_emotion_219_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_219_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["fear", "sad", "happy", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_219.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[800, 2007], [2109, 9382], [9838, 12598], [13377, 14594], [16031, 19085], [20147, 21541], [21965, 22810], [23906, 30757], [31771, 32584], [32769, 35559], [37355, 40582], [40913, 41773], [42173, 43192]], "num_segments": 13}
{"id": "sakura_emotion_219_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_219_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Suggest spending some time together to cheer them up.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Encourage them to take deep breaths to relax.", "Calmly acknowledge their frustration and suggest a solution."], "answer": "Calmly acknowledge their frustration and suggest a solution.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_219.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[918, 6039], [6928, 7994], [8176, 9204], [10287, 18085], [19411, 20723], [20758, 21956], [22690, 23646], [23647, 25909], [26301, 30964], [31852, 34232], [34690, 35953], [36110, 40993], [41667, 42806]], "num_segments": 13}
{"id": "sakura_emotion_218_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_218_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["I\u2019m so excited, I just can\u2019t contain my happiness!", "I can\u2019t even look at this without feeling uncomfortable.", "I can\u2019t breathe, I\u2019m just so afraid right now.", "I\u2019m feeling so down, like nothing can lift my spirits."], "answer": "I\u2019m feeling so down, like nothing can lift my spirits.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_218.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[298, 1743], [2990, 4165], [5243, 11370], [13032, 15782], [16783, 18593], [18651, 19889], [20246, 26932], [27998, 29239], [29485, 30431], [30993, 32322]], "num_segments": 10}
{"id": "sakura_emotion_221_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_221_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "angry", "happy", "sad"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_221.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[232, 1587], [2111, 5149], [5164, 8732], [8937, 9789], [10806, 14564], [15462, 16971], [17384, 18555], [19056, 24110], [25142, 26224], [26988, 32194], [32748, 37672], [37695, 38965], [39249, 40543]], "num_segments": 13}
{"id": "sakura_emotion_220_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_220_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["angry", "disgust", "sad", "happy"], "answer": "angry", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_220.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[661, 8550], [9588, 10616], [11090, 13053], [13079, 13907], [14789, 17053], [18373, 21267], [22067, 29387], [29543, 32723], [32776, 37146], [37643, 38499]], "num_segments": 10}
{"id": "sakura_emotion_222_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_222_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["sad", "angry", "happy", "disgust"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_222.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1054, 3077], [3448, 8580], [9152, 10903], [10914, 12512], [13048, 15069], [15105, 16324], [16610, 19216], [19718, 20851], [21070, 25555], [25597, 28293], [28421, 29254], [29443, 31417]], "num_segments": 12}
{"id": "sakura_emotion_221_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_221_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["This situation is really starting to piss me off!", "I can\u2019t breathe, I\u2019m just so afraid right now.", "I don\u2019t know how to move on from this loss.", "It\u2019s so dirty! Please clean it as quick as possible."], "answer": "It\u2019s so dirty! Please clean it as quick as possible.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_221.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[157, 1090], [1492, 4719], [4979, 8167], [8263, 9751], [9981, 13556], [14763, 15656], [16723, 17607], [18057, 19519], [19666, 23859], [25121, 31166], [31199, 34926], [35874, 38203], [38733, 40925]], "num_segments": 13}
{"id": "sakura_emotion_220_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_220_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Hearing a shocking and offensive statement.", "A parent scolding their child for misbehavior.", "A person crying after a breakup.", "Winning a long-anticipated award or prize."], "answer": "A parent scolding their child for misbehavior.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_220.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[530, 8024], [8037, 9289], [9638, 12944], [13417, 16018], [16881, 20279], [21520, 28207], [28735, 35995], [36050, 36912], [37666, 38693]], "num_segments": 9}
{"id": "sakura_emotion_222_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_222_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Smile and engage positively in the conversation.", "Offer reassurance and remind them they are safe.", "Listen empathetically and let them express their feelings.", "Reassure them and offer a way to move past the uncomfortable    situation."], "answer": "Listen empathetically and let them express their feelings.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_222.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[342, 3480], [3724, 4557], [4747, 5822], [6760, 7633], [8224, 9419], [9618, 13732], [13822, 14946], [15329, 16219], [16595, 17817], [18424, 25897], [26153, 27325], [28279, 29614], [30206, 31306]], "num_segments": 13}
{"id": "sakura_emotion_224_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_224_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "disgust", "fear", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_224.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1657, 3122], [4719, 5852], [6459, 10457], [10555, 11505], [12422, 14349], [14509, 16760], [17055, 19356], [20243, 23535], [23975, 26521], [26676, 29863], [29878, 30832]], "num_segments": 11}
{"id": "sakura_emotion_224_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_224_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Smile and engage positively in the conversation.", "Provide emotional support and avoid dismissing their sadness.", "Give them space to cool off before engaging further.", "Stay calm and provide support to ease their anxiety."], "answer": "Give them space to cool off before engaging further.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_224.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[337, 2224], [3014, 5402], [5632, 6705], [6885, 8320], [8499, 9445], [9979, 11369], [11511, 18163], [18895, 20559], [20619, 22575], [22984, 27925], [28131, 30785]], "num_segments": 11}
{"id": "sakura_emotion_228_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_228_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["disgust", "happy", "sad", "angry"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_228.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[740, 1667], [2060, 6085], [6255, 7899], [8840, 10373], [10695, 14689], [15149, 16979], [17430, 18600], [19935, 22296], [22607, 25157], [25740, 29222]], "num_segments": 10}
{"id": "sakura_emotion_226_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_226_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "fear", "sad", "angry"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_226.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[183, 1328], [1463, 6983], [7158, 8372], [8537, 15480], [15520, 16894], [17317, 19497], [19652, 27441], [27525, 28896], [29368, 33155]], "num_segments": 9}
{"id": "sakura_emotion_223_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_223_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["happy", "angry", "disgust", "fear"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_223.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[174, 4217], [5045, 8388], [9373, 15628], [16477, 19357], [19985, 23710], [25381, 31219], [32137, 34798], [34798, 36185]], "num_segments": 8}
{"id": "sakura_emotion_223_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_223_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["That\u2019s just revolting, I can\u2019t believe it.", "This is the best day ever, I feel on top of the world!", "This situation is really starting to piss me off!", "I\u2019m really scared about what might happen next."], "answer": "This is the best day ever, I feel on top of the world!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_223.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[617, 3141], [3736, 4974], [5519, 6509], [8243, 13490], [14444, 19403], [21036, 22000], [22630, 27831], [27907, 30157], [30522, 31684], [31807, 33582], [34387, 36136]], "num_segments": 11}
{"id": "sakura_emotion_225_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_225_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Flared nostrils with a tense expression", "Eyes gazing downward with trembling lips", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "Relaxed facial muscles with a cheerful grin"], "answer": "Eyes gazing downward with trembling lips", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_225.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1753, 8773], [9317, 15247], [15333, 20321], [21208, 22843], [23331, 24494], [25739, 30017], [30710, 31983], [33188, 34282], [34621, 36027], [36621, 42524]], "num_segments": 10}
{"id": "sakura_emotion_228_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_228_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Retracted chin with one corner of the mouth twitching, as if intolerable.", "A broad smile with sparkling eyes", "Frozen facial expression with trembling lips and quickened breathing.", "Raised eyebrows with a scowl"], "answer": "A broad smile with sparkling eyes", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_228.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[526, 1333], [1909, 4873], [5792, 6929], [7306, 8126], [8574, 15548], [16177, 19169], [19433, 21401], [22831, 27530], [27578, 28597], [28701, 29718]], "num_segments": 10}
{"id": "sakura_emotion_226_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_226_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Encourage them to take deep breaths to relax.", "Offer congratulations or compliments to share their happiness.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Listen empathetically and let them express their feelings."], "answer": "Listen empathetically and let them express their feelings.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_226.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[45, 2951], [3156, 4958], [5668, 7208], [8039, 11361], [11924, 17801], [17911, 18742], [18971, 24892], [24920, 25816], [25909, 26822], [27161, 28040], [28133, 29682], [30339, 32166], [32225, 33160]], "num_segments": 13}
{"id": "sakura_emotion_225_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_225_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "sad", "happy", "disgust"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_225.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[254, 1215], [2868, 9870], [10073, 12155], [12237, 15003], [15403, 16338], [17363, 23275], [24269, 26091], [27191, 28544], [28855, 30087], [30325, 31451], [31733, 36470], [38013, 39344], [39691, 41469], [41667, 42679]], "num_segments": 14}
{"id": "sakura_emotion_227_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_227_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["disgust", "fear", "angry", "sad"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_227.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[332, 2980], [4465, 6250], [6560, 7585], [7985, 11380], [11458, 12601], [13282, 15212], [15546, 19580], [19694, 26147], [26408, 30625]], "num_segments": 9}
{"id": "sakura_emotion_227_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_227_masked_100pct.wav", "question": "From the provided sentences, which one best matches the emotional state of individuals who are experiencing the same emotion as the speaker?", "choices": ["This thing looks absolutely gross and dirty; I can\u2019t stand it!", "I\u2019m really scared about what might happen next.", "I\u2019ve had enough of this nonsense.", "I can\u2019t stop smiling, everything feels so right."], "answer": "I\u2019ve had enough of this nonsense.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_227.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[796, 4288], [5809, 8879], [9085, 10443], [10483, 17873], [18114, 19931], [20376, 26874], [27217, 29168], [29215, 30787]], "num_segments": 8}
{"id": "sakura_emotion_230_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_230_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "fear", "happy", "sad"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_230.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[439, 1358], [2582, 5770], [6511, 8519], [9354, 14026], [14758, 16640], [17695, 24178], [24316, 26420], [26542, 27613], [27791, 29838], [30361, 32237], [33432, 34790], [36094, 37134]], "num_segments": 12}
{"id": "sakura_emotion_229_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_229_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Turning away from spoiled food.", "Attending a close friend's funeral.", "Facing an aggressive dog on the street.", "Slamming a door after a disagreement."], "answer": "Turning away from spoiled food.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_229.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[182, 1868], [2130, 5530], [5736, 9300], [10377, 17070], [18754, 19931], [20364, 26807], [27266, 28345], [28351, 34627], [35193, 36435], [36996, 37846]], "num_segments": 10}
{"id": "sakura_emotion_230_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_230_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["This is the best day ever, I feel on top of the world!", "I don\u2019t know how to move on from this loss.", "I feel like I\u2019m in danger, and I don\u2019t know what to do.", "That\u2019s just revolting, I can\u2019t believe it."], "answer": "This is the best day ever, I feel on top of the world!", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_230.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[406, 4965], [5097, 5918], [6079, 11789], [13177, 20546], [20765, 23032], [23580, 27086], [28041, 29136], [30249, 35937], [36140, 37098]], "num_segments": 9}
{"id": "sakura_emotion_229_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_229_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["happy", "disgust", "fear", "sad"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_229.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[630, 2686], [3573, 5962], [6308, 7614], [7985, 8797], [9035, 9965], [10970, 11914], [11970, 13138], [14199, 16360], [17211, 18566], [19704, 25752], [26533, 27378], [27498, 29070], [29977, 35894], [35992, 37878]], "num_segments": 14}
{"id": "sakura_emotion_231_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_231_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Hugging a loved one after a long separation.", "A person crying after a breakup.", "Reacting to a foul odor in a room.", "A person yelling after being cut off in traffic."], "answer": "Reacting to a foul odor in a room.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_231.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[427, 1817], [3097, 5392], [5790, 7507], [7882, 13583], [13597, 15362], [15638, 18154], [19222, 22080], [22145, 23999], [24270, 26510], [27426, 29561], [30022, 33565], [33799, 36741], [37426, 40117], [40960, 44623], [45626, 47879], [47892, 52995], [53019, 53999]], "num_segments": 17}
{"id": "sakura_emotion_233_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_233_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["disgust", "sad", "angry", "happy"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_233.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1294, 5298], [5538, 8115], [8340, 11778], [12892, 13991], [14033, 15270], [15610, 17119], [17180, 19453], [19488, 20655], [21578, 26157], [27200, 28693], [28901, 29714], [29976, 30790], [31305, 36995], [37634, 40065], [40197, 44537], [45048, 45853], [46604, 47531], [48453, 49318]], "num_segments": 18}
{"id": "sakura_emotion_232_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_232_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["angry", "sad", "happy", "disgust"], "answer": "angry", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_232.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1070, 5111], [6074, 9576], [10025, 17065], [18086, 18892], [19506, 20982], [21214, 23346], [23422, 30100], [30496, 31403], [31860, 37044], [37150, 38265]], "num_segments": 10}
{"id": "sakura_emotion_231_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_231_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "sad", "angry", "happy"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_231.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[620, 6560], [7448, 10718], [11156, 13475], [13688, 15674], [16045, 17966], [19439, 24616], [25972, 28893], [29175, 30197], [30767, 31695], [31989, 38162], [38622, 39522], [39677, 47289], [49375, 54983]], "num_segments": 13}
{"id": "sakura_emotion_234_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_234_masked_100pct.wav", "question": "Which facial expression best matches the emotion in the audio?", "choices": ["Tightly furrowed brow with trembling lips", "Averted gaze with a grimacing mouth", "A heavy sigh with a frown and slumped posture", "Flared nostrils with a tense expression"], "answer": "A heavy sigh with a frown and slumped posture", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_234.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[213, 1402], [2110, 4323], [4377, 7323], [7569, 14740], [15602, 16536], [16984, 18262], [18551, 19389], [19857, 21286], [21695, 22978], [23038, 24363], [24365, 28002], [28281, 30563], [30749, 31726], [31880, 35734], [36197, 39067], [40383, 41324], [42182, 43907]], "num_segments": 17}
{"id": "sakura_emotion_235_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_235_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["happy", "angry", "disgust", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_235.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[53, 1080], [1608, 3597], [3979, 5835], [6237, 11734], [13402, 16531], [16718, 22056], [22228, 23408], [23617, 25334], [26589, 27676], [28041, 33525], [33645, 35038], [35154, 36031]], "num_segments": 12}
{"id": "sakura_emotion_232_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_232_masked_100pct.wav", "question": "Which facial expression best matches the emotion in the audio?", "choices": ["Tightly pressed lips with glaring eyes", "Wrinkled forehead and a forlorn expression", "Averted gaze with a grimacing mouth", "Eyes crinkling with an open-mouthed laugh"], "answer": "Tightly pressed lips with glaring eyes", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_232.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[500, 5327], [5623, 6509], [7657, 8643], [8998, 12422], [12816, 16794], [17502, 24304], [24870, 26447], [26543, 31953], [31994, 36353], [36409, 38047]], "num_segments": 10}
{"id": "sakura_emotion_233_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_233_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Offer congratulations or compliments to share their happiness.", "Reassure them and offer a way to move past the uncomfortable    situation.", "Encourage them to take deep breaths to relax.", "Offer a comforting hug or words of reassurance."], "answer": "Reassure them and offer a way to move past the uncomfortable    situation.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_233.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1131, 1949], [2035, 4705], [4981, 7369], [8042, 14275], [15333, 18442], [18527, 19769], [19837, 23599], [23996, 25377], [25484, 27892], [28862, 36365], [37826, 39746], [40247, 41605], [42521, 44258], [44473, 46627], [47220, 49902]], "num_segments": 15}
{"id": "sakura_emotion_235_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_235_masked_100pct.wav", "question": "What facial expression most aligns with the emotion in the recording?", "choices": ["Head slightly pulled back with a terrified gaze, as if searching for an escape.", "Squinted eyes and a pinched nose", "A sharp, piercing gaze and compressed lips", "Eyes gazing downward with trembling lips"], "answer": "Head slightly pulled back with a terrified gaze, as if searching for an escape.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_235.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[638, 4162], [4745, 5953], [6100, 10692], [11227, 13110], [13389, 19028], [19042, 20140], [20827, 21997], [22298, 23627], [23805, 24639], [25069, 26227], [26408, 27654], [28545, 29879], [30191, 34592], [35617, 36705]], "num_segments": 14}
{"id": "sakura_emotion_234_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_234_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["disgust", "angry", "fear", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_234.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[389, 1350], [2202, 5097], [5352, 7456], [7541, 14404], [14412, 18645], [19922, 23251], [23464, 30137], [30445, 36305], [36581, 37723], [38595, 40496], [41517, 43322]], "num_segments": 11}
{"id": "sakura_emotion_236_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_236_masked_100pct.wav", "question": "Considering the emotion expressed in the audio, which of the following facial expressions would align most closely with it?", "choices": ["A broad smile with sparkling eyes", "Wrinkled forehead and a forlorn expression", "Tightly furrowed brow with trembling lips", "Averted gaze with a grimacing mouth"], "answer": "Averted gaze with a grimacing mouth", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_236.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[404, 8351], [8503, 9435], [9697, 17606], [17703, 21049], [21526, 23635], [23940, 31782], [31807, 36590], [36749, 42015], [42833, 45059]], "num_segments": 9}
{"id": "sakura_emotion_236_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_236_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "happy", "fear", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_236.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[201, 2372], [3334, 4451], [4672, 8405], [9190, 12171], [12623, 19410], [20101, 21129], [21366, 22959], [23144, 23945], [24205, 25748], [26106, 30021], [30179, 32292], [32346, 34695], [34983, 35992], [36382, 41216], [41536, 42570], [43836, 44857]], "num_segments": 16}
{"id": "sakura_emotion_237_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_237_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "happy", "disgust", "fear"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_237.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[719, 5391], [5729, 9309], [10201, 12076], [12662, 15474], [15498, 16474], [16821, 18602], [19336, 20363], [20394, 22646], [23212, 24151], [24604, 26282], [26825, 28260], [28260, 29061]], "num_segments": 12}
{"id": "sakura_emotion_237_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_237_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["This is terrifying, I can\u2019t stop thinking about it.", "This situation is really starting to piss me off!", "It\u2019s so dirty! Please clean it as quick as possible.", "I feel so grateful and full of joy right now."], "answer": "I feel so grateful and full of joy right now.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_237.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[281, 1226], [1489, 4932], [5453, 6455], [6602, 14092], [14668, 20127], [21393, 23094], [23136, 24708], [24710, 27409], [28121, 29048]], "num_segments": 9}
{"id": "sakura_emotion_238_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_238_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Rejecting a tasteless meal with a grimace.", "Slamming a door after a disagreement.", "Facing an aggressive dog on the street.", "Laughing at a funny joke in a conversation."], "answer": "Slamming a door after a disagreement.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_238.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[934, 2016], [2570, 3967], [4163, 11570], [11902, 15804], [16304, 18369], [19459, 26719], [27668, 28630], [28983, 31075], [31383, 33325], [33375, 35073], [35368, 36457]], "num_segments": 11}
{"id": "sakura_emotion_238_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_238_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "happy", "disgust", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_238.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[672, 4854], [5140, 6816], [7028, 7932], [8424, 11641], [12184, 13353], [13539, 19071], [19731, 21300], [21318, 22328], [22856, 23680], [23716, 25153], [25259, 29713], [29726, 30764], [30836, 32673], [34188, 35821]], "num_segments": 14}
{"id": "sakura_emotion_239_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_239_masked_100pct.wav", "question": "Which situation best corresponds to the emotion conveyed in the speech?", "choices": ["Watching a horror movie alone in the dark.", "Hugging a loved one after a long separation.", "Slamming a door after a disagreement.", "A person crying after a breakup."], "answer": "Hugging a loved one after a long separation.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_239.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[132, 1623], [1735, 7973], [8162, 9776], [10087, 13429], [13638, 14841], [15798, 23439], [23830, 24946], [25030, 25851], [25907, 27365], [28978, 30839], [31299, 32612], [32629, 33735], [34940, 36041], [37125, 37946], [38019, 40924], [41313, 43787]], "num_segments": 16}
{"id": "sakura_emotion_239_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_239_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["disgust", "happy", "angry", "sad"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_239.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[397, 1260], [1324, 2568], [3564, 4521], [4759, 7034], [7604, 13683], [15513, 21286], [22207, 23545], [24577, 26853], [27846, 31123], [31505, 34564], [35188, 39065], [39266, 41758], [42093, 43053], [43078, 44027]], "num_segments": 14}
{"id": "sakura_emotion_240_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_240_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Saying goodbye at an airport.", "Walking alone in a dark alley at night.", "Winning a long-anticipated award or prize.", "Slamming a door after a disagreement."], "answer": "Slamming a door after a disagreement.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_240.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1361, 2470], [2669, 5979], [7753, 9492], [9877, 11173], [12003, 15580], [16153, 18030], [18104, 20367], [20379, 21901], [22619, 28459], [28592, 34607], [34996, 36359]], "num_segments": 11}
{"id": "sakura_emotion_240_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_240_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "sad", "angry", "fear"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_240.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1349, 5536], [6123, 11609], [12810, 15721], [16665, 21988], [21992, 23031], [23465, 25186], [25293, 27779], [27828, 29453], [30823, 35400]], "num_segments": 9}
{"id": "sakura_emotion_241_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_241_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["happy", "angry", "sad", "fear"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_241.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1446, 2389], [2390, 4775], [5763, 7683], [7984, 8802], [9126, 13374], [13672, 14554], [14880, 17166], [17250, 18222], [18790, 24159], [24423, 25870], [26116, 27562], [28400, 29727], [29858, 33576], [35654, 37289], [37690, 40039]], "num_segments": 15}
{"id": "sakura_emotion_241_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_241_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["A warm, genuine smile with slightly tilted head", "Wide-open eyes with raised eyebrows and slightly parted lips.", "Furrowed brows with slightly open mouth, as if about to shout.", "Eyes gazing downward with trembling lips"], "answer": "Furrowed brows with slightly open mouth, as if about to shout.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_241.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[385, 1713], [1769, 6581], [6770, 9044], [10605, 15574], [15608, 22526], [24238, 26354], [27111, 29101], [29465, 30560], [31224, 38446], [38788, 40563]], "num_segments": 10}
{"id": "sakura_emotion_244_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_244_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["I\u2019m really scared about what might happen next.", "I\u2019m just so happy I could burst!", "I\u2019m feeling so down, like nothing can lift my spirits.", "This situation is really starting to piss me off!"], "answer": "I\u2019m really scared about what might happen next.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_244.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[616, 1960], [2725, 3988], [4574, 7546], [9888, 12705], [14044, 15018], [16088, 19023], [20313, 21641], [22321, 23510], [24964, 32366], [32472, 33347], [33849, 35452], [35800, 37247], [37354, 38162], [39099, 46270], [47673, 54973], [55962, 56813]], "num_segments": 16}
{"id": "sakura_emotion_242_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_242_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "disgust", "happy", "angry"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_242.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[614, 2930], [3665, 8323], [9219, 11644], [12525, 14548], [14828, 16370], [16923, 20876], [20958, 26343], [26540, 32130], [33479, 34790], [34930, 37114], [37317, 38236], [38302, 42904], [43942, 47330], [47444, 49936], [50010, 50954]], "num_segments": 15}
{"id": "sakura_emotion_242_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_242_masked_100pct.wav", "question": "From the provided sentences, which one best matches the emotional state of individuals who are experiencing the same emotion as the speaker?", "choices": ["I feel like I\u2019m in danger, and I don\u2019t know what to do.", "That\u2019s just revolting, I can\u2019t believe it.", "I feel so empty, like nothing matters anymore.", "I\u2019ve had enough of this nonsense."], "answer": "That\u2019s just revolting, I can\u2019t believe it.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_242.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1536, 2393], [2510, 4528], [4664, 6029], [6589, 7912], [8312, 9997], [10067, 10894], [11177, 12055], [13010, 15569], [15799, 16699], [16974, 19453], [19561, 25547], [25871, 26817], [27791, 34664], [35190, 38993], [39102, 39937], [41131, 47664], [47829, 50779]], "num_segments": 17}
{"id": "sakura_emotion_243_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_243_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "fear", "happy", "angry"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_243.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[461, 2111], [3674, 5051], [5664, 6646], [6812, 12095], [12832, 16179], [16296, 18183], [18267, 23320], [24394, 25245], [25761, 27776], [28123, 31090], [31531, 39039], [39778, 41454], [41802, 42818], [42978, 43783], [43835, 46076]], "num_segments": 15}
{"id": "sakura_emotion_244_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_244_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "fear", "happy", "angry"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_244.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1771, 9112], [9373, 13447], [14434, 15802], [15822, 17207], [17650, 20651], [20835, 22131], [22211, 24335], [25077, 29227], [30448, 37284], [38519, 39841], [40139, 41761], [42726, 49766], [49950, 54335], [54863, 55748], [56773, 57651]], "num_segments": 15}
{"id": "sakura_emotion_243_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_243_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["A person smiling after receiving good news.", "Saying goodbye at an airport.", "Facing an aggressive dog on the street.", "A parent scolding their child for misbehavior."], "answer": "A person smiling after receiving good news.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_243.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[661, 8518], [9064, 14655], [15385, 17580], [17699, 25455], [26198, 27033], [28427, 36094], [36521, 37447], [37603, 39365], [40663, 42235], [42618, 43817], [44194, 46957]], "num_segments": 11}
{"id": "sakura_emotion_245_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_245_masked_100pct.wav", "question": "Which facial expression best matches the emotion in the audio?", "choices": ["Eyes gazing downward with trembling lips", "A sharp, piercing gaze and compressed lips", "Squinted eyes and a pinched nose", "Wide-open eyes with raised eyebrows and slightly parted lips."], "answer": "A sharp, piercing gaze and compressed lips", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_245.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[438, 1555], [2800, 8764], [9252, 10748], [11608, 16053], [16668, 24478], [24653, 26264], [27104, 35017], [36902, 43718], [45218, 48411]], "num_segments": 9}
{"id": "sakura_emotion_246_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_246_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "happy", "sad", "disgust"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_246.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1206, 3461], [3897, 6255], [6383, 13257], [13729, 14677], [14973, 18344], [19144, 21291], [21891, 24878], [25497, 30349], [30379, 32020], [32445, 33473]], "num_segments": 10}
{"id": "sakura_emotion_245_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_245_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "disgust", "angry", "sad"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_245.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[130, 5178], [5655, 6641], [6822, 8801], [9921, 14901], [15181, 16497], [16636, 18019], [18322, 24347], [26297, 31684], [31729, 33244], [33395, 37702], [37968, 38807], [38856, 40463], [40749, 43568], [43900, 47458], [47621, 48757]], "num_segments": 15}
{"id": "sakura_emotion_246_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_246_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Apologize and admit your mistake, if appropriate.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Suggest an activity to keep the positive energy flowing.", "Encourage them to take deep breaths to relax."], "answer": "Encourage them to take deep breaths to relax.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_246.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[44, 1840], [2734, 10288], [10989, 13207], [14183, 16353], [17432, 18260], [18354, 20037], [20580, 27341], [27614, 28922], [29123, 31051], [32237, 33235]], "num_segments": 10}
{"id": "sakura_emotion_247_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_247_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "fear", "sad", "disgust"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_247.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[130, 1130], [2018, 4644], [5252, 11742], [12442, 15644], [15869, 22217], [22780, 24037], [24637, 27561], [28173, 29989], [31858, 37164], [37312, 38227], [38290, 39664]], "num_segments": 11}
{"id": "sakura_emotion_247_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_247_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Apologize and admit your mistake, if appropriate.", "Hold their hand or offer some physical reassurance.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Listen empathetically and let them express their feelings."], "answer": "Hold their hand or offer some physical reassurance.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_247.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[350, 1284], [1544, 6748], [6811, 7642], [7771, 8919], [8974, 9911], [10657, 12882], [12935, 16232], [16515, 22493], [22836, 25011], [25596, 27586], [28102, 29021], [29380, 33202], [34135, 35667], [36153, 37320], [37470, 39510]], "num_segments": 15}
{"id": "sakura_emotion_248_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_248_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["This thing looks absolutely gross and dirty; I can\u2019t stand it!", "This situation is really starting to piss me off!", "I\u2019m really scared about what might happen next.", "This is the best day ever, I feel on top of the world!"], "answer": "I\u2019m really scared about what might happen next.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_248.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[167, 1255], [1390, 3572], [3812, 4772], [5457, 12269], [13240, 14343], [14634, 16159], [16635, 17496], [18178, 20406], [21457, 23579], [23817, 24630], [24635, 26180], [26567, 30915], [31099, 33183], [33603, 41420]], "num_segments": 14}
{"id": "sakura_emotion_248_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_248_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "sad", "happy", "disgust"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_248.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[889, 2146], [2198, 3706], [4306, 5145], [6030, 10982], [11457, 18214], [18688, 19819], [20028, 24600], [25706, 26538], [26811, 27641], [29085, 35161], [35505, 37225], [37296, 42620]], "num_segments": 12}
{"id": "sakura_emotion_249_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_249_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "angry", "fear", "sad"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_249.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[789, 1649], [1675, 3354], [5025, 11123], [11476, 13515], [13970, 19134], [19902, 20706], [20962, 23092], [23094, 25390], [25964, 26844], [27731, 34412], [34966, 36637], [36654, 37763], [38335, 41333], [41808, 46962], [47604, 48836]], "num_segments": 15}
{"id": "sakura_emotion_250_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_250_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Listen empathetically and let them express their feelings.", "Give them space to cool off before engaging further.", "Celebrate their joy with a cheerful response.", "Hold their hand or offer some physical reassurance."], "answer": "Celebrate their joy with a cheerful response.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_250.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[323, 3703], [4538, 5428], [6003, 8043], [8342, 15625], [16379, 18259], [18620, 20231], [20510, 22632], [23727, 31275], [32747, 34506], [35783, 37109]], "num_segments": 10}
{"id": "sakura_emotion_250_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_250_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["sad", "happy", "fear", "disgust"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_250.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[163, 1630], [1660, 4763], [5039, 7728], [7928, 9415], [9595, 11355], [11412, 12346], [12801, 14895], [16213, 18858], [18927, 23078], [23191, 25267], [26101, 29159], [29175, 33867], [34263, 36056], [36204, 37790]], "num_segments": 14}
{"id": "sakura_emotion_251_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_251_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["fear", "sad", "happy", "disgust"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_251.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[470, 1431], [1472, 2689], [2944, 5590], [6515, 7717], [9064, 11743], [12887, 13855], [14564, 15481], [15934, 18277], [18774, 19653], [20562, 27113], [28238, 29045], [29177, 30523], [31317, 35988]], "num_segments": 13}
{"id": "sakura_emotion_249_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_249_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Turning away from spoiled food.", "A person smiling after receiving good news.", "A person crying after a breakup.", "Facing an aggressive dog on the street."], "answer": "Turning away from spoiled food.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_249.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[807, 4793], [6365, 7706], [8227, 9069], [9103, 11938], [12946, 16702], [17425, 18308], [18859, 25028], [26657, 29382], [29538, 30374], [31195, 33308], [33495, 34957], [35514, 37887], [38055, 39217], [39365, 42991], [43268, 44364], [44523, 46829], [47112, 48144]], "num_segments": 17}
{"id": "sakura_emotion_251_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_251_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Watching a touching but sorrowful movie scene.", "Watching a horror movie alone in the dark.", "Turning away from spoiled food.", "Laughing at a funny joke in a conversation."], "answer": "Watching a touching but sorrowful movie scene.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_251.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1003, 8488], [9637, 10506], [10751, 15303], [16398, 20198], [20809, 24031], [24230, 26250], [27018, 31405], [32535, 36331]], "num_segments": 8}
{"id": "sakura_emotion_252_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_252_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Hearing a shocking and offensive statement.", "Reading a heartfelt goodbye letter.", "Throwing an object in frustration.", "Celebrating a birthday with friends and family."], "answer": "Hearing a shocking and offensive statement.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_252.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[777, 4313], [5170, 7038], [8728, 11299], [11807, 12836], [13713, 19746], [20592, 23058], [24177, 26353], [27684, 34864], [35384, 36673], [36908, 37716], [37994, 38874], [39886, 40896], [41138, 42171], [42242, 43585]], "num_segments": 14}
{"id": "sakura_emotion_252_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_252_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["sad", "happy", "angry", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_252.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[218, 1186], [2228, 3274], [4188, 5133], [5976, 8657], [9241, 13848], [14200, 15651], [17557, 18440], [18466, 19651], [20076, 22238], [22849, 27054], [27295, 29795], [30308, 35038], [35156, 40232], [40709, 41807]], "num_segments": 14}
{"id": "sakura_emotion_253_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_253_masked_100pct.wav", "question": "What facial expression most aligns with the emotion in the recording?", "choices": ["Squinted eyes and a pinched nose", "Furrowed brows with slightly open mouth, as if about to shout.", "Head slightly pulled back with a terrified gaze, as if searching for an escape.", "A heavy sigh with a frown and slumped posture"], "answer": "Head slightly pulled back with a terrified gaze, as if searching for an escape.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_253.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[302, 7787], [8812, 10244], [11103, 14795], [15072, 16086], [16260, 19728], [20685, 23259], [23427, 29409], [29501, 30947], [31101, 32843], [33693, 35041], [35776, 37470]], "num_segments": 11}
{"id": "sakura_emotion_253_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_253_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "sad", "fear", "angry"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_253.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[538, 3434], [4002, 5198], [6287, 7785], [7794, 14126], [14374, 20728], [21446, 22272], [22729, 25373], [25609, 27138], [28580, 30192], [30977, 35281], [36318, 37616]], "num_segments": 11}
{"id": "sakura_emotion_254_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_254_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "sad", "fear", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_254.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[315, 2563], [3256, 9452], [9563, 13151], [13293, 14763], [15423, 17721], [19210, 24161], [25358, 27559], [28247, 33584], [34339, 41651]], "num_segments": 9}
{"id": "sakura_emotion_255_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_255_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["disgust", "fear", "sad", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_255.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[409, 1563], [1688, 2596], [2993, 7147], [7403, 9507], [10444, 11566], [12123, 13061], [13441, 15332], [15600, 16633], [16847, 19681], [21226, 22414], [23722, 26956], [27417, 28483], [29525, 32220], [33074, 34993], [36320, 38627]], "num_segments": 15}
{"id": "sakura_emotion_256_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_256_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "angry", "disgust", "fear"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_256.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[190, 1598], [1619, 4033], [4844, 8515], [9260, 14341], [14547, 16874], [17196, 18037], [18461, 20010], [20289, 23105], [23118, 24571], [25049, 26083], [26126, 32620], [33269, 41056]], "num_segments": 12}
{"id": "sakura_emotion_255_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_255_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["This is terrifying, I can\u2019t stop thinking about it.", "I can\u2019t believe this is happening, I\u2019m so furious!", "This thing looks absolutely gross and dirty; I can\u2019t stand it!", "I can\u2019t stop smiling, everything feels so right."], "answer": "I can\u2019t believe this is happening, I\u2019m so furious!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_255.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1265, 3793], [5387, 7680], [7803, 9404], [9636, 11960], [12287, 13492], [14252, 15618], [16481, 17489], [19419, 21009], [21013, 23816], [24009, 24854], [24888, 27935], [28379, 29323], [29538, 30726], [31354, 37245], [38126, 39321]], "num_segments": 15}
{"id": "sakura_emotion_254_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_254_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Celebrate their joy with a cheerful response.", "Offer reassurance and remind them they are safe.", "Express understanding calmly and suggest leaving the unpleasant environment.", "Listen attentively without interrupting to let them vent."], "answer": "Listen attentively without interrupting to let them vent.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_254.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[454, 1293], [1399, 4222], [4333, 11944], [12053, 14428], [15046, 18583], [18783, 20146], [20662, 23811], [23968, 26161], [26240, 27690], [27778, 31512], [32468, 35120], [35449, 37342], [37399, 41816]], "num_segments": 13}
{"id": "sakura_emotion_258_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_258_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["sad", "happy", "disgust", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_258.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[37, 1244], [2066, 2947], [3304, 4435], [5326, 8043], [8652, 12242], [12339, 13896], [14297, 15118], [15175, 18224], [19243, 27169], [27296, 28237], [29118, 30207], [30496, 32262]], "num_segments": 12}
{"id": "sakura_emotion_257_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_257_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Reassure them and offer a way to move past the uncomfortable    situation.", "Give them space to cool off before engaging further.", "Provide emotional support and avoid dismissing their sadness.", "Offer reassurance and remind them they are safe."], "answer": "Offer reassurance and remind them they are safe.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_257.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[270, 1444], [2149, 3693], [4061, 5094], [5501, 7436], [7833, 8730], [9113, 9959], [10050, 11804], [13171, 15475], [15624, 21983], [23137, 24408], [24717, 25890], [26036, 28589], [30508, 35019], [36589, 39048], [39625, 42006], [42660, 43664]], "num_segments": 16}
{"id": "sakura_emotion_256_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_256_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["A person crying after a breakup.", "Facing an aggressive dog on the street.", "Hugging a loved one after a long separation.", "Throwing an object in frustration."], "answer": "Hugging a loved one after a long separation.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_256.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[511, 1420], [1640, 4044], [5365, 12683], [12772, 17394], [17467, 23916], [24492, 26701], [26942, 28834], [29327, 31544], [32605, 39413], [40197, 41935]], "num_segments": 10}
{"id": "sakura_emotion_258_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_258_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Saying goodbye at an airport.", "Hearing a shocking and offensive statement.", "Winning a long-anticipated award or prize.", "Facing an aggressive dog on the street."], "answer": "Facing an aggressive dog on the street.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_258.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[541, 3713], [3750, 4633], [4722, 5646], [5689, 6700], [6907, 8662], [8925, 16863], [16983, 17854], [17898, 20112], [20293, 21943], [22164, 30134], [30173, 31424], [31465, 32964]], "num_segments": 12}
{"id": "sakura_emotion_259_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_259_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Express genuine excitement for their good news or achievement.", "Listen attentively without interrupting to let them vent.", "Offer reassurance and remind them they are safe.", "Express understanding calmly and suggest leaving the unpleasant environment."], "answer": "Listen attentively without interrupting to let them vent.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_259.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[126, 1063], [1422, 5641], [6362, 7313], [7788, 9085], [9752, 11075], [12078, 15582], [15609, 17468], [17654, 18510], [19520, 22847], [23416, 26077], [26488, 28022], [28655, 30830], [30863, 32228]], "num_segments": 13}
{"id": "sakura_emotion_257_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_257_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "happy", "sad", "angry"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_257.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[111, 2296], [3107, 7462], [8328, 12253], [13351, 20370], [21420, 24401], [24762, 28875], [29104, 34513], [34676, 36887], [37352, 43842]], "num_segments": 9}
{"id": "sakura_emotion_260_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_260_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["happy", "sad", "angry", "disgust"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_260.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[865, 3949], [5252, 8257], [9573, 17076], [17609, 18465], [18732, 20489], [21432, 22635], [24072, 26082], [27622, 30779], [32042, 33227], [33414, 34355], [34967, 36766], [37306, 38147], [39061, 39868]], "num_segments": 13}
{"id": "sakura_emotion_259_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_259_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["disgust", "angry", "sad", "happy"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_259.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1488, 2607], [3780, 6488], [7148, 8330], [8448, 13000], [13110, 17540], [17635, 19192], [19332, 20139], [20817, 22952], [23138, 23964], [24238, 27099], [27746, 31835]], "num_segments": 11}
{"id": "sakura_emotion_260_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_260_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I can\u2019t stop smiling, everything feels so right.", "I can\u2019t believe this is happening, I\u2019m so furious!", "This thing looks absolutely gross and dirty; I can\u2019t stand it!", "I can\u2019t shake the feeling that something bad is coming."], "answer": "I can\u2019t stop smiling, everything feels so right.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_260.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[253, 1682], [3005, 8541], [9314, 16725], [16941, 18609], [18845, 24317], [24895, 25771], [26386, 33147], [33747, 34859], [36701, 38774]], "num_segments": 9}
{"id": "sakura_emotion_261_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_261_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "disgust", "happy", "angry"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_261.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1577, 2812], [2862, 3672], [4181, 5604], [5801, 9431], [9451, 13766], [14021, 16994], [17123, 18363], [18600, 19617], [19883, 20772], [20963, 22485], [23530, 24805], [25062, 29251], [29382, 31306], [32157, 33524], [34683, 35766]], "num_segments": 15}
{"id": "sakura_emotion_262_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_262_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["fear", "happy", "sad", "disgust"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_262.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[360, 2210], [3029, 3966], [4357, 9243], [9768, 16643], [18133, 19931], [20658, 21990], [22612, 23832], [24365, 25592], [25909, 27021], [27900, 29528], [29677, 31290], [32580, 35672], [36813, 38078]], "num_segments": 13}
{"id": "sakura_emotion_261_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_261_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Rejecting a tasteless meal with a grimace.", "Facing an aggressive dog on the street.", "Reading a heartfelt goodbye letter.", "Winning a long-anticipated award or prize."], "answer": "Winning a long-anticipated award or prize.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_261.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[922, 1790], [1987, 2862], [3452, 4385], [4501, 6170], [6701, 8109], [8330, 13406], [13458, 14575], [14685, 18741], [18909, 19720], [19729, 20728], [21534, 23823], [24897, 28887], [29777, 32150], [33075, 35166], [35199, 36012]], "num_segments": 15}
{"id": "sakura_emotion_262_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_262_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Encourage them to take deep breaths to relax.", "Suggest an activity to keep the positive energy flowing.", "Listen empathetically and let them express their feelings."], "answer": "Listen empathetically and let them express their feelings.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_262.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[263, 1067], [1491, 2483], [2655, 4161], [4285, 5717], [5785, 11282], [11711, 13370], [13400, 15271], [15630, 17929], [18639, 19986], [19995, 21216], [21479, 25828], [26114, 26967], [27030, 29469], [29989, 31582], [32366, 35664], [36412, 37318]], "num_segments": 16}
{"id": "sakura_emotion_263_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_263_masked_100pct.wav", "question": "Which situation best corresponds to the emotion conveyed in the speech?", "choices": ["Slamming a door after a disagreement.", "Reading a heartfelt goodbye letter.", "Hearing a shocking and offensive statement.", "Winning a long-anticipated award or prize."], "answer": "Slamming a door after a disagreement.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_263.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[387, 5529], [6261, 7112], [7621, 12758], [13024, 14470], [14485, 15774], [16368, 24126], [24704, 26388], [26518, 27453], [27838, 30811], [31038, 35610], [37310, 41338], [42283, 43686]], "num_segments": 12}
{"id": "sakura_emotion_263_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_263_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["sad", "disgust", "fear", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_263.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[244, 4923], [6674, 7709], [7942, 9036], [9623, 10886], [11177, 12469], [12865, 14297], [14324, 16213], [16796, 18227], [18331, 20419], [21352, 23675], [23741, 27972], [28336, 30360], [31903, 35537], [36899, 40761], [41838, 43059]], "num_segments": 15}
{"id": "sakura_emotion_264_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_264_masked_100pct.wav", "question": "Considering the emotion expressed in the audio, which of the following facial expressions would align most closely with it?", "choices": ["Averted gaze with a grimacing mouth", "A heavy sigh with a frown and slumped posture", "A broad smile with sparkling eyes", "Frozen facial expression with trembling lips and quickened breathing."], "answer": "A heavy sigh with a frown and slumped posture", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_264.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[517, 8321], [8409, 11432], [11557, 14213], [14258, 18359], [19457, 26372], [27307, 28169], [28456, 29467], [29876, 31306], [32321, 39985], [40733, 41641], [41691, 46382], [47041, 48707]], "num_segments": 12}
{"id": "sakura_emotion_265_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_265_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Walking alone in a dark alley at night.", "Turning away from spoiled food.", "Slamming a door after a disagreement.", "A person smiling after receiving good news."], "answer": "Slamming a door after a disagreement.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_265.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[81, 933], [1393, 2628], [2940, 4784], [5195, 10672], [11027, 11938], [12128, 16172], [16719, 18551], [19139, 20442], [20616, 27213], [27441, 29902], [30868, 38365]], "num_segments": 11}
{"id": "sakura_emotion_264_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_264_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["disgust", "happy", "fear", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_264.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[421, 1640], [2514, 8137], [8863, 10352], [10488, 13476], [14361, 17861], [18541, 22089], [22435, 23983], [24338, 25969], [26181, 30798], [31680, 34060], [34064, 35310], [35926, 43785], [44092, 44970], [45438, 49747]], "num_segments": 14}
{"id": "sakura_emotion_266_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_266_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "angry", "sad", "happy"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_266.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[148, 2922], [4451, 5811], [7963, 12304], [12730, 14268], [15238, 17729], [18111, 24069], [25837, 28951], [29365, 30469], [31055, 32000], [32263, 34134], [34758, 36490], [37809, 40523], [41865, 48390], [49499, 50755], [51416, 56264], [56643, 57588], [57698, 58569], [59514, 62744]], "num_segments": 18}
{"id": "sakura_emotion_266_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_266_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["Tightly pressed lips with glaring eyes", "Downturned mouth and teary eyes", "Relaxed facial muscles with a cheerful grin", "Frozen facial expression with trembling lips and quickened breathing."], "answer": "Frozen facial expression with trembling lips and quickened breathing.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_266.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[328, 2396], [2850, 7287], [7415, 12299], [12413, 14903], [15291, 19237], [20224, 21839], [22915, 25945], [27492, 32007], [32289, 33648], [33970, 38476], [38893, 40300], [40382, 41900], [42228, 43101], [44137, 45641], [46489, 48979], [49346, 55357], [55425, 61760], [62287, 63253]], "num_segments": 18}
{"id": "sakura_emotion_268_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_268_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["This is the best day ever, I feel on top of the world!", "It\u2019s so dirty! Please clean it as quick as possible.", "This is terrifying, I can\u2019t stop thinking about it.", "How dare they treat me so unfairly like this!"], "answer": "How dare they treat me so unfairly like this!", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_268.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[912, 2869], [2954, 3902], [4061, 8401], [8917, 10328], [11015, 17080], [17106, 19952], [20772, 23464], [24215, 25362], [25728, 26599], [26634, 28297], [28340, 29323], [29334, 32667]], "num_segments": 12}
{"id": "sakura_emotion_267_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_267_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "happy", "fear", "disgust"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_267.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[217, 4239], [4301, 5671], [5988, 11185], [11917, 13194], [13751, 16467], [16853, 17660], [17692, 18852], [19336, 20656], [20947, 23394], [23618, 24855], [25412, 28396], [29360, 31808], [32922, 34253], [34341, 39703], [41023, 43358], [43634, 46809], [47687, 48800]], "num_segments": 17}
{"id": "sakura_emotion_267_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_267_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Preparing for a high-stakes exam with anxiety.", "A person smiling after receiving good news.", "Hearing a shocking and offensive statement.", "A parent scolding their child for misbehavior."], "answer": "Preparing for a high-stakes exam with anxiety.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_267.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[26, 1481], [2012, 3696], [3888, 5031], [5495, 7599], [8795, 9823], [10038, 13006], [13185, 15443], [15744, 18019], [19100, 20290], [20738, 21772], [21805, 22941], [23188, 25644], [26455, 27707], [27914, 33588], [35072, 40035], [40263, 41492], [41910, 48433]], "num_segments": 17}
{"id": "sakura_emotion_269_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_269_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["happy", "disgust", "fear", "angry"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_269.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[71, 937], [1578, 3787], [3814, 5199], [5285, 11581], [11645, 13181], [14658, 20011], [20398, 22439], [23137, 26475], [27767, 32596], [33241, 38816], [38944, 39966], [40680, 44943], [45000, 47048]], "num_segments": 13}
{"id": "sakura_emotion_268_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_268_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["fear", "angry", "happy", "disgust"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_268.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[908, 2252], [3083, 10650], [11706, 15514], [16505, 24005], [24080, 27090], [28326, 31317], [31993, 32859]], "num_segments": 7}
{"id": "sakura_emotion_269_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_269_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Walking alone in a dark alley at night.", "A person smiling after receiving good news.", "A heated argument between colleagues.", "Hearing a shocking and offensive statement."], "answer": "Walking alone in a dark alley at night.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_269.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[944, 2075], [2229, 9457], [10100, 11609], [12079, 17244], [17298, 18353], [19367, 25072], [26722, 28231], [29593, 32441], [33708, 34917], [35176, 36281], [36449, 38350], [39983, 40783], [42004, 43420], [43957, 45441], [45996, 47190]], "num_segments": 15}
{"id": "sakura_emotion_270_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_270_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["Retracted chin with one corner of the mouth twitching, as if intolerable.", "Furrowed brows with slightly open mouth, as if about to shout.", "Wrinkled forehead and a forlorn expression", "Head slightly pulled back with a terrified gaze, as if searching for an escape."], "answer": "Wrinkled forehead and a forlorn expression", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_270.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[594, 1795], [1944, 3274], [4178, 7518], [8940, 10790], [12056, 18652], [19448, 24108], [24120, 28605], [28756, 29935], [30704, 38401], [39633, 43187], [43305, 44917], [45725, 48013], [48018, 48823], [48923, 49753]], "num_segments": 14}
{"id": "sakura_emotion_271_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_271_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "happy", "sad", "angry"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_271.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1242, 8797], [9422, 11410], [11592, 16793], [17666, 18597], [19631, 20614], [21060, 23512], [23595, 24594], [25806, 30386], [30415, 32235], [33447, 36149]], "num_segments": 10}
{"id": "sakura_emotion_270_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_270_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "sad", "disgust", "happy"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_270.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1664, 4677], [4726, 6455], [7397, 11278], [11871, 17374], [17741, 19040], [20104, 21393], [22035, 24035], [25075, 28988], [29475, 31752], [31863, 35507], [35968, 37348], [38760, 41841], [42618, 43961], [44918, 49354]], "num_segments": 14}
{"id": "sakura_emotion_271_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_271_masked_100pct.wav", "question": "Which facial expression best matches the emotion in the audio?", "choices": ["Wrinkled forehead and a forlorn expression", "Frozen facial expression with trembling lips and quickened breathing.", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "A radiant expression with raised cheeks"], "answer": "A radiant expression with raised cheeks", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_271.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[825, 1927], [2583, 5557], [6473, 10715], [11009, 13445], [13769, 18717], [18833, 19698], [20434, 21925], [21969, 25672], [25679, 32681], [33052, 34089], [34210, 36397]], "num_segments": 11}
{"id": "sakura_emotion_265_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_265_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["fear", "disgust", "angry", "sad"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_265.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1188, 3748], [4940, 6865], [7333, 11803], [12025, 13069], [14625, 16806], [17540, 18486], [18895, 20193], [20694, 21585], [21616, 26108], [26489, 28755], [28803, 33037], [33387, 38850]], "num_segments": 12}
{"id": "sakura_emotion_272_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_272_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I can\u2019t believe this is happening, I\u2019m so furious!", "It\u2019s so dirty! Please clean it as quick as possible.", "I can\u2019t breathe, I\u2019m just so afraid right now.", "I just can\u2019t stop thinking about all those bad memories."], "answer": "I just can\u2019t stop thinking about all those bad memories.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_272.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[71, 1569], [1883, 2949], [3547, 9198], [10001, 15711], [16593, 17531], [17825, 19115], [19341, 22253], [23288, 30444], [31093, 31992], [32156, 33364]], "num_segments": 10}
{"id": "sakura_emotion_272_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_272_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["disgust", "angry", "sad", "fear"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_272.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[239, 1716], [2199, 8741], [8809, 12038], [12222, 15043], [15660, 16992], [17698, 20601], [21240, 27573], [27787, 29095], [29389, 32223], [32459, 33583]], "num_segments": 10}
{"id": "sakura_emotion_274_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_274_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["sad", "fear", "angry", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_274.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[533, 5127], [5261, 8121], [8310, 9127], [9679, 11798], [12443, 18844], [20015, 21100], [22598, 23849], [25509, 30036], [30952, 35509], [36332, 37282], [37620, 39336]], "num_segments": 11}
{"id": "sakura_emotion_276_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_276_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "disgust", "fear", "happy"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_276.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[534, 3709], [4428, 5661], [5829, 6711], [6775, 11667], [11827, 13058], [13290, 18216], [18918, 20551], [21585, 22525], [22620, 27047], [27186, 28396], [28617, 29817], [29896, 33719], [34523, 36143], [37019, 37849], [38203, 39941]], "num_segments": 15}
{"id": "sakura_emotion_274_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_274_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Give them space to cool off before engaging further.", "Offer a comforting hug or words of reassurance.", "Encourage them to take deep breaths to relax.", "Reassure them and offer a way to move past the uncomfortable    situation."], "answer": "Reassure them and offer a way to move past the uncomfortable    situation.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_274.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[386, 4951], [4957, 5757], [6144, 7630], [7710, 11682], [12831, 16996], [17081, 19776], [20243, 25998], [26003, 29289], [30514, 36046], [36422, 39186]], "num_segments": 10}
{"id": "sakura_emotion_273_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_273_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Offer a comforting hug or words of reassurance.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Encourage them to take deep breaths to relax.", "Offer congratulations or compliments to share their happiness."], "answer": "Encourage them to take deep breaths to relax.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_273.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[102, 3479], [4218, 5370], [5804, 11718], [11896, 16669], [18002, 18971], [21316, 22548], [23300, 27643], [29164, 30050], [30436, 31279], [31672, 34147], [35143, 38151], [39490, 40507], [40558, 45325], [46958, 52995]], "num_segments": 14}
{"id": "sakura_emotion_276_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_276_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["It\u2019s so dirty! Please clean it as quick as possible.", "How dare they treat me so unfairly like this!", "I\u2019m really scared about what might happen next.", "This is the best day ever, I feel on top of the world!"], "answer": "It\u2019s so dirty! Please clean it as quick as possible.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_276.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[817, 2503], [3898, 8685], [9248, 16933], [18689, 24643], [25085, 28628], [28773, 30291], [30567, 38408], [38832, 39806]], "num_segments": 8}
{"id": "sakura_emotion_275_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_275_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Watching a touching but sorrowful movie scene.", "Hearing a shocking and offensive statement.", "A heated argument between colleagues.", "Preparing for a high-stakes exam with anxiety."], "answer": "Watching a touching but sorrowful movie scene.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_275.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1243, 2631], [3090, 6480], [8430, 10553], [10683, 17926], [18016, 18838], [19502, 20743], [21474, 28476], [29477, 34735], [34841, 36938]], "num_segments": 9}
{"id": "sakura_emotion_273_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_273_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["disgust", "sad", "fear", "angry"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_273.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[262, 1090], [1645, 3189], [3474, 7433], [7464, 12822], [14319, 18428], [18776, 20018], [21518, 22874], [23674, 25907], [26107, 33541], [34435, 35273], [35767, 42797], [43514, 49866], [50066, 52659], [52720, 53819]], "num_segments": 14}
{"id": "sakura_emotion_277_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_277_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Turning away from spoiled food.", "Throwing an object in frustration.", "Laughing at a funny joke in a conversation.", "Reading a heartfelt goodbye letter."], "answer": "Laughing at a funny joke in a conversation.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_277.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[296, 1706], [2145, 3996], [4012, 4897], [5465, 6666], [7417, 11126], [11853, 15279], [15941, 18527], [18862, 23072], [23265, 25064], [25489, 26894], [28144, 29064], [29312, 34326], [34639, 36691], [36767, 38183], [38205, 39606], [40269, 43776], [43784, 44616], [44744, 45740], [46546, 48774]], "num_segments": 19}
{"id": "sakura_emotion_275_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_275_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["sad", "fear", "disgust", "happy"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_275.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[27, 4375], [5414, 6667], [6711, 9258], [9711, 14058], [15074, 16226], [16855, 18756], [19310, 23414], [23420, 28319], [29610, 30482], [31871, 33299], [33726, 34637], [35320, 37887]], "num_segments": 12}
{"id": "sakura_emotion_278_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_278_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["Head slightly pulled back with a terrified gaze, as if searching for an escape.", "Averted gaze with a grimacing mouth", "Wrinkled forehead and a forlorn expression", "A broad smile with sparkling eyes"], "answer": "A broad smile with sparkling eyes", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_278.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[452, 6870], [7512, 10924], [12000, 13195], [14647, 20431], [20488, 23508], [24446, 26202], [26398, 27302], [27445, 28288], [29845, 34628], [34965, 36774], [36812, 37720], [38347, 40033], [40247, 45725]], "num_segments": 13}
{"id": "sakura_emotion_278_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_278_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["fear", "angry", "sad", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_278.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[604, 8057], [8656, 10260], [10636, 14924], [16492, 19625], [20722, 26068], [26143, 27201], [27795, 29118], [29985, 34096], [34831, 36851], [36857, 44449], [44947, 46065]], "num_segments": 11}
{"id": "sakura_emotion_277_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_277_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "happy", "sad", "angry"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_277.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[684, 2402], [2571, 3418], [3754, 6409], [7021, 8023], [8437, 9482], [9682, 11662], [13035, 19658], [19985, 25621], [26073, 26904], [28055, 28855], [29761, 30602], [31127, 34000], [34069, 40934], [40974, 41973], [43921, 46793], [46816, 47905], [48387, 49249]], "num_segments": 17}
{"id": "sakura_emotion_279_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_279_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "sad", "disgust", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_279.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[388, 1410], [1495, 2521], [3122, 4386], [4456, 5604], [5811, 11454], [11945, 12887], [12995, 19843], [20301, 21103], [21355, 26858], [26893, 30337], [31599, 33307], [33873, 34769], [34911, 35953]], "num_segments": 13}
{"id": "sakura_emotion_280_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_280_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "fear", "sad", "disgust"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_280.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[340, 3715], [4273, 8794], [9890, 11044], [11472, 15321], [16114, 18461], [18488, 22906], [23353, 24575], [24651, 27951], [28586, 34690], [35548, 38501], [39211, 40067], [40352, 43180], [44257, 46543], [46886, 47725]], "num_segments": 14}
{"id": "sakura_emotion_281_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_281_masked_100pct.wav", "question": "From the provided sentences, which one best matches the emotional state of individuals who are experiencing the same emotion as the speaker?", "choices": ["It\u2019s hard to imagine things ever getting better.", "I\u2019m so excited, I just can\u2019t contain my happiness!", "I can\u2019t even look at this without feeling uncomfortable.", "Stop making excuses; this is entirely your fault!"], "answer": "I\u2019m so excited, I just can\u2019t contain my happiness!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_281.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[164, 1210], [2269, 9226], [9687, 10640], [10708, 12092], [13247, 18963], [19000, 21383], [21510, 22367], [22756, 25545], [25677, 26830], [26954, 28540], [29294, 31314], [33117, 33971], [34004, 35188], [35229, 40860]], "num_segments": 14}
{"id": "sakura_emotion_279_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_279_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Watching a horror movie alone in the dark.", "Watching a touching but sorrowful movie scene.", "A person yelling after being cut off in traffic.", "Winning a long-anticipated award or prize."], "answer": "A person yelling after being cut off in traffic.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_279.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[89, 6379], [6747, 13334], [13542, 14663], [15935, 19469], [20291, 21143], [21374, 24153], [24711, 28602], [28839, 29801], [30580, 32410], [33033, 34574], [34656, 36126]], "num_segments": 11}
{"id": "sakura_emotion_280_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_280_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["Head slightly pulled back with a terrified gaze, as if searching for an escape.", "Furrowed brows with slightly open mouth, as if about to shout.", "Wrinkled forehead and a forlorn expression", "Averted gaze with a grimacing mouth"], "answer": "Head slightly pulled back with a terrified gaze, as if searching for an escape.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_280.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[304, 4149], [5606, 8377], [8795, 9980], [10625, 12850], [13564, 17771], [19232, 27095], [27503, 28702], [29774, 35952], [36522, 38303], [38569, 41680], [42059, 43522], [44016, 47154]], "num_segments": 12}
{"id": "sakura_emotion_282_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_282_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["I\u2019m feeling so down, like nothing can lift my spirits.", "It\u2019s so dirty! Please clean it as quick as possible.", "I\u2019m really scared about what might happen next.", "How dare they treat me so unfairly like this!"], "answer": "I\u2019m really scared about what might happen next.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_282.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[563, 1658], [1713, 2593], [3114, 5161], [5495, 10089], [11030, 14713], [15069, 16422], [16573, 19407], [20211, 28145], [28441, 29981], [30130, 31082], [31315, 34191], [34574, 36289], [36761, 38873]], "num_segments": 13}
{"id": "sakura_emotion_281_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_281_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "sad", "angry", "disgust"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_281.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[273, 1850], [3137, 10049], [11183, 13922], [15222, 16551], [16834, 19001], [19439, 20277], [21738, 26460], [27434, 28515], [28666, 35183], [36118, 40136], [40183, 41847]], "num_segments": 11}
{"id": "sakura_emotion_283_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_283_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Listen attentively without interrupting to let them vent.", "Express genuine excitement for their good news or achievement.", "Avoid discussing further and respect their aversion to the topic.", "Encourage them to take deep breaths to relax."], "answer": "Encourage them to take deep breaths to relax.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_283.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[743, 2021], [3258, 4788], [5764, 6579], [8071, 14675], [14952, 16202], [16699, 17658], [18016, 20410], [20924, 21928], [22267, 23360], [23926, 24752], [24788, 29151], [29193, 30065], [30245, 31052], [31158, 34656], [34804, 36276]], "num_segments": 15}
{"id": "sakura_emotion_283_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_283_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "sad", "fear", "angry"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_283.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1368, 5725], [6004, 8048], [8614, 9689], [9901, 11609], [12115, 16296], [16607, 20643], [22200, 28433], [28481, 32267], [33435, 35342]], "num_segments": 9}
{"id": "sakura_emotion_282_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_282_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "sad", "angry", "happy"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_282.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[703, 3543], [3675, 6153], [6163, 7651], [8358, 9294], [9370, 10380], [10462, 11734], [12209, 13859], [14209, 15633], [16126, 18724], [19212, 22122], [22745, 23564], [23673, 27060], [27365, 28351], [28670, 29632], [29741, 32444], [32950, 34343], [34491, 35800], [36044, 37742]], "num_segments": 18}
{"id": "sakura_emotion_285_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_285_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["It\u2019s so dirty! Please clean it as quick as possible.", "I\u2019ve had enough of this nonsense.", "I can\u2019t breathe, I\u2019m just so afraid right now.", "I don\u2019t know how to move on from this loss."], "answer": "It\u2019s so dirty! Please clean it as quick as possible.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_285.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[684, 1728], [2067, 2954], [3325, 5566], [6972, 9635], [11097, 14289], [14489, 18556], [19082, 20127], [21029, 22442], [22607, 24451], [25034, 30483], [31584, 38273], [38288, 39974], [40267, 46413], [46861, 48282], [48359, 50048]], "num_segments": 15}
{"id": "sakura_emotion_285_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_285_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "angry", "disgust", "happy"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_285.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[365, 1605], [1921, 5773], [5926, 12269], [12653, 14039], [14084, 19881], [20306, 22345], [22943, 27988], [28141, 30575], [31438, 32506], [32727, 38558], [39493, 40310], [40337, 42176], [42862, 48582]], "num_segments": 13}
{"id": "sakura_emotion_286_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_286_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "angry", "disgust", "happy"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_286.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1693, 8009], [8073, 9487], [10281, 11199], [11915, 19908], [20765, 22654], [23700, 26424], [26511, 27376], [28604, 32125], [32834, 33784], [33843, 35063], [35068, 41376]], "num_segments": 11}
{"id": "sakura_emotion_286_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_286_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["It\u2019s so dirty! Please clean it as quick as possible.", "I\u2019m just so happy I could burst!", "I can\u2019t believe this is happening, I\u2019m so furious!", "I just can\u2019t stop thinking about all those bad memories."], "answer": "I can\u2019t believe this is happening, I\u2019m so furious!", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_286.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1718, 3634], [4728, 5948], [6614, 7662], [7750, 13027], [13257, 19083], [19519, 24925], [25110, 26801], [26992, 27981], [28816, 34042], [34787, 36728], [37256, 42205]], "num_segments": 11}
{"id": "sakura_emotion_287_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_287_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "sad", "happy", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_287.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[350, 1617], [1783, 9268], [9378, 10452], [10959, 13760], [14762, 20007], [20021, 24144], [25391, 28298], [28842, 31325], [31326, 33740], [34450, 36763], [37368, 38645], [38889, 39874], [39997, 41958]], "num_segments": 13}
{"id": "sakura_emotion_287_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_287_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["I feel so empty, like nothing matters anymore.", "How dare they treat me so unfairly like this!", "I can\u2019t even look at this without feeling uncomfortable.", "This is terrifying, I can\u2019t stop thinking about it."], "answer": "This is terrifying, I can\u2019t stop thinking about it.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_287.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[334, 1172], [1425, 4709], [5701, 6729], [7514, 8786], [9060, 9935], [10685, 13937], [15188, 16520], [17435, 18563], [19182, 20054], [20117, 22361], [22613, 29228], [29660, 30576], [30656, 32849], [33215, 35911], [35975, 37240], [37906, 40093], [40430, 43019]], "num_segments": 17}
{"id": "sakura_emotion_288_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_288_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "disgust", "sad", "angry"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_288.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[697, 1622], [2729, 4268], [4383, 5491], [6155, 10913], [10914, 17981], [18617, 19443], [19617, 26853], [27457, 32412], [32433, 33324], [33640, 36603]], "num_segments": 10}
{"id": "sakura_emotion_288_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_288_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Reading a heartfelt goodbye letter.", "Celebrating a birthday with friends and family.", "Reacting to a foul odor in a room.", "A parent scolding their child for misbehavior."], "answer": "Reading a heartfelt goodbye letter.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_288.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[664, 2297], [2487, 5029], [5691, 12325], [13555, 20363], [21457, 22777], [23334, 27824], [27840, 29731], [29738, 31567], [32398, 34042], [34362, 35914], [36002, 36915]], "num_segments": 11}
{"id": "sakura_emotion_284_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_284_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["sad", "angry", "fear", "disgust"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_284.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[503, 1698], [2294, 4171], [5205, 6238], [6513, 7727], [8739, 11780], [13117, 14431], [15201, 16868], [17333, 19314], [19315, 20286], [21003, 22043], [22169, 26628], [28264, 32707], [33139, 34633], [35437, 39609], [40514, 47352], [47456, 48515], [50223, 51079]], "num_segments": 17}
{"id": "sakura_emotion_289_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_289_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "fear", "disgust", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_289.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1853, 7722], [8391, 12279], [12953, 14916], [16127, 21911], [22490, 25078], [25582, 26547], [26908, 29352], [29544, 32174], [33178, 36091]], "num_segments": 9}
{"id": "sakura_emotion_284_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_284_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Clenched teeth with side facial muscles showing tension.", "Squinted eyes and a pinched nose", "Wrinkled forehead and a forlorn expression", "A broad smile with sparkling eyes"], "answer": "Clenched teeth with side facial muscles showing tension.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_284.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1641, 2466], [4387, 5902], [6237, 7490], [7644, 9619], [10491, 15347], [16591, 19128], [19312, 21955], [22913, 27743], [27921, 29657], [30751, 32918], [33935, 37643], [38361, 39959], [40000, 41150], [41350, 43863], [43899, 45271], [45661, 46989], [47122, 50721]], "num_segments": 17}
{"id": "sakura_emotion_289_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_289_masked_100pct.wav", "question": "Which facial expression best fits the emotion heard in the audio?", "choices": ["A wrinkled nose and raised upper lip", "Frozen facial expression with trembling lips and quickened breathing.", "A broad smile with sparkling eyes", "A heavy sigh with a frown and slumped posture"], "answer": "A broad smile with sparkling eyes", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_289.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[857, 4718], [4860, 6753], [7784, 9253], [10391, 13119], [13434, 14257], [14458, 19344], [20092, 21656], [21657, 27307], [27737, 31386], [31663, 32560], [33277, 36668]], "num_segments": 11}
{"id": "sakura_emotion_291_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_291_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "happy", "angry", "sad"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_291.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[462, 2851], [4197, 9136], [10454, 17792], [18198, 21383], [21489, 27114], [28216, 33883], [34301, 36065], [36727, 38275], [38941, 40522], [40815, 41880], [42946, 47716], [49075, 49901], [50070, 52321], [52435, 55028], [55974, 63423]], "num_segments": 15}
{"id": "sakura_emotion_291_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_291_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Avoid discussing further and respect their aversion to the topic.", "Stay calm and provide support to ease their anxiety.", "Suggest an activity to keep the positive energy flowing.", "Provide emotional support and avoid dismissing their sadness."], "answer": "Avoid discussing further and respect their aversion to the topic.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_291.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[67, 2995], [3452, 7413], [7552, 9283], [10085, 11024], [11253, 18366], [19444, 21659], [21912, 22729], [23051, 25634], [26427, 28929], [29550, 37299], [37479, 40212], [40430, 42312], [43188, 45273], [45750, 46606], [47469, 48852], [49084, 50522], [50996, 52870], [53367, 54996], [55054, 55992], [56078, 58529], [60994, 62932]], "num_segments": 21}
{"id": "sakura_emotion_290_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_290_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "angry", "happy", "sad"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_290.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[993, 1957], [2257, 4282], [4644, 5680], [6132, 7168], [8238, 10249], [10388, 11309], [11757, 16353], [17334, 21652], [21753, 22599], [23012, 25718], [25833, 31665], [31912, 34767], [34781, 37917], [38131, 39388], [40433, 43753], [44371, 45350]], "num_segments": 16}
{"id": "sakura_emotion_293_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_293_masked_100pct.wav", "question": "Which of the following sentences would most likely reflect the emotional state of people experiencing the same emotion as the speaker?", "choices": ["I feel so empty, like nothing matters anymore.", "I can\u2019t breathe, I\u2019m just so afraid right now.", "How dare they treat me so unfairly like this!", "I can\u2019t even look at this without feeling uncomfortable."], "answer": "I can\u2019t breathe, I\u2019m just so afraid right now.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_293.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1544, 3328], [4111, 5033], [5477, 8536], [8909, 11541], [11899, 13509], [14253, 17248], [18156, 21306], [21700, 22511], [23127, 25034], [25326, 32787], [32919, 35366], [35898, 37819], [37843, 38757]], "num_segments": 13}
{"id": "sakura_emotion_293_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_293_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["fear", "sad", "angry", "disgust"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_293.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[511, 2473], [3094, 8836], [9932, 12512], [12595, 15012], [15166, 16122], [17788, 22731], [22855, 23902], [24159, 30075], [30711, 37033], [37222, 38401]], "num_segments": 10}
{"id": "sakura_emotion_290_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_290_masked_100pct.wav", "question": "What facial expression most aligns with the emotion in the recording?", "choices": ["Averted gaze with a grimacing mouth", "A broad smile with sparkling eyes", "Flared nostrils with a tense expression", "Frozen facial expression with trembling lips and quickened breathing."], "answer": "Frozen facial expression with trembling lips and quickened breathing.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_290.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[57, 885], [1172, 8897], [9221, 12089], [12302, 16204], [16280, 17411], [18089, 19318], [19512, 21377], [22927, 24811], [24823, 30407], [30969, 32067], [33031, 36291], [36561, 38026], [38230, 41249], [41305, 42585], [43491, 44585]], "num_segments": 15}
{"id": "sakura_emotion_292_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_292_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "sad", "disgust", "angry"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_292.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[148, 967], [1066, 3452], [3740, 8683], [8705, 9739], [9896, 11158], [11233, 12256], [12693, 20332], [21677, 28840], [28956, 32835], [34253, 35202], [35202, 37965], [38178, 39204], [39220, 41615]], "num_segments": 13}
{"id": "sakura_emotion_292_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_292_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["Stop making excuses; this is entirely your fault!", "I can\u2019t breathe, I\u2019m just so afraid right now.", "I feel so empty, like nothing matters anymore.", "This makes me feel sick to my stomach."], "answer": "I can\u2019t breathe, I\u2019m just so afraid right now.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_292.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[480, 2184], [2338, 3775], [4109, 5532], [5668, 6998], [7409, 10687], [11332, 14380], [14991, 15801], [15991, 22323], [23531, 26847], [27322, 28637], [28965, 29850], [29902, 31200], [31300, 36843], [37021, 38005], [38169, 40383], [40541, 41377]], "num_segments": 16}
{"id": "sakura_emotion_296_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_296_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Suggest an activity to keep the positive energy flowing.", "Reassure them and offer a way to move past the uncomfortable    situation.", "Stay calm and provide support to ease their anxiety.", "Listen empathetically and let them express their feelings."], "answer": "Suggest an activity to keep the positive energy flowing.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_296.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[837, 2206], [2283, 4082], [4449, 5751], [6576, 12706], [13152, 15036], [15711, 16973], [17127, 18134], [18563, 21333], [21758, 23390], [24053, 29100], [29373, 30224], [30302, 31697], [31932, 34235], [34365, 35456], [35609, 37263], [37318, 38972]], "num_segments": 16}
{"id": "sakura_emotion_297_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_297_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["disgust", "angry", "fear", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_297.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2, 1685], [2032, 3802], [4467, 8584], [8995, 15930], [16184, 17068], [17405, 20930], [21312, 27758], [28438, 30750], [30899, 32426], [32526, 35638], [35983, 37805], [38080, 39117], [39521, 41257], [41736, 43417], [43528, 47790]], "num_segments": 15}
{"id": "sakura_emotion_296_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_296_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "sad", "fear", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_296.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[377, 2301], [2599, 7226], [7956, 9951], [10029, 12575], [13341, 15080], [15877, 17037], [17039, 22057], [22078, 25827], [26885, 28048], [28148, 29486], [29910, 31006], [31092, 32258], [32326, 33804], [33805, 39242]], "num_segments": 14}
{"id": "sakura_emotion_297_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_297_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Celebrate their joy with a cheerful response.", "Apologize and admit your mistake, if appropriate.", "Offer a comforting hug or words of reassurance.", "Avoid discussing further and respect their aversion to the topic."], "answer": "Celebrate their joy with a cheerful response.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_297.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1585, 8557], [10072, 11844], [12058, 13404], [13516, 16936], [18404, 19593], [20073, 21365], [22724, 27282], [28566, 29620], [29772, 37425], [37998, 39130], [41160, 43850], [45205, 46701], [47129, 47935]], "num_segments": 13}
{"id": "sakura_emotion_295_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_295_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "angry", "sad", "happy"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_295.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1588, 9304], [10747, 18400], [18542, 19715], [19797, 23231], [23598, 25185], [25372, 29185], [29833, 32053], [32256, 39535], [40094, 41119], [41640, 42693]], "num_segments": 10}
{"id": "sakura_emotion_294_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_294_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "sad", "fear", "happy"], "answer": "angry", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_294.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[571, 2625], [2649, 5388], [6830, 13068], [13680, 15170], [15885, 17864], [18409, 19635], [21474, 24287], [24778, 26661], [26735, 28331], [28453, 34709], [36037, 42434], [42727, 45830]], "num_segments": 12}
{"id": "sakura_emotion_294_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_294_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I don\u2019t know how to move on from this loss.", "This is the best day ever, I feel on top of the world!", "I\u2019m really scared about what might happen next.", "Stop making excuses; this is entirely your fault!"], "answer": "Stop making excuses; this is entirely your fault!", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_294.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[716, 2896], [3306, 5010], [5182, 8269], [8952, 9809], [10337, 12415], [12468, 15656], [16037, 20622], [20895, 22375], [22804, 23980], [24296, 26160], [26311, 30608], [30974, 31827], [32750, 34037], [35606, 36428], [37003, 40538], [41553, 43709], [43926, 45095], [45653, 46784]], "num_segments": 18}
{"id": "sakura_emotion_295_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_295_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Wrinkled forehead and a forlorn expression", "Furrowed brows with slightly open mouth, as if about to shout.", "A wrinkled nose and raised upper lip", "Tightly furrowed brow with trembling lips"], "answer": "A wrinkled nose and raised upper lip", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_295.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[139, 1155], [1654, 2487], [2959, 4718], [5159, 8144], [8272, 9770], [10089, 10922], [10982, 17071], [18782, 20308], [20542, 21449], [21547, 25752], [26238, 28185], [28356, 29870], [30621, 31487], [31959, 39490], [40193, 42073]], "num_segments": 15}
{"id": "sakura_emotion_300_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_300_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["angry", "sad", "disgust", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_300.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[575, 3088], [3479, 5700], [6895, 11898], [11994, 14398], [15769, 16761], [17088, 24640]], "num_segments": 6}
{"id": "sakura_emotion_299_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_299_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "fear", "disgust", "sad"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_299.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[116, 1531], [1605, 8962], [9057, 10134], [11434, 12772], [13273, 15880], [15986, 21705], [22535, 29986], [30195, 31321], [31782, 32895], [33258, 34769], [35672, 37329], [37693, 38619], [39381, 41571], [41913, 43913], [44918, 45780], [46037, 47556], [47625, 54844], [55548, 59907]], "num_segments": 18}
{"id": "sakura_emotion_300_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_300_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Give them space to cool off before engaging further.", "Smile and engage positively in the conversation.", "Encourage them to take deep breaths to relax.", "Express understanding calmly and suggest leaving the unpleasant environment."], "answer": "Encourage them to take deep breaths to relax.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_300.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[667, 3807], [4232, 5050], [5366, 9171], [9546, 10589], [12100, 12988], [13557, 14797], [15184, 17418], [17958, 20296], [20922, 23737], [24415, 25460]], "num_segments": 10}
{"id": "sakura_emotion_298_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_298_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "sad", "happy", "fear"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_298.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1175, 9051], [10425, 11767], [12380, 13183], [13258, 16611], [16807, 18194], [18551, 19517], [19760, 23912], [23914, 25078], [25438, 26673], [28119, 30432], [30811, 31733], [31894, 32711], [32765, 37269], [37475, 39620], [40989, 41860], [43202, 44315]], "num_segments": 16}
{"id": "sakura_emotion_298_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_298_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Offer congratulations or compliments to share their happiness.", "Listen attentively without interrupting to let them vent.", "Hold their hand or offer some physical reassurance.", "Suggest spending some time together to cheer them up."], "answer": "Offer congratulations or compliments to share their happiness.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_298.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1225, 2664], [2721, 4165], [4576, 12320], [12723, 16413], [17266, 23589], [23798, 26363], [26642, 29994], [30309, 31257], [31633, 33979], [34277, 40087], [41973, 44536]], "num_segments": 11}
{"id": "sakura_emotion_302_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_302_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "happy", "fear", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_302.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[472, 7863], [8133, 10513], [10876, 12660], [13584, 20455], [21463, 24855], [25093, 26939], [27907, 33521], [34441, 35903], [36139, 41206], [41288, 48752], [49109, 53021], [53500, 54499], [54648, 55580], [55995, 57226], [57314, 58504], [58779, 66315]], "num_segments": 16}
{"id": "sakura_emotion_299_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_299_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["This is the best day ever, I feel on top of the world!", "This makes me feel sick to my stomach.", "I can\u2019t shake the feeling that something bad is coming.", "I\u2019m feeling so down, like nothing can lift my spirits."], "answer": "This makes me feel sick to my stomach.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_299.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1061, 2742], [2832, 5714], [6783, 11405], [11625, 16976], [17396, 18760], [18822, 22022], [22277, 30055], [30149, 31803], [31917, 33998], [34661, 42449], [42817, 44492], [45702, 50292], [51009, 57512], [58575, 59760]], "num_segments": 14}
{"id": "sakura_emotion_304_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_304_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "sad", "disgust", "fear"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_304.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[80, 2069], [3346, 4230], [5047, 6717], [6741, 9218], [9678, 13040], [14128, 15069], [15645, 17030], [17817, 19059], [19170, 22970]], "num_segments": 9}
{"id": "sakura_emotion_301_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_301_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "sad", "angry", "happy"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_301.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1325, 3328], [4035, 5191], [5618, 10441], [12273, 13607], [14464, 15323], [15861, 20361], [21189, 23220], [23473, 24881], [25408, 32926], [33677, 34647], [35649, 39927], [40195, 44500], [45688, 46977], [47521, 54095], [54538, 55588], [55900, 56761], [56817, 57737], [60151, 65501], [65650, 66882]], "num_segments": 19}
{"id": "sakura_emotion_302_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_302_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Avoid discussing further and respect their aversion to the topic.", "Celebrate their joy with a cheerful response.", "Hold their hand or offer some physical reassurance.", "Offer a comforting hug or words of reassurance."], "answer": "Offer a comforting hug or words of reassurance.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_302.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1263, 8698], [8846, 9843], [9970, 15496], [16172, 19214], [19397, 20301], [20303, 24676], [25756, 27677], [28928, 34638], [36201, 38066], [38244, 41300], [41544, 42372], [42784, 47025], [48681, 49846], [50008, 53751], [53760, 55285], [55740, 60396], [60627, 62112], [62329, 63782], [63954, 66142]], "num_segments": 19}
{"id": "sakura_emotion_301_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_301_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Winning a long-anticipated award or prize.", "A person yelling after being cut off in traffic.", "Turning away from spoiled food.", "A person crying after a breakup."], "answer": "A person crying after a breakup.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_301.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[762, 1681], [3381, 4880], [5816, 9957], [10608, 12748], [12811, 16580], [16993, 17816], [18642, 20952], [20962, 22727], [23826, 25943], [26416, 27725], [28707, 30316], [30376, 32189], [32887, 40568], [41002, 42601], [43561, 50482], [51430, 53889], [54170, 58914], [59374, 61877], [63368, 66512]], "num_segments": 19}
{"id": "sakura_emotion_303_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_303_masked_100pct.wav", "question": "Which situation best corresponds to the emotion conveyed in the speech?", "choices": ["Walking alone in a dark alley at night.", "A heated argument between colleagues.", "Rejecting a tasteless meal with a grimace.", "A person smiling after receiving good news."], "answer": "Walking alone in a dark alley at night.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_303.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1365, 2268], [2959, 5578], [6400, 9526], [10251, 13715], [14400, 21336], [21350, 22788], [23436, 25991], [26545, 28774], [29782, 36151], [36505, 40060], [40094, 46458], [46736, 51340], [53187, 60372], [61131, 62098], [62861, 70281], [70591, 72523], [74698, 76306], [76620, 78381], [78878, 81001], [81407, 83010], [83194, 84867], [85681, 86691], [87087, 90876], [92347, 93472]], "num_segments": 24}
{"id": "sakura_emotion_304_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_304_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["I can\u2019t shake the feeling that something bad is coming.", "It\u2019s hard to imagine things ever getting better.", "I\u2019m so excited, I just can\u2019t contain my happiness!", "That\u2019s just revolting, I can\u2019t believe it."], "answer": "That\u2019s just revolting, I can\u2019t believe it.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_304.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[571, 2266], [2558, 4050], [4349, 12019], [12124, 13332], [13757, 19006], [20041, 21015], [21571, 22486]], "num_segments": 7}
{"id": "sakura_emotion_306_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_306_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["angry", "sad", "disgust", "fear"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_306.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1133, 2578], [3241, 4275], [4517, 5908], [6339, 10029], [11184, 16801], [17420, 18626], [19426, 20852], [20918, 22212], [22596, 23977], [24597, 28535], [29074, 34530]], "num_segments": 11}
{"id": "sakura_emotion_305_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_305_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "sad", "disgust", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_305.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[739, 1746], [2021, 3186], [4596, 5521], [6303, 7289], [7852, 14327], [14548, 15546], [15841, 17474], [18003, 19753], [19803, 21717], [21815, 23447], [23650, 28495], [28560, 29377], [30037, 30877], [31798, 34177], [34474, 35633], [36046, 36911], [37808, 39341], [39563, 46030], [47742, 49030], [49303, 50151], [50379, 51598], [51683, 59400]], "num_segments": 22}
{"id": "sakura_emotion_305_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_305_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Averted gaze with a grimacing mouth", "Clenched teeth with side facial muscles showing tension.", "Tightly furrowed brow with trembling lips", "A broad smile with sparkling eyes"], "answer": "A broad smile with sparkling eyes", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_305.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[560, 2936], [3746, 7360], [7833, 12265], [12416, 16233], [16413, 17581], [17633, 20761], [21410, 27800], [27923, 30132], [30271, 34615], [35359, 36797], [37654, 42531], [43777, 44914], [46349, 49736], [50878, 52205], [52786, 54782], [56064, 57597], [58166, 60051]], "num_segments": 17}
{"id": "sakura_emotion_306_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_306_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Hold their hand or offer some physical reassurance.", "Suggest spending some time together to cheer them up.", "Smile and engage positively in the conversation.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable."], "answer": "Suggest spending some time together to cheer them up.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_306.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[600, 6070], [6331, 7256], [7602, 9455], [9762, 13728], [14887, 21832], [22966, 23984], [24015, 28599], [29314, 33662], [33828, 35110]], "num_segments": 9}
{"id": "sakura_emotion_303_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_303_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "disgust", "happy", "sad"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_303.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1184, 5447], [6425, 8770], [9283, 10365], [11385, 13350], [15154, 21864], [21910, 23086], [23610, 24809], [25079, 31509], [31729, 33759], [33797, 34766], [35089, 36149], [36348, 40505], [41438, 43828], [44774, 48313], [48611, 49418], [50772, 55950], [57338, 64796], [66004, 67990], [69419, 73167], [74994, 76161], [76176, 82239], [82310, 84141], [84508, 86786], [86974, 90571], [90958, 93084]], "num_segments": 25}
{"id": "sakura_emotion_308_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_308_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["I feel like I\u2019m in danger, and I don\u2019t know what to do.", "This situation is really starting to piss me off!", "I\u2019m feeling so down, like nothing can lift my spirits.", "I\u2019m just so happy I could burst!"], "answer": "This situation is really starting to piss me off!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_308.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[678, 4067], [4877, 8354], [9179, 11366]], "num_segments": 3}
{"id": "sakura_emotion_308_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_308_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["disgust", "fear", "sad", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_308.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[833, 2333], [2406, 4157], [4433, 5917], [6572, 8844], [9939, 11384]], "num_segments": 5}
{"id": "sakura_emotion_307_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_307_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I can\u2019t even look at this without feeling uncomfortable.", "This situation is really starting to piss me off!", "I\u2019m so excited, I just can\u2019t contain my happiness!", "I\u2019m really scared about what might happen next."], "answer": "I can\u2019t even look at this without feeling uncomfortable.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_307.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[416, 1299], [2515, 4173], [5213, 6844], [7354, 10560], [11362, 14875], [15127, 16429], [16769, 18748], [19429, 20663], [20761, 21700], [21732, 23803], [24491, 30366], [31154, 32414], [33767, 35891], [36821, 37655], [37800, 40187], [40876, 43144], [43495, 51379], [52537, 57021], [57472, 61624], [62285, 63322], [64035, 67508], [68053, 69354], [69416, 75155], [75278, 76137], [77108, 79151], [79199, 80712]], "num_segments": 26}
{"id": "sakura_emotion_307_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_307_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "disgust", "happy", "fear"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_307.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1163, 8822], [9569, 10486], [11461, 14257], [15828, 21671], [22822, 24007], [24419, 25386], [26409, 33254], [33433, 34834], [34986, 39151], [39638, 40456], [41844, 42859], [43563, 48941], [49676, 51517], [51643, 53657], [53761, 54943], [55293, 56296], [56865, 59578], [59747, 61786], [62371, 65730], [66138, 67050], [67288, 68914], [69248, 70965], [71646, 75568], [77130, 79691]], "num_segments": 24}
{"id": "sakura_emotion_311_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_311_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["It\u2019s hard to imagine things ever getting better.", "I\u2019m so excited, I just can\u2019t contain my happiness!", "I can\u2019t shake the feeling that something bad is coming.", "How dare they treat me so unfairly like this!"], "answer": "I\u2019m so excited, I just can\u2019t contain my happiness!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_311.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[65, 1841], [2782, 3804], [3953, 5065], [5251, 6447], [6949, 10845], [11681, 13106], [13635, 16990], [17858, 20265], [21171, 22817]], "num_segments": 9}
{"id": "sakura_emotion_311_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_311_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["disgust", "fear", "happy", "angry"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_311.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[349, 1991], [2086, 2916], [3476, 5694], [5999, 8589], [9626, 10995], [11716, 13114], [13298, 14238], [14590, 21087], [21710, 22831]], "num_segments": 9}
{"id": "sakura_emotion_309_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_309_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["Furrowed brows with slightly open mouth, as if about to shout.", "Downturned mouth and teary eyes", "Frozen facial expression with trembling lips and quickened breathing.", "Averted gaze with a grimacing mouth"], "answer": "Frozen facial expression with trembling lips and quickened breathing.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_309.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[421, 1446], [1641, 3428], [4055, 7361], [7548, 9157], [9348, 14782], [15058, 16494], [16569, 18913], [19280, 22850], [23144, 25142], [25629, 32816], [33671, 34560], [34707, 36688]], "num_segments": 12}
{"id": "sakura_emotion_309_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_309_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["fear", "happy", "disgust", "sad"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_309.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[863, 2054], [2177, 3827], [3954, 7041], [7103, 10757], [10970, 12340], [12810, 19344], [19622, 20853], [21079, 28003], [28124, 32295], [32716, 33577], [33633, 35699], [36336, 37229]], "num_segments": 12}
{"id": "sakura_emotion_313_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_313_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["fear", "happy", "sad", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_313.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[661, 6617], [7170, 7974], [8452, 9387], [9928, 10931], [11008, 13933], [15265, 17415], [18084, 20316], [21106, 23215], [23274, 24839]], "num_segments": 9}
{"id": "sakura_emotion_310_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_310_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "disgust", "fear", "angry"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_310.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1026, 3224], [4204, 5156], [5504, 6899], [7409, 9069], [9954, 15368], [15816, 17384], [18044, 22751], [23201, 29147], [29602, 31067], [31981, 36000], [36830, 38263], [38755, 39736], [40476, 42727], [44633, 46701], [47387, 48604], [48776, 49830], [50356, 53219], [54003, 54861], [54936, 60559], [61673, 64512], [65166, 70750], [70878, 72539], [73047, 75453], [77315, 78301], [78342, 79523], [79832, 85985], [85989, 86881], [87025, 88368], [88830, 90252], [91494, 93384], [93639, 94731], [96728, 101952], [102083, 107162], [107169, 109365], [109915, 114574], [114670, 117247], [118193, 119984], [120038, 123754]], "num_segments": 38}
{"id": "sakura_emotion_312_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_312_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Winning a long-anticipated award or prize.", "Seeing an unpleasant image online.", "Slamming a door after a disagreement.", "Facing an aggressive dog on the street."], "answer": "Facing an aggressive dog on the street.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_312.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[635, 3279], [3296, 6181], [6280, 8691], [9397, 13113], [13933, 19426], [19977, 23631], [24560, 25585], [25597, 28160]], "num_segments": 8}
{"id": "sakura_emotion_312_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_312_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "disgust", "angry", "happy"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_312.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[10, 5796], [6038, 6928], [7885, 13289], [13575, 14555], [14598, 15782], [15823, 23056], [23208, 24603], [25388, 29199]], "num_segments": 8}
{"id": "sakura_emotion_315_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_315_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "fear", "happy", "angry"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_315.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[558, 1622], [1706, 2513], [2970, 4504], [4624, 9348], [9364, 10841], [11045, 11848], [11946, 13610]], "num_segments": 7}
{"id": "sakura_emotion_313_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_313_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Listen empathetically and let them express their feelings.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Apologize and admit your mistake, if appropriate.", "Offer reassurance and remind them they are safe."], "answer": "Apologize and admit your mistake, if appropriate.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_313.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[280, 2002], [2602, 4513], [4647, 6674], [7266, 10370], [10442, 12565], [12863, 18862], [19154, 23573], [23996, 24856]], "num_segments": 8}
{"id": "sakura_emotion_315_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_315_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Avoid discussing further and respect their aversion to the topic.", "Offer reassurance and remind them they are safe.", "Celebrate their joy with a cheerful response.", "Suggest spending some time together to cheer them up."], "answer": "Celebrate their joy with a cheerful response.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_315.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[415, 1538], [1931, 6141], [6249, 13132], [13462, 14593]], "num_segments": 4}
{"id": "sakura_emotion_310_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_310_masked_100pct.wav", "question": "Which facial expression best fits the emotion heard in the audio?", "choices": ["Wrinkled forehead and a forlorn expression", "Squinted eyes and a pinched nose", "Wide-open eyes with raised eyebrows and slightly parted lips.", "A warm, genuine smile with slightly tilted head"], "answer": "A warm, genuine smile with slightly tilted head", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_310.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[99, 1056], [1186, 2864], [3580, 4659], [5157, 5961], [6452, 8394], [8922, 10364], [10665, 18183], [19101, 20376], [21514, 29463], [30971, 35495], [35928, 37298], [38619, 39634], [39913, 40785], [42461, 44687], [46162, 48415], [48927, 50503], [52299, 56654], [56691, 58950], [61373, 63016], [63157, 66677], [67717, 74095], [75681, 79806], [80814, 82637], [84000, 88458], [88544, 93171], [93526, 94776], [95719, 99661], [100914, 103191], [103725, 109201], [109389, 111169], [111431, 118048], [118971, 120142], [120920, 122185], [122672, 124086]], "num_segments": 34}
{"id": "sakura_emotion_319_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_319_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "fear", "sad", "happy"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_319.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[517, 2282], [2560, 10345], [10922, 11920], [11935, 13816], [15386, 18400], [19190, 20164], [20939, 24439], [24983, 26353], [26508, 27699]], "num_segments": 9}
{"id": "sakura_emotion_314_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_314_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["How dare they treat me so unfairly like this!", "I can\u2019t stop smiling, everything feels so right.", "I\u2019m really scared about what might happen next.", "This makes me feel sick to my stomach."], "answer": "This makes me feel sick to my stomach.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_314.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[256, 2221], [2423, 10131], [10495, 12168], [13509, 14380], [15267, 16834], [17336, 18648], [19545, 22078], [22112, 23009], [23764, 24694], [25922, 29134], [29385, 30499], [32456, 35451], [35505, 36523], [36731, 44458], [45649, 46536], [46682, 49182], [51725, 55031], [55955, 62434], [62442, 64916], [65567, 69395], [69836, 71811], [72590, 75483], [76738, 77641], [77809, 80808], [81223, 82111], [83383, 84878], [85145, 86376]], "num_segments": 27}
{"id": "sakura_emotion_314_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_314_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["disgust", "angry", "happy", "sad"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_314.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1014, 2065], [3390, 7827], [9742, 11103], [11193, 14204], [15100, 19992], [21650, 25903], [27234, 29540], [30747, 35601], [35640, 38032], [38830, 42505], [42628, 49045], [50222, 52159], [52591, 54608], [54871, 55722], [56033, 59477], [59698, 60996], [61274, 62537], [62945, 64195], [64699, 65665], [65813, 68418], [69347, 70330], [71604, 73999], [74649, 75855], [76416, 78019], [79120, 80909], [81327, 82181], [82613, 83431], [83966, 84841], [85005, 86052]], "num_segments": 29}
{"id": "sakura_emotion_316_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_316_masked_100pct.wav", "question": "Which facial expression best matches the emotion in the audio?", "choices": ["A sharp, piercing gaze and compressed lips", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "Eyes crinkling with an open-mouthed laugh", "Frozen facial expression with trembling lips and quickened breathing."], "answer": "Frozen facial expression with trembling lips and quickened breathing.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_316.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[242, 1849], [1968, 3325], [4300, 7674], [8526, 13444], [13470, 14361], [14865, 16051], [16175, 17130], [17705, 19666], [20414, 21705], [22128, 26260], [26416, 27768], [28519, 30902], [31232, 32606], [33678, 39906], [39930, 41781], [42607, 45064], [45232, 46228], [46765, 47722], [48960, 51363], [51428, 57881], [57921, 62447], [62747, 68166], [68231, 69834], [70667, 73684], [74549, 75370]], "num_segments": 25}
{"id": "sakura_emotion_318_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_318_masked_100pct.wav", "question": "Which facial expression best fits the emotion heard in the audio?", "choices": ["A wrinkled nose and raised upper lip", "Tightly furrowed brow with trembling lips", "Eyes gazing downward with trembling lips", "Eyes crinkling with an open-mouthed laugh"], "answer": "Tightly furrowed brow with trembling lips", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_318.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1400, 7447], [7666, 8646], [8891, 10657], [10814, 16634], [17214, 18081], [18524, 21302], [22266, 23885], [24345, 28956], [29126, 32330], [32773, 36422], [36618, 37759]], "num_segments": 11}
{"id": "sakura_emotion_317_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_317_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "sad", "happy", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_317.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[294, 2838], [2985, 8417], [9039, 9913], [10374, 14163], [15056, 16425], [17030, 18337], [18442, 20574], [21907, 23224], [23432, 26199], [27720, 29158], [29176, 34890], [36392, 37442], [37472, 38359], [38798, 40426], [40822, 42907], [43618, 45207], [46259, 50143], [51375, 52515], [52886, 60255], [62187, 69751], [70049, 75660], [77144, 83458], [84128, 86607], [86899, 88021], [88029, 91641], [92009, 96434], [96733, 97612], [97971, 100860], [100883, 101939]], "num_segments": 29}
{"id": "sakura_emotion_319_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_319_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Winning a long-anticipated award or prize.", "Attending a close friend's funeral.", "Walking alone in a dark alley at night.", "Rejecting a tasteless meal with a grimace."], "answer": "Attending a close friend's funeral.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_319.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[160, 3861], [5489, 11469], [11894, 13247], [13805, 14624], [15182, 17352], [18060, 23552], [24011, 27343]], "num_segments": 7}
{"id": "sakura_emotion_318_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_318_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["sad", "fear", "disgust", "happy"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_318.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1208, 2030], [2235, 3083], [3294, 5502], [5689, 10687], [12062, 13334], [13371, 14633], [14806, 15770], [16195, 22715], [22818, 23827], [24037, 30897], [31590, 36516]], "num_segments": 11}
{"id": "sakura_emotion_316_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_316_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["sad", "fear", "disgust", "angry"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_316.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2295, 4469], [6921, 10888], [11386, 14771], [16418, 20618], [20644, 21772], [21784, 22989], [23097, 28108], [29155, 35458], [36575, 39579], [39701, 41416], [42371, 45414], [46272, 49514], [50733, 53877], [54055, 57177], [57902, 61989], [62897, 63884], [64110, 66475], [66568, 68404], [68855, 69699], [69769, 75938]], "num_segments": 20}
{"id": "sakura_emotion_317_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_317_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Reacting to a sudden loud noise in an empty house.", "Saying goodbye at an airport.", "Throwing an object in frustration.", "Winning a long-anticipated award or prize."], "answer": "Reacting to a sudden loud noise in an empty house.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_317.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[885, 4888], [4923, 5727], [5737, 7137], [7634, 9852], [10707, 11701], [12268, 17449], [18204, 20802], [22244, 23860], [24366, 25293], [25630, 26515], [26906, 29065], [30021, 35641], [35837, 36710], [37516, 38431], [38657, 44234], [45732, 47047], [47799, 49078], [49306, 50674], [51915, 53031], [53044, 55436], [56467, 58052], [58378, 63910], [64297, 68475], [69094, 71235], [71465, 72844], [72886, 73884], [74259, 76477], [77623, 78636], [78649, 84646], [85374, 86526], [86558, 88148], [88294, 91732], [92451, 94914], [95538, 97371], [97668, 102744]], "num_segments": 35}
{"id": "sakura_emotion_325_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_325_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["happy", "sad", "disgust", "angry"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_325.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[527, 2544], [2598, 5563], [6522, 9565], [9881, 10920], [11046, 12392], [12589, 16863], [17078, 23832]], "num_segments": 7}
{"id": "sakura_emotion_321_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_321_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["fear", "happy", "angry", "sad"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_321.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[148, 2911], [4310, 5921], [7138, 10905], [11636, 17196], [18863, 22580], [23998, 24929], [25006, 27473], [28773, 29977], [30312, 31406], [31576, 32637], [33021, 38192], [38552, 42289], [43933, 46209], [46932, 48361], [48756, 53783], [53934, 58983], [60597, 61579], [63655, 65197], [65296, 73014], [73228, 77370], [79686, 87633], [89509, 93785], [95792, 101038], [102219, 106284], [106580, 108709], [109687, 115312], [115688, 119437], [119915, 122916], [123259, 126087], [126731, 128654], [129503, 132401], [132713, 134443], [134444, 137060], [137087, 140813], [140875, 142302], [142590, 149593], [150414, 151488]], "num_segments": 37}
{"id": "sakura_emotion_323_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_323_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Attending a close friend's funeral.", "Watching a horror movie alone in the dark.", "Rejecting a tasteless meal with a grimace.", "Winning a long-anticipated award or prize."], "answer": "Rejecting a tasteless meal with a grimace.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_323.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[180, 1934], [2739, 3950], [3962, 4783], [4972, 12083], [13126, 15078], [15085, 21428], [21440, 23191], [23312, 24566]], "num_segments": 8}
{"id": "sakura_emotion_320_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_320_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "fear", "sad", "disgust"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_320.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[336, 1706], [3388, 4222], [4392, 6013], [6113, 11214], [11906, 13679], [14568, 15716], [16155, 16994], [18169, 23075], [24849, 26703], [26729, 27900], [30023, 31588], [32382, 34007], [34324, 38546], [39244, 40359], [40498, 45836], [48006, 50006], [51815, 59331], [59955, 61864], [61873, 63983], [65461, 71946]], "num_segments": 20}
{"id": "sakura_emotion_325_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_325_masked_100pct.wav", "question": "Considering the emotion expressed in the audio, which of the following facial expressions would align most closely with it?", "choices": ["Tightly pressed lips with glaring eyes", "Relaxed facial muscles with a cheerful grin", "A drooping gaze with a slack jaw", "Squinted eyes and a pinched nose"], "answer": "Relaxed facial muscles with a cheerful grin", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_325.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2082, 9541], [9991, 11940], [12454, 15265], [16074, 17698], [17838, 20421], [20681, 21635], [21741, 22906], [23154, 24174]], "num_segments": 8}
{"id": "sakura_emotion_322_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_322_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["disgust", "sad", "angry", "fear"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_322.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[566, 1726], [2701, 4095], [5175, 6281], [6993, 9353], [10820, 13108], [13927, 16346], [16475, 17358], [18195, 21640], [22048, 23846], [24660, 26151], [26336, 28476], [28577, 29638], [30606, 32549], [32935, 36842], [36896, 39500], [40260, 41214], [41543, 48099], [48146, 52051], [52611, 53979], [55350, 56214], [57321, 61032], [61126, 64797], [64831, 66642], [66869, 68047], [68802, 69641], [69819, 70855], [70978, 71960], [72219, 73662], [73790, 76780], [77993, 80063], [80479, 85441], [85453, 86795], [86832, 87790], [88232, 95895], [96507, 100265], [100830, 104472], [105217, 106925], [108238, 109157]], "num_segments": 38}
{"id": "sakura_emotion_320_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_320_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["Facing an aggressive dog on the street.", "Reading a heartfelt goodbye letter.", "Throwing an object in frustration.", "A person smiling after receiving good news."], "answer": "Facing an aggressive dog on the street.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_320.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[479, 3166], [4488, 5435], [6314, 7989], [8205, 12268], [12841, 13765], [14320, 15529], [15781, 21248], [22754, 24113], [24146, 25265], [25572, 26897], [27858, 30175], [30404, 31546], [32330, 33910], [36795, 38843], [39083, 40624], [40975, 42041], [43241, 46503], [47327, 50788], [51223, 54036], [54997, 60972], [61627, 67998], [68686, 71731]], "num_segments": 22}
{"id": "sakura_emotion_322_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_322_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Reassure them and offer a way to move past the uncomfortable    situation.", "Listen empathetically and let them express their feelings.", "Offer reassurance and remind them they are safe.", "Suggest an activity to keep the positive energy flowing."], "answer": "Reassure them and offer a way to move past the uncomfortable    situation.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_322.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[650, 1923], [3326, 6363], [7138, 8456], [9693, 12179], [12964, 18693], [19298, 22912], [22961, 23807], [24651, 27857], [27915, 31873], [32411, 36513], [37473, 41508], [43256, 44447], [44721, 51092], [51563, 53709], [54217, 56352], [56857, 57946], [58137, 59203], [59491, 61736], [61834, 63070], [63764, 65022], [65119, 69482], [69741, 70675], [71238, 79232], [79529, 80400], [80623, 83267], [84349, 85589], [86459, 87338], [89023, 93561], [94074, 95269], [95358, 96734], [96795, 98810], [98831, 101312], [101864, 102716], [103312, 104461], [105754, 107109], [108805, 110108]], "num_segments": 36}
{"id": "sakura_emotion_323_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_323_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["disgust", "angry", "sad", "happy"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_323.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[287, 2322], [2423, 3780], [4712, 5628], [7078, 11751], [12578, 17104], [17499, 18997], [19134, 21017], [21389, 25174]], "num_segments": 8}
{"id": "sakura_emotion_321_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_321_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["A drooping gaze with a slack jaw", "Tightly furrowed brow with trembling lips", "Averted gaze with a grimacing mouth", "A warm, genuine smile with slightly tilted head"], "answer": "A warm, genuine smile with slightly tilted head", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_321.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[952, 6802], [8576, 9410], [9811, 16297], [16613, 20997], [21607, 22536], [23561, 27118], [27570, 29528], [30668, 33674], [34795, 35780], [36091, 37264], [37766, 39299], [41345, 44464], [45531, 50518], [51119, 54767], [55458, 61575], [62186, 65844], [66146, 68816], [70270, 73466], [73580, 75699], [76110, 79526], [79826, 86817], [87058, 88223], [89524, 90730], [90774, 91955], [92845, 93953], [94739, 97813], [98506, 102153], [102447, 103295], [103359, 104647], [105811, 109127], [109678, 112219], [112975, 115888], [117872, 119861], [121425, 129062], [129254, 130205], [130336, 133217], [134830, 137992], [138277, 140113], [141214, 145005], [145797, 148687], [149685, 151396]], "num_segments": 41}
{"id": "sakura_emotion_324_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_324_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "sad", "angry", "disgust"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_324.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[985, 1949], [2958, 4663], [4991, 9829], [10403, 14281], [14503, 21824], [22349, 28681], [29165, 30765], [31019, 35072], [37261, 39128], [39836, 40929], [42206, 43845], [44120, 45574], [45617, 52472], [52869, 54525], [55248, 57223], [58101, 59991], [61030, 61982], [63028, 67512], [68612, 70557], [71980, 76305], [77552, 80286], [80867, 84413], [85473, 86457], [87865, 90672], [90807, 92783], [95793, 96852], [98104, 99057], [99967, 100910], [102098, 108585], [109378, 111157]], "num_segments": 30}
{"id": "sakura_emotion_324_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_324_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["Slamming a door after a disagreement.", "Celebrating a birthday with friends and family.", "Facing an aggressive dog on the street.", "Attending a close friend's funeral."], "answer": "Celebrating a birthday with friends and family.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_324.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1158, 3029], [3073, 4709], [5174, 7288], [8729, 9607], [10248, 11338], [11779, 18006], [18203, 19276], [21151, 22027], [22621, 28231], [28239, 29250], [29420, 30827], [31912, 33904], [34444, 35873], [36362, 43251], [44886, 46014], [46124, 52458], [53486, 57534], [58309, 60901], [61466, 62316], [63324, 65607], [65968, 67483], [67950, 74827], [75876, 76986], [77375, 79933], [80495, 83100], [83368, 90295], [90591, 91416], [92681, 93553], [93645, 95615], [95768, 100156], [101645, 104060], [104328, 105596], [106247, 109611], [110433, 112049]], "num_segments": 34}
{"id": "sakura_emotion_327_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_327_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "angry", "happy", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_327.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[320, 1274], [1383, 4578], [5105, 10624], [11459, 14270], [14416, 16256], [16467, 18573], [18783, 21093], [21292, 22235], [23183, 31123], [33125, 34852], [36146, 41498], [41989, 43771], [44485, 46407], [46728, 47547], [47998, 55179], [55670, 56761], [58390, 60729], [60816, 63851], [64966, 66063], [68205, 70613], [72042, 76056], [76092, 77179]], "num_segments": 22}
{"id": "sakura_emotion_326_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_326_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["fear", "angry", "happy", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_326.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[132, 3180], [4462, 5298], [6898, 9501], [9593, 12214], [12344, 15863], [15972, 19267], [19450, 20355], [20668, 23226], [24161, 30324], [30439, 31509], [31941, 33658], [34354, 40234], [40743, 42175], [42343, 44036], [45246, 48046], [48274, 50063], [50121, 53039]], "num_segments": 17}
{"id": "sakura_emotion_327_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_327_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["A heated argument between colleagues.", "Reacting to a foul odor in a room.", "Saying goodbye at an airport.", "Reacting to a sudden loud noise in an empty house."], "answer": "Saying goodbye at an airport.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_327.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[248, 2718], [5236, 6892], [7677, 15300], [16791, 18773], [19779, 20731], [21435, 23911], [25235, 26090], [26874, 28568], [29077, 30021], [30049, 31345], [32338, 40227], [40786, 42352], [42641, 43924], [44321, 51920], [52698, 55071], [55078, 55991], [56372, 58638], [59303, 67176], [67388, 69626], [69650, 70690], [70774, 76391], [77148, 78559]], "num_segments": 22}
{"id": "sakura_emotion_326_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_326_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Apologize and admit your mistake, if appropriate.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Listen empathetically and let them express their feelings.", "Encourage them to take deep breaths to relax."], "answer": "Listen empathetically and let them express their feelings.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_326.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[391, 1873], [2190, 3474], [3844, 7263], [7788, 12191], [13204, 17613], [18474, 20945], [21182, 22151], [22565, 25724], [25865, 27249], [27269, 31297], [31613, 33083], [33113, 35255], [35505, 43043], [43059, 44429], [44449, 48428], [49557, 50702], [51499, 53193]], "num_segments": 17}
{"id": "sakura_emotion_329_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_329_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "fear", "disgust", "happy"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_329.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1777, 3030], [3466, 7647], [9048, 16254], [17058, 18814], [20084, 27366], [27420, 28751], [29113, 35175], [35775, 41173], [41201, 42656], [43112, 48491], [49001, 50446], [52120, 53716], [54958, 56714], [57201, 58705], [59153, 62818], [63248, 66464], [68326, 70959], [71450, 72490], [72674, 73868], [74603, 75476], [76176, 77363], [77502, 84370], [84684, 90867], [91647, 93654], [94443, 99579], [99603, 100462]], "num_segments": 26}
{"id": "sakura_emotion_331_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_331_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["fear", "sad", "disgust", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_331.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[998, 1809], [2108, 4549], [4979, 8626], [8757, 9611], [10236, 11185], [11302, 14364], [14661, 22562], [22629, 23602], [24173, 25603], [25630, 26577]], "num_segments": 10}
{"id": "sakura_emotion_333_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_333_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["fear", "disgust", "happy", "sad"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_333.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[310, 1619], [1831, 7170], [7471, 8404], [8856, 10763], [10967, 11962], [12286, 14333]], "num_segments": 6}
{"id": "sakura_emotion_331_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_331_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Celebrate their joy with a cheerful response.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Listen attentively without interrupting to let them vent.", "Listen empathetically and let them express their feelings."], "answer": "Celebrate their joy with a cheerful response.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_331.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[219, 1909], [1952, 4996], [5196, 11716], [12868, 16211], [16595, 22969], [23102, 25266], [25350, 26219]], "num_segments": 7}
{"id": "sakura_emotion_329_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_329_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Preparing for a high-stakes exam with anxiety.", "A heated argument between colleagues.", "Winning a long-anticipated award or prize.", "Turning away from spoiled food."], "answer": "Turning away from spoiled food.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_329.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[689, 3460], [3696, 6397], [7176, 8164], [9173, 11710], [12167, 13188], [13707, 14544], [15634, 18204], [18626, 25714], [25999, 27404], [27654, 30518], [30945, 31832], [32332, 34154], [34381, 35193], [36910, 43112], [43254, 48738], [48809, 50043], [50456, 51573], [52040, 52953], [53623, 56071], [58055, 58938], [59047, 59945], [60210, 61900], [62794, 64200], [64814, 69680], [69768, 72515], [73036, 74948], [75016, 76860], [77835, 79192], [79741, 81449], [82224, 83926], [84254, 86068], [86580, 87629], [88367, 89806], [89865, 90674], [90918, 93176], [94613, 97536], [98034, 99473]], "num_segments": 37}
{"id": "sakura_emotion_328_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_328_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "angry", "disgust", "fear"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_328.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[493, 3134], [3597, 8238], [9093, 10485], [10536, 15559], [15921, 16819], [16945, 19034], [19306, 21589], [22087, 22913], [24760, 26276], [27697, 30392], [32836, 34477], [34806, 35666], [35828, 36930], [37485, 39269], [40250, 42218], [42291, 43322], [43941, 51612], [53049, 57616], [57754, 58605], [58944, 59953], [60736, 61612], [62558, 64153], [64460, 65912], [66258, 67681], [68385, 75801], [76697, 83575], [83716, 85208], [85421, 90407], [90759, 94007], [94211, 95035], [95041, 96136], [97907, 103776], [104166, 107987], [108058, 108880]], "num_segments": 34}
{"id": "sakura_emotion_328_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_328_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Hearing a shocking and offensive statement.", "A heated argument between colleagues.", "Laughing at a funny joke in a conversation.", "Watching a touching but sorrowful movie scene."], "answer": "Hearing a shocking and offensive statement.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_328.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2576, 5589], [6553, 8407], [8447, 11095], [11511, 12361], [13399, 16243], [16642, 17975], [18289, 20062], [21348, 27744], [29354, 33490], [35015, 42421], [43066, 50225], [51142, 52429], [52534, 54307], [54373, 57150], [58286, 64250], [66156, 68710], [69142, 70056], [70251, 72536], [73486, 77549], [77839, 85357], [86316, 90706], [91263, 92891], [94440, 96463], [96487, 100007], [102271, 107897], [109264, 110525]], "num_segments": 26}
{"id": "sakura_emotion_330_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_330_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "fear", "sad", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_330.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[457, 1484], [2749, 8324], [8673, 11590], [12115, 17222], [17505, 19947], [20021, 25148], [25416, 30547], [31089, 37940], [38094, 38990], [39764, 40599], [41764, 43972], [44650, 45593], [45628, 46523], [47251, 49874]], "num_segments": 14}
{"id": "sakura_emotion_332_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_332_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["happy", "sad", "fear", "disgust"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_332.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[689, 5237], [6075, 8604], [10322, 12588], [12603, 13405], [13915, 19746], [20980, 21912], [23329, 31257], [32747, 40415], [40601, 41769], [42512, 45165], [46662, 53436], [54637, 58553], [59550, 61625], [63077, 65770], [65990, 67204], [67895, 69745], [70034, 70982], [71416, 72281], [73301, 80265], [80975, 83799], [84280, 85427], [86556, 87887], [88214, 92141]], "num_segments": 23}
{"id": "sakura_emotion_330_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_330_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["It\u2019s hard to imagine things ever getting better.", "This situation is really starting to piss me off!", "I can\u2019t shake the feeling that something bad is coming.", "This makes me feel sick to my stomach."], "answer": "This situation is really starting to piss me off!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_330.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[306, 1360], [1617, 5733], [6486, 8003], [8270, 11927], [12296, 19458], [19791, 21265], [21373, 22654], [22773, 27637], [28894, 29999], [30569, 35350], [35667, 38367], [38969, 40936], [41293, 47447], [48226, 49458]], "num_segments": 14}
{"id": "sakura_emotion_333_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_333_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["This is terrifying, I can\u2019t stop thinking about it.", "I\u2019m so excited, I just can\u2019t contain my happiness!", "Stop making excuses; this is entirely your fault!", "That\u2019s just revolting, I can\u2019t believe it."], "answer": "This is terrifying, I can\u2019t stop thinking about it.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_333.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[373, 1342], [1598, 2566], [3150, 4265], [5250, 7000], [7084, 10468], [10856, 11676], [11764, 13752]], "num_segments": 7}
{"id": "sakura_emotion_334_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_334_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["happy", "fear", "disgust", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_334.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[823, 1714], [2634, 4615], [5814, 12875], [14295, 18862], [19195, 20246], [20735, 27378]], "num_segments": 6}
{"id": "sakura_emotion_332_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_332_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Hearing a shocking and offensive statement.", "Walking alone in a dark alley at night.", "Watching a touching but sorrowful movie scene.", "A person yelling after being cut off in traffic."], "answer": "Walking alone in a dark alley at night.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_332.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[200, 2307], [2900, 3867], [5813, 10174], [10370, 11937], [12014, 14286], [14806, 17700], [17721, 18947], [19772, 24640], [25920, 28971], [29101, 29981], [30132, 34719], [35648, 37443], [37861, 43067], [43975, 46875], [47378, 49941], [51022, 57635], [58281, 63118], [64348, 66058], [66555, 67933], [68708, 71195], [71555, 72561], [72899, 73842], [74477, 79430], [80859, 84259], [85908, 87063], [87697, 90036], [90659, 91501]], "num_segments": 27}
{"id": "sakura_emotion_334_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_334_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["It\u2019s hard to imagine things ever getting better.", "That\u2019s just revolting, I can\u2019t believe it.", "I can\u2019t believe this is happening, I\u2019m so furious!", "I can\u2019t breathe, I\u2019m just so afraid right now."], "answer": "I can\u2019t believe this is happening, I\u2019m so furious!", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_334.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[372, 1891], [2333, 3454], [4160, 5375], [6188, 7153], [7874, 9001], [9109, 11184], [12118, 12973], [14210, 19905], [20218, 24621], [25063, 28002], [28129, 28976]], "num_segments": 11}
{"id": "sakura_emotion_338_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_338_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["sad", "disgust", "fear", "angry"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_338.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[85, 937], [1042, 7070], [7303, 8346], [8480, 15161], [15873, 17401], [17883, 25370], [26417, 27451]], "num_segments": 7}
{"id": "sakura_emotion_336_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_336_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "happy", "angry", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_336.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[363, 1252], [1731, 4640], [5390, 9577], [10991, 12032], [12859, 18746], [19626, 24576], [25532, 27488], [27609, 28809], [29932, 30830], [32539, 36694], [37565, 40060], [40108, 41587], [43194, 45089], [46232, 51670], [52735, 56214], [57986, 63175], [63793, 67475], [69056, 73171], [75137, 76284], [77683, 82061], [82158, 86927], [88138, 89225], [90510, 95303], [96390, 97613], [98897, 99898]], "num_segments": 25}
{"id": "sakura_emotion_338_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_338_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Smile and engage positively in the conversation.", "Express understanding calmly and suggest leaving the unpleasant environment.", "Offer reassurance and remind them they are safe.", "Listen attentively without interrupting to let them vent."], "answer": "Offer reassurance and remind them they are safe.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_338.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[29, 1236], [1373, 3563], [4660, 6374], [6660, 10165], [10972, 12652], [12767, 14092], [14498, 15849], [16531, 22489], [23358, 27635]], "num_segments": 9}
{"id": "sakura_emotion_340_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_340_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["I\u2019m feeling so down, like nothing can lift my spirits.", "I can\u2019t shake the feeling that something bad is coming.", "That\u2019s just revolting, I can\u2019t believe it.", "I feel so grateful and full of joy right now."], "answer": "That\u2019s just revolting, I can\u2019t believe it.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_340.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[264, 2239], [2725, 5099], [5305, 8541], [9898, 11449], [11573, 18719], [19356, 20556], [20630, 22287], [22616, 24065], [24081, 26102], [26494, 30363], [31497, 34163], [35202, 36738], [37817, 38670], [39671, 40913]], "num_segments": 14}
{"id": "sakura_emotion_339_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_339_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["sad", "fear", "happy", "disgust"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_339.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[239, 2177], [3047, 6354], [6936, 10816], [11925, 13734], [14216, 17866], [17953, 20068], [20214, 21641], [22213, 28093], [28521, 29579]], "num_segments": 9}
{"id": "sakura_emotion_340_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_340_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "happy", "angry", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_340.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[328, 6183], [7057, 7995], [8521, 9757], [10733, 11939], [12184, 13303], [13884, 17661], [18821, 20210], [20471, 22585], [23439, 24723], [25650, 26453], [27221, 28573], [29783, 32340], [32682, 34386], [34881, 35928], [37152, 41399]], "num_segments": 15}
{"id": "sakura_emotion_339_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_339_masked_100pct.wav", "question": "Which facial expression best fits the emotion heard in the audio?", "choices": ["A radiant expression with raised cheeks", "Squinted eyes and a pinched nose", "Furrowed brows with slightly open mouth, as if about to shout.", "A heavy sigh with a frown and slumped posture"], "answer": "A radiant expression with raised cheeks", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_339.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[522, 1822], [2120, 6911], [8327, 9149], [9695, 11889], [12787, 14394], [14432, 15356], [16100, 19545], [19763, 26987], [27148, 27990], [28281, 29595]], "num_segments": 10}
{"id": "sakura_emotion_337_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_337_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I can\u2019t believe this is happening, I\u2019m so furious!", "I\u2019m so excited, I just can\u2019t contain my happiness!", "I don\u2019t know how to move on from this loss.", "It\u2019s so dirty! Please clean it as quick as possible."], "answer": "I don\u2019t know how to move on from this loss.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_337.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1229, 2214], [2277, 4531], [5887, 12358], [12420, 14554], [15115, 17447], [17676, 19567], [21086, 23566], [23744, 25327], [26934, 28436], [30794, 32064], [33223, 34195], [35019, 37482], [38691, 44606], [45144, 47729], [48278, 52299], [53206, 55424], [56446, 61894], [62915, 64858], [65625, 66793], [67068, 68599], [69063, 74218]], "num_segments": 21}
{"id": "sakura_emotion_336_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_336_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["Wrinkled forehead and a forlorn expression", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "A broad smile with sparkling eyes", "Raised eyebrows with a scowl"], "answer": "Retracted chin with one corner of the mouth twitching, as if intolerable.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_336.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[702, 2846], [3926, 7805], [8225, 9107], [11127, 17032], [17273, 18450], [18552, 24374], [25161, 30948], [31858, 33959], [34564, 37569], [39896, 41149], [41442, 43957], [44336, 48020], [48475, 50188], [50220, 51153], [53227, 54597], [54997, 55992], [56503, 62547], [62779, 66315], [66700, 73427], [73772, 77713], [79636, 80507], [80633, 82078], [82739, 83880], [84316, 85582], [86810, 87947], [88094, 89268], [89630, 90697], [91774, 98681], [98715, 100706]], "num_segments": 29}
{"id": "sakura_emotion_337_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_337_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "disgust", "sad", "fear"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_337.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[135, 2797], [3072, 4331], [4579, 7409], [8072, 10196], [10717, 12320], [12451, 15496], [15675, 17323], [17652, 21494], [23024, 28850], [29443, 31804], [33558, 39562], [39644, 40732], [41735, 42878], [44115, 47073], [47227, 49490], [49710, 52834], [52946, 54364], [54453, 55603], [55969, 59690], [60725, 66004], [67271, 68804], [69202, 71718], [71820, 73585], [73659, 74749]], "num_segments": 24}
{"id": "sakura_emotion_342_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_342_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "fear", "disgust", "happy"], "answer": "angry", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_342.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[60, 1625], [2243, 4693], [4815, 11005], [11638, 13494], [14239, 18687], [19112, 22218], [22929, 29466], [32090, 34094], [34190, 37704], [37769, 40476], [41356, 45831]], "num_segments": 11}
{"id": "sakura_emotion_341_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_341_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["happy", "sad", "angry", "fear"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_341.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[581, 3436], [4168, 5956], [6148, 8164], [8751, 10189], [11774, 12685], [13021, 15639], [16291, 17185], [17235, 20595], [21176, 22783], [23157, 24656], [24779, 32615], [32767, 33817], [34283, 35742], [35753, 36696], [36703, 40086], [40688, 41762], [41972, 43427], [43995, 49620], [49956, 51108]], "num_segments": 19}
{"id": "sakura_emotion_341_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_341_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Give them space to cool off before engaging further.", "Celebrate their joy with a cheerful response.", "Hold their hand or offer some physical reassurance.", "Reassure them and offer a way to move past the uncomfortable    situation."], "answer": "Give them space to cool off before engaging further.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_341.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[116, 1557], [1567, 6822], [7397, 8217], [8370, 10008], [10114, 15548], [15557, 21418], [23434, 26042], [27111, 30714], [31583, 35964], [36199, 37142], [37266, 38820], [39557, 46541], [47280, 48579], [48708, 50730], [51026, 52021]], "num_segments": 15}
{"id": "sakura_emotion_342_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_342_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Express genuine excitement for their good news or achievement.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Hold their hand or offer some physical reassurance.", "Apologize and admit your mistake, if appropriate."], "answer": "Apologize and admit your mistake, if appropriate.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_342.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[542, 7923], [10017, 16420], [16432, 17467], [18440, 24856], [25460, 27234], [27559, 28546], [28990, 29831], [29865, 31017], [31647, 32523], [33208, 34688], [35266, 42224], [43246, 46731]], "num_segments": 12}
{"id": "sakura_emotion_345_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_345_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Listen empathetically and let them express their feelings.", "Hold their hand or offer some physical reassurance.", "Give them space to cool off before engaging further."], "answer": "Give them space to cool off before engaging further.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_345.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[494, 1493], [1557, 3452], [3550, 4733], [5286, 8348], [9578, 17321], [18650, 19972], [20022, 21890], [22788, 24225], [24251, 25199], [25294, 27290]], "num_segments": 10}
{"id": "sakura_emotion_343_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_343_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "sad", "happy", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_343.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[208, 1767], [2984, 4675], [5151, 6043], [6396, 10550], [11555, 12433], [12682, 13900], [14432, 16392], [16415, 17777], [18244, 20023], [20636, 21999], [22076, 23752], [24858, 30044], [30802, 31665], [31687, 38729]], "num_segments": 14}
{"id": "sakura_emotion_343_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_343_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Reading a heartfelt goodbye letter.", "Celebrating a birthday with friends and family.", "Reacting to a foul odor in a room.", "Preparing for a high-stakes exam with anxiety."], "answer": "Preparing for a high-stakes exam with anxiety.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_343.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[471, 5992], [6538, 9185], [9264, 12316], [12616, 13838], [14033, 15193], [15376, 18132], [19288, 21183], [22090, 23103], [23343, 25082], [25907, 33899], [34291, 35298], [35557, 36438], [36577, 38077]], "num_segments": 13}
{"id": "sakura_emotion_345_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_345_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["happy", "fear", "disgust", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_345.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[127, 1054], [1311, 2689], [2937, 7492], [7610, 15265], [16013, 19035], [19244, 24371], [25317, 26895]], "num_segments": 7}
{"id": "sakura_emotion_335_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_335_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["I\u2019ve had enough of this nonsense.", "It\u2019s so dirty! Please clean it as quick as possible.", "I don\u2019t know how to move on from this loss.", "I\u2019m really scared about what might happen next."], "answer": "I don\u2019t know how to move on from this loss.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_335.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1260, 4158], [4648, 6275], [7620, 8605], [10198, 11992], [13594, 15950], [17274, 18384], [19336, 20736], [20871, 23931], [25850, 27089], [27975, 34459], [37468, 40718], [41760, 47783], [48060, 48872], [49140, 56017], [57822, 61159], [63091, 67545], [68388, 71524], [73470, 77657], [78739, 80277], [81582, 86477], [86622, 88175], [88212, 89138], [89570, 90542], [90577, 91870], [93710, 95913], [96239, 100014], [100771, 102067], [102329, 103746], [103856, 110094], [111181, 113091], [115011, 116407], [116832, 118674], [118728, 119630], [120902, 122347], [122844, 128523], [129159, 130149], [130636, 133859], [134889, 140446], [140720, 147178], [147322, 149537], [150553, 154392], [156254, 158109], [158549, 159631], [159804, 162369], [162847, 163745], [165002, 167372], [170496, 174620], [177487, 180864], [181845, 186514], [188103, 190181], [190591, 191889], [192426, 195093], [198182, 204819], [206010, 207437], [207950, 208881], [209139, 211128]], "num_segments": 56}
{"id": "sakura_emotion_335_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_335_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "happy", "sad", "fear"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_335.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[524, 2021], [2860, 3835], [4658, 8857], [9646, 11573], [11578, 18351], [21275, 23050], [23555, 29881], [31350, 32333], [32534, 35425], [36415, 42297], [43555, 44458], [45179, 46665], [46992, 49638], [49871, 52259], [52751, 54376], [54767, 62680], [63548, 65305], [66118, 71185], [71548, 72933], [74545, 81191], [82059, 84014], [85629, 86799], [87081, 92171], [93178, 98815], [100183, 100996], [101138, 106046], [107793, 109855], [110087, 112916], [113602, 116331], [117797, 119295], [120517, 122080], [122592, 126196], [127563, 129482], [131588, 133908], [134269, 135916], [136086, 137850], [138350, 142487], [142623, 144374], [145283, 146522], [147527, 150493], [152122, 155602], [155773, 156624], [158619, 165866], [166094, 167174], [167400, 169837], [169864, 176661], [179513, 181331], [181529, 183412], [183455, 191230], [192212, 199090], [200281, 201702], [202339, 203287], [203696, 204702], [205328, 209354]], "num_segments": 54}
{"id": "sakura_emotion_346_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_346_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Suggest spending some time together to cheer them up.", "Listen attentively without interrupting to let them vent.", "Avoid discussing further and respect their aversion to the topic.", "Hold their hand or offer some physical reassurance."], "answer": "Listen attentively without interrupting to let them vent.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_346.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[91, 901], [1013, 1850], [2122, 3372], [3681, 4737], [4873, 11330], [11688, 12631], [12643, 19573], [20075, 23737], [24048, 25207]], "num_segments": 9}
{"id": "sakura_emotion_344_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_344_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["fear", "disgust", "angry", "happy"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_344.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[644, 7670], [8225, 9148], [9226, 10552], [10925, 12661], [12731, 16367], [17651, 21975], [21977, 23008], [23033, 24473], [24507, 25854], [25882, 28261], [28336, 33706], [33837, 34765], [34927, 36296], [36449, 37529]], "num_segments": 14}
{"id": "sakura_emotion_346_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_346_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["fear", "disgust", "sad", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_346.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[193, 1111], [1290, 2757], [2797, 3726], [4445, 8341], [8545, 10109], [10452, 15747], [15773, 17634], [19135, 21700], [21809, 23146], [23558, 25048]], "num_segments": 10}
{"id": "sakura_emotion_347_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_347_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["happy", "disgust", "fear", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_347.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[182, 2157], [2576, 3660], [3965, 6423], [8333, 11452], [11493, 18502], [18584, 20134], [20729, 25594], [25708, 29333], [29779, 34201], [34629, 40636], [41443, 43310], [43705, 46190], [46852, 53928], [54936, 56462], [56796, 59538], [59834, 60864], [62441, 68247], [69001, 72203], [73197, 74067], [75274, 77683], [78375, 79737], [80782, 81738], [82971, 88292], [89464, 90963], [91054, 97651], [98050, 98968]], "num_segments": 26}
{"id": "sakura_emotion_344_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_344_masked_100pct.wav", "question": "Which situation best corresponds to the emotion conveyed in the speech?", "choices": ["Watching a horror movie alone in the dark.", "Slamming a door after a disagreement.", "Watching a touching but sorrowful movie scene.", "Turning away from spoiled food."], "answer": "Turning away from spoiled food.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_344.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[365, 1402], [2176, 9693], [10211, 11689], [11925, 17190], [17200, 18203], [18545, 26128], [26589, 27418], [27524, 29237], [29466, 31915], [31974, 35041], [35672, 37522]], "num_segments": 11}
{"id": "sakura_emotion_348_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_348_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "happy", "angry", "sad"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_348.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[649, 1822], [3086, 7842], [8203, 15541], [15568, 23548], [23949, 24847], [25124, 26177], [26565, 27959], [28176, 34640], [34907, 38960], [39949, 42011], [43151, 48157], [48206, 49131], [49131, 52826], [53140, 60581], [60588, 63717], [65385, 66337], [66784, 69707], [69725, 70727]], "num_segments": 18}
{"id": "sakura_emotion_347_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_347_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I can\u2019t stop smiling, everything feels so right.", "It\u2019s hard to imagine things ever getting better.", "This makes me feel sick to my stomach.", "I\u2019ve had enough of this nonsense."], "answer": "It\u2019s hard to imagine things ever getting better.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_347.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[173, 1230], [1504, 4229], [4856, 6060], [6921, 7758], [8186, 9154], [11222, 15397], [17815, 22181], [22219, 25150], [25434, 26567], [27162, 32224], [32732, 40318], [41177, 47979], [48094, 49371], [49952, 50986], [52192, 55591], [56170, 62634], [62791, 64114], [65058, 68359], [69486, 70335], [70683, 71774], [72549, 74351], [74486, 80881], [81120, 84453], [85120, 87711], [88656, 89516], [89657, 91392], [92058, 95152], [95201, 98235]], "num_segments": 28}
{"id": "sakura_emotion_350_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_350_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "disgust", "happy", "fear"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_350.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2, 937], [1530, 2587], [3177, 10270], [11098, 14446], [16229, 20776], [20844, 22260]], "num_segments": 6}
{"id": "sakura_emotion_348_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_348_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Reacting to a sudden loud noise in an empty house.", "A heated argument between colleagues.", "Reacting to a foul odor in a room.", "Celebrating a birthday with friends and family."], "answer": "Celebrating a birthday with friends and family.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_348.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[88, 2456], [3592, 7914], [9555, 11548], [11659, 15431], [16505, 24009], [24240, 29790], [30013, 34927], [35733, 36793], [36994, 38629], [39639, 46198], [47799, 49059], [49121, 52267], [53133, 54105], [54407, 55790], [55997, 56921], [57162, 58486], [58784, 59620], [60621, 62951], [63810, 65067], [65208, 66095], [66559, 70028], [70292, 71208]], "num_segments": 22}
{"id": "sakura_emotion_349_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_349_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["disgust", "fear", "sad", "angry"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_349.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[519, 1330], [1471, 4742], [5241, 6737], [7755, 9217], [9477, 12933], [13048, 14928], [15104, 16445], [16498, 17882], [18673, 24206], [25567, 26987], [27590, 34082], [34760, 39221], [39398, 42010], [42544, 48921], [49521, 51911], [53185, 55943]], "num_segments": 16}
{"id": "sakura_emotion_350_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_350_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Express understanding calmly and suggest leaving the unpleasant environment.", "Encourage them to take deep breaths to relax.", "Smile and engage positively in the conversation.", "Give them space to cool off before engaging further."], "answer": "Smile and engage positively in the conversation.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_350.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1059, 3654], [4159, 5741], [6260, 11124], [11309, 16352], [17089, 20423], [21108, 22501]], "num_segments": 6}
{"id": "sakura_emotion_351_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_351_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["sad", "disgust", "angry", "happy"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_351.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1090, 2693], [4109, 7616], [7685, 9612], [11462, 12474], [12776, 14114], [15246, 17096], [17101, 18074], [19870, 27702], [29047, 30165], [31370, 36263], [36937, 38519], [40151, 40998]], "num_segments": 12}
{"id": "sakura_emotion_352_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_352_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["sad", "disgust", "happy", "angry"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_352.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[265, 2440], [3412, 10549], [11597, 13194], [13991, 15084], [15486, 16552]], "num_segments": 5}
{"id": "sakura_emotion_352_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_352_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Watching a touching but sorrowful movie scene.", "Watching a horror movie alone in the dark.", "A parent scolding their child for misbehavior.", "Turning away from spoiled food."], "answer": "Turning away from spoiled food.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_352.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[109, 1101], [1608, 2692], [3872, 10040], [10219, 11331], [12014, 12847], [13288, 15659], [15788, 16603]], "num_segments": 7}
{"id": "sakura_emotion_351_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_351_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Express genuine excitement for their good news or achievement.", "Apologize and admit your mistake, if appropriate.", "Suggest spending some time together to cheer them up.", "Encourage them to take deep breaths to relax."], "answer": "Suggest spending some time together to cheer them up.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_351.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[969, 3502], [3952, 5677], [5843, 8424], [9339, 12007], [12144, 13184], [13609, 15294], [15302, 20876], [22185, 25270], [26170, 27438], [27534, 29315], [29989, 32101], [32304, 38082], [39062, 41538]], "num_segments": 13}
{"id": "sakura_emotion_349_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_349_masked_100pct.wav", "question": "Based on the emotion identified in the audio, which of these facial expressions is most likely to match the speaker's emotional state?", "choices": ["A sharp, piercing gaze and compressed lips", "Tightly furrowed brow with trembling lips", "Eyes gazing downward with trembling lips", "Squinted eyes and a pinched nose"], "answer": "Eyes gazing downward with trembling lips", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_349.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1896, 5794], [6398, 7618], [9028, 16037], [16162, 17223], [17361, 19103], [19454, 25122], [25981, 31643], [32806, 35647], [35821, 43275], [43292, 46439], [47613, 48472], [49674, 50997], [51967, 53798], [53887, 56889]], "num_segments": 14}
{"id": "sakura_emotion_354_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_354_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["sad", "fear", "happy", "disgust"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_354.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[643, 1943], [2462, 5714], [5800, 6927], [7174, 8711], [9392, 10779], [11501, 12483], [12900, 18882], [19748, 21906], [22492, 27749], [28403, 33469], [34312, 35361], [35543, 37140], [37437, 39501], [39990, 46723]], "num_segments": 14}
{"id": "sakura_emotion_354_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_354_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["That\u2019s just revolting, I can\u2019t believe it.", "This situation is really starting to piss me off!", "This is the best day ever, I feel on top of the world!", "I can\u2019t breathe, I\u2019m just so afraid right now."], "answer": "I can\u2019t breathe, I\u2019m just so afraid right now.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_354.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1177, 3836], [4137, 7570], [7927, 8742], [9129, 14882], [15415, 16523], [17523, 20123], [20783, 23350], [23717, 24735], [26079, 26992], [28218, 29718], [29892, 31712], [31821, 32627], [33092, 37615], [38926, 42797], [42972, 46011], [46135, 47704]], "num_segments": 16}
{"id": "sakura_emotion_355_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_355_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["sad", "disgust", "fear", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_355.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[81, 1445], [1846, 5603], [5856, 7840], [7956, 10495], [10826, 13148], [13453, 14967], [15005, 16439], [16780, 22325], [22861, 26766], [26815, 27727], [28598, 29681], [30074, 31569], [32292, 33304], [33881, 35350], [35999, 37752], [38081, 39285], [40363, 41517]], "num_segments": 17}
{"id": "sakura_emotion_355_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_355_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["A wrinkled nose and raised upper lip", "Frozen facial expression with trembling lips and quickened breathing.", "A broad smile with sparkling eyes", "Tightly pressed lips with glaring eyes"], "answer": "A broad smile with sparkling eyes", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_355.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[25, 977], [1045, 4492], [4972, 5828], [6234, 13070], [13446, 15031], [15116, 22692], [22952, 24202], [24527, 27075], [27167, 28715], [28991, 31363], [31492, 32507], [32572, 35033], [35615, 36460], [36487, 37415], [37427, 40391]], "num_segments": 15}
{"id": "sakura_emotion_356_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_356_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["I\u2019m really scared about what might happen next.", "I can\u2019t stop smiling, everything feels so right.", "I feel so empty, like nothing matters anymore.", "This thing looks absolutely gross and dirty; I can\u2019t stand it!"], "answer": "I can\u2019t stop smiling, everything feels so right.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_356.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[776, 2122], [2691, 6266], [6846, 8003], [8018, 10149], [10467, 13223], [13685, 15141], [15467, 17243], [17295, 20962], [20972, 21972], [22159, 26964], [27013, 28113]], "num_segments": 11}
{"id": "sakura_emotion_353_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_353_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "fear", "happy", "disgust"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_353.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[42, 1366], [1548, 9352], [9670, 13566], [14249, 16085], [17494, 23647], [24570, 25645], [25930, 29379], [30150, 31650], [32892, 35352], [36075, 43014], [43479, 47156], [48390, 50021], [50601, 55141], [56564, 59410], [59542, 60641], [61176, 62070], [62096, 62991], [63308, 67593], [67620, 68566], [71104, 75615], [76340, 81808], [82865, 88985], [89760, 91426]], "num_segments": 23}
{"id": "sakura_emotion_357_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_357_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "fear", "disgust", "angry"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_357.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1028, 3982], [5443, 6708], [8649, 13403], [14916, 17596], [18427, 20199], [20921, 21826], [22001, 23829], [25204, 26683], [26818, 29046], [29407, 30522], [31265, 35631], [38051, 40139], [40437, 43123], [43168, 44345], [45820, 50924], [53000, 54755], [55466, 62094], [62231, 63315], [64930, 72391], [73517, 75081], [76476, 81327], [81446, 83361], [83855, 90706], [91104, 95847]], "num_segments": 24}
{"id": "sakura_emotion_353_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_353_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Tightly furrowed brow with trembling lips", "A wrinkled nose and raised upper lip", "A sharp, piercing gaze and compressed lips", "A heavy sigh with a frown and slumped posture"], "answer": "Tightly furrowed brow with trembling lips", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_353.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[907, 1816], [2135, 6261], [7302, 14861], [16221, 20627], [20678, 21572], [22302, 24272], [24930, 28607], [30015, 31014], [32260, 34868], [35958, 41153], [41197, 42485], [42960, 46935], [47056, 49223], [49884, 50775], [51343, 52769], [53193, 54521], [55607, 56878], [56995, 64568], [65778, 67207], [67340, 70252], [70834, 71858], [72422, 77764], [78871, 80861], [80974, 84351], [85223, 87194], [87412, 88772], [88790, 89713]], "num_segments": 27}
{"id": "sakura_emotion_356_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_356_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["fear", "sad", "happy", "angry"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_356.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1095, 6031], [6847, 9621], [10003, 11612], [11615, 13060], [14153, 15104], [15358, 17657], [18186, 19838], [20383, 23958], [24758, 26967], [27052, 28072]], "num_segments": 10}
{"id": "sakura_emotion_359_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_359_masked_100pct.wav", "question": "Based on the emotion identified in the audio, which of these facial expressions is most likely to match the speaker's emotional state?", "choices": ["Head slightly pulled back with a terrified gaze, as if searching for an escape.", "Clenched teeth with side facial muscles showing tension.", "Averted gaze with a grimacing mouth", "A warm, genuine smile with slightly tilted head"], "answer": "Clenched teeth with side facial muscles showing tension.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_359.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[372, 1964], [2349, 3769], [4219, 7191], [7980, 9427], [9787, 11070], [11526, 12587], [12876, 18776], [19562, 24008], [25274, 27199], [27382, 30903], [31119, 32374]], "num_segments": 11}
{"id": "sakura_emotion_359_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_359_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["happy", "angry", "sad", "disgust"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_359.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[577, 2853], [4066, 8781], [8822, 9972], [10126, 11761], [12033, 15225], [16634, 20533], [21138, 24796], [25415, 26543], [26897, 31535], [31640, 32500], [32686, 33878]], "num_segments": 11}
{"id": "sakura_emotion_357_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_357_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Attending a close friend's funeral.", "Hugging a loved one after a long separation.", "A parent scolding their child for misbehavior.", "Seeing an unpleasant image online."], "answer": "Attending a close friend's funeral.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_357.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1092, 3610], [5166, 11772], [12105, 14887], [15420, 18624], [19652, 21805], [22454, 24032], [24334, 28532], [28808, 34690], [35607, 36700], [37090, 38012], [40524, 42422], [42464, 45197], [45846, 50754], [51004, 53040], [53390, 55622], [56739, 57580], [58191, 60741], [61376, 64110], [64404, 65498], [65701, 67294], [68535, 74093], [74565, 77563], [79286, 82815], [83504, 90206], [91009, 92188], [92444, 94838]], "num_segments": 26}
{"id": "sakura_emotion_358_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_358_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["This thing looks absolutely gross and dirty; I can\u2019t stand it!", "This is the best day ever, I feel on top of the world!", "This situation is really starting to piss me off!", "I feel so empty, like nothing matters anymore."], "answer": "I feel so empty, like nothing matters anymore.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_358.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[655, 2841], [4558, 8689], [10235, 12049], [14556, 18528], [19615, 21268], [21322, 25512], [25834, 27986], [28352, 29236], [30520, 34390], [35475, 42958], [43588, 48231], [48814, 55658], [56384, 57278], [57483, 64372], [64612, 65866], [65989, 68402], [68403, 70416], [71162, 72053], [72310, 73915], [74216, 75602], [77821, 80934], [81024, 88927], [89266, 90592], [90803, 93824], [94095, 96893], [97586, 98703], [100994, 106024], [107145, 108124], [108606, 113073], [113722, 121559]], "num_segments": 30}
{"id": "sakura_emotion_358_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_358_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "angry", "fear", "happy"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_358.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[41, 879], [1279, 2993], [3390, 6211], [7635, 8530], [9429, 15319], [16033, 19044], [19250, 23491], [24999, 31073], [32963, 37986], [38788, 39732], [40481, 47548], [49829, 55616], [55627, 63130], [63341, 66343], [66644, 69766], [69925, 74509], [74818, 76945], [77839, 78669], [79036, 80075], [80815, 82211], [83066, 85530], [85549, 91419], [91673, 96054], [97543, 99633], [100542, 102232], [102983, 110035], [110900, 111951], [112439, 113719], [114171, 120539]], "num_segments": 29}
{"id": "sakura_emotion_360_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_360_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "disgust", "fear", "sad"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_360.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[222, 2022], [2571, 6577], [6864, 11598], [13436, 14404], [14883, 15781], [16440, 18819], [19197, 20495], [20927, 24380], [24910, 26307], [26435, 30391], [31620, 32527], [32777, 33907], [34531, 35438], [36211, 38005], [38538, 41568], [41904, 43534], [44589, 47155], [48023, 48909], [49904, 57865], [58814, 60603], [60897, 61729], [62093, 63460], [64231, 65245], [65641, 70650], [71305, 72183], [72619, 79884], [79979, 81125], [82889, 84238], [84484, 89628], [90184, 91874], [91957, 93064], [94376, 95197], [95247, 100300], [102162, 106482], [107792, 114099], [114781, 116425]], "num_segments": 36}
{"id": "sakura_emotion_361_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_361_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["This situation is really starting to piss me off!", "I can\u2019t stop smiling, everything feels so right.", "It\u2019s hard to imagine things ever getting better.", "I can\u2019t even look at this without feeling uncomfortable."], "answer": "This situation is really starting to piss me off!", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_361.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[115, 1838], [2588, 5385], [6306, 11551], [11858, 16957], [17753, 21099], [21926, 25931], [27297, 32833], [33554, 39012], [40119, 46156], [46939, 47803], [49015, 50897], [50922, 56177], [56393, 57612], [59142, 60538], [60757, 62719], [64390, 68096], [69369, 70658], [70779, 71657], [72106, 76563], [77369, 80463], [80572, 82476], [83242, 86596], [87409, 89212]], "num_segments": 23}
{"id": "sakura_emotion_363_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_363_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "happy", "disgust", "angry"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_363.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[47, 963], [2363, 4655], [4814, 9096], [10374, 13013], [14419, 18290], [18470, 19436], [19488, 21016], [22099, 25765], [25977, 27465], [28477, 31475], [32059, 34271], [34664, 39095], [40066, 45480], [45527, 48551], [48841, 56086], [57182, 58116], [59716, 61225], [61243, 62911], [62962, 64646]], "num_segments": 19}
{"id": "sakura_emotion_362_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_362_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "sad", "disgust", "happy"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_362.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[292, 3420], [4422, 5594], [5605, 10637], [11238, 15012], [15330, 17351], [17877, 19027], [19091, 20162], [21313, 23046], [23993, 24888], [25117, 32013], [33545, 38922], [39559, 40715], [40998, 43725], [45293, 47717], [47745, 49163], [49394, 51720], [53080, 58831], [59936, 61494], [63298, 64218], [65491, 70371], [71052, 73215], [73723, 75355], [75606, 82344], [82992, 84211], [84438, 90007], [90646, 92037], [92520, 99341], [99692, 103807], [105318, 108812]], "num_segments": 29}
{"id": "sakura_emotion_361_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_361_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["happy", "sad", "angry", "disgust"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_361.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[211, 5516], [5880, 7845], [7994, 8989], [9408, 10688], [10810, 13430], [13923, 15699], [15782, 16986], [17086, 18416], [18454, 20539], [21841, 26923], [27862, 30886], [31703, 35031], [35915, 38585], [39026, 41284], [41741, 42594], [42736, 45136], [45389, 46763], [46856, 48879], [49717, 50542], [51252, 58744], [59127, 62283], [63076, 66695], [67126, 68224], [69242, 70687], [72250, 73417], [74040, 76488], [77466, 85202], [86221, 87455], [87540, 89510]], "num_segments": 29}
{"id": "sakura_emotion_362_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_362_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["Reading a heartfelt goodbye letter.", "Throwing an object in frustration.", "Turning away from spoiled food.", "Laughing at a funny joke in a conversation."], "answer": "Reading a heartfelt goodbye letter.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_362.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[165, 3103], [3483, 10915], [12067, 13400], [15474, 21470], [22458, 25554], [25758, 27677], [28323, 29163], [30166, 32069], [32135, 33344], [34660, 35622], [37176, 39389], [39490, 41254], [41390, 43570], [43755, 48544], [49083, 50261], [50503, 56107], [56349, 57229], [57993, 62693], [63950, 70549], [72720, 74729], [75443, 77547], [77892, 79930], [80247, 82830], [83995, 86209], [86417, 87709], [88074, 89245], [89469, 92380], [92545, 93491], [93626, 94747], [95801, 103651], [105782, 109366]], "num_segments": 31}
{"id": "sakura_emotion_363_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_363_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["A heated argument between colleagues.", "Reacting to a sudden loud noise in an empty house.", "Seeing an unpleasant image online.", "A person smiling after receiving good news."], "answer": "Reacting to a sudden loud noise in an empty house.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_363.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[62, 7052], [7688, 9080], [9421, 10737], [10888, 12335], [12581, 13655], [14640, 15659], [15830, 19543], [19983, 23513], [23613, 27030], [27659, 28725], [30277, 32809], [32914, 35542], [35919, 37056], [37090, 38164], [39371, 43246], [44486, 48948], [48968, 55875], [56528, 57590], [57636, 59090], [59126, 64035]], "num_segments": 20}
{"id": "sakura_emotion_364_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_364_masked_100pct.wav", "question": "Based on the emotion identified in the audio, which of these facial expressions is most likely to match the speaker's emotional state?", "choices": ["Raised eyebrows with a scowl", "Squinted eyes and a pinched nose", "Eyes gazing downward with trembling lips", "Wide-open eyes with raised eyebrows and slightly parted lips."], "answer": "Raised eyebrows with a scowl", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_364.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[261, 2018], [2681, 4069], [4902, 6878], [7560, 9566], [10082, 11234], [11637, 12897], [13001, 14893], [15002, 19006], [21022, 25425], [25768, 29319], [30174, 31888], [33152, 39608], [40040, 42143]], "num_segments": 13}
{"id": "sakura_emotion_364_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_364_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "fear", "disgust", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_364.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1106, 4250], [4624, 6913], [8065, 9673], [10596, 12160], [12819, 16050], [16493, 19728], [20592, 22303], [22310, 23443], [24018, 25575], [25888, 27761], [28019, 33208], [33863, 37008], [38405, 39794], [40872, 42305]], "num_segments": 14}
{"id": "sakura_emotion_366_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_366_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "fear", "angry", "disgust"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_366.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1379, 7335], [7339, 8509], [9027, 12262], [13361, 16874], [17318, 18425], [19997, 21570], [22226, 23428], [23605, 25469], [26079, 28880], [30118, 37219], [37554, 39314], [39758, 44964], [45076, 46727]], "num_segments": 13}
{"id": "sakura_emotion_365_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_365_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["disgust", "sad", "fear", "angry"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_365.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2675, 8074], [9072, 11204], [11443, 17510], [18475, 22693], [23759, 25064], [27287, 28641], [28787, 32138], [32410, 33693], [33973, 39117], [40230, 41900], [43108, 45178], [46166, 47638], [49289, 50411], [51149, 56352], [56745, 62043], [62280, 64509], [64972, 70160], [70694, 73278], [73742, 75577], [75869, 78824], [79095, 81353], [82148, 88275], [88709, 95106]], "num_segments": 23}
{"id": "sakura_emotion_366_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_366_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["Stop making excuses; this is entirely your fault!", "I\u2019m feeling so down, like nothing can lift my spirits.", "I\u2019m so excited, I just can\u2019t contain my happiness!", "I feel like I\u2019m in danger, and I don\u2019t know what to do."], "answer": "Stop making excuses; this is entirely your fault!", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_366.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[406, 8042], [8884, 10632], [10724, 18004], [18839, 21290], [21931, 23103], [23897, 29201], [30806, 33268], [33457, 34842], [36339, 39763], [40132, 42221], [42417, 45259], [45715, 46571]], "num_segments": 12}
{"id": "sakura_emotion_365_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_365_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["Stop making excuses; this is entirely your fault!", "This makes me feel sick to my stomach.", "I\u2019m so excited, I just can\u2019t contain my happiness!", "I don\u2019t know how to move on from this loss."], "answer": "This makes me feel sick to my stomach.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_365.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[52, 1399], [1550, 2573], [2908, 5508], [5731, 8362], [8367, 9819], [10208, 11182], [11685, 19676], [20545, 23021], [23430, 29477], [30301, 33914], [35019, 36101], [36313, 38860], [40618, 43440], [43659, 50736], [52334, 56287], [56510, 60636], [61426, 62527], [63057, 65301], [66040, 66877], [66987, 68783], [69154, 70447], [72272, 76069], [76668, 78631], [78746, 83406], [84208, 85223], [85967, 86974], [87923, 89303], [89511, 90455], [90537, 92613], [93126, 94217], [94775, 95991]], "num_segments": 31}
{"id": "sakura_emotion_367_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_367_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "happy", "angry", "sad"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_367.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[915, 2251], [2279, 3557], [3849, 5462], [7112, 8946], [9180, 13699], [14586, 17777], [17908, 21101]], "num_segments": 7}
{"id": "sakura_emotion_367_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_367_masked_100pct.wav", "question": "What facial expression most aligns with the emotion in the recording?", "choices": ["Eyes gazing downward with trembling lips", "Raised eyebrows with a scowl", "Wide-open eyes with raised eyebrows and slightly parted lips.", "A wrinkled nose and raised upper lip"], "answer": "Raised eyebrows with a scowl", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_367.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[382, 1320], [2329, 9787], [10300, 11148], [12531, 19564], [19705, 21489]], "num_segments": 5}
{"id": "sakura_emotion_368_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_368_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["fear", "disgust", "happy", "angry"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_368.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[290, 2294], [2510, 9581], [9739, 10769], [10852, 13773], [14347, 15707], [16881, 24766], [24848, 26414], [26582, 33806], [34994, 41119], [41425, 44650]], "num_segments": 10}
{"id": "sakura_emotion_368_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_368_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["A wrinkled nose and raised upper lip", "Tightly pressed lips with glaring eyes", "Eyes gazing downward with trembling lips", "Frozen facial expression with trembling lips and quickened breathing."], "answer": "A wrinkled nose and raised upper lip", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_368.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1681, 9454], [9496, 12289], [12691, 13594], [13629, 20627], [21918, 26331], [26368, 27393], [27641, 31961], [32408, 37736], [39291, 40902], [40963, 41883], [42270, 43407], [43743, 44601]], "num_segments": 12}
{"id": "sakura_emotion_369_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_369_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "fear", "disgust", "sad"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_369.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[723, 1843], [2310, 4046], [4729, 6118], [6120, 12514], [13031, 13888], [13961, 18365], [18655, 20432], [20837, 21728], [22714, 29170], [29657, 36230], [36738, 38113], [38279, 39318], [39470, 46942], [47523, 48553], [49217, 54178], [54837, 56208], [57518, 61967], [62278, 63594]], "num_segments": 18}
{"id": "sakura_emotion_369_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_369_masked_100pct.wav", "question": "From the provided sentences, which one best matches the emotional state of individuals who are experiencing the same emotion as the speaker?", "choices": ["I can\u2019t even look at this without feeling uncomfortable.", "I can\u2019t shake the feeling that something bad is coming.", "Stop making excuses; this is entirely your fault!", "I just can\u2019t stop thinking about all those bad memories."], "answer": "I can\u2019t even look at this without feeling uncomfortable.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_369.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[530, 2900], [3154, 8360], [9564, 16851], [17108, 23070], [23319, 25271], [25418, 29354], [31610, 39385], [40160, 41892], [42898, 44159], [44212, 49624], [49701, 51301], [52309, 58030], [58812, 62447]], "num_segments": 13}
{"id": "sakura_emotion_371_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_371_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Listen attentively without interrupting to let them vent.", "Express genuine excitement for their good news or achievement.", "Listen empathetically and let them express their feelings.", "Offer reassurance and remind them they are safe."], "answer": "Listen empathetically and let them express their feelings.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_371.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1264, 3492], [4081, 4923], [5238, 9844], [9927, 11149], [11653, 17947], [18656, 23327]], "num_segments": 6}
{"id": "sakura_emotion_371_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_371_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "sad", "happy", "angry"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_371.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[490, 2878], [2984, 4108], [4772, 7953], [8532, 13862], [13966, 15423], [15494, 16741], [17399, 18540], [18659, 22781]], "num_segments": 8}
{"id": "sakura_emotion_372_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_372_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["happy", "fear", "sad", "disgust"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_372.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1093, 4328], [4801, 8090], [8783, 12036], [12175, 15791], [16075, 17673], [17790, 18738], [19462, 21024], [21800, 23563], [23737, 29816], [30335, 32563], [33807, 38451], [40239, 42767], [42835, 47971], [48822, 51825], [52297, 53358]], "num_segments": 15}
{"id": "sakura_emotion_360_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_360_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Celebrate their joy with a cheerful response.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Offer reassurance and remind them they are safe.", "Apologize and admit your mistake, if appropriate."], "answer": "Celebrate their joy with a cheerful response.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_360.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[318, 1420], [1490, 4300], [4415, 5433], [6157, 7852], [8553, 15146], [16687, 18490], [18713, 19634], [19660, 20641], [21059, 24558], [24605, 25657], [25701, 27760], [27769, 28798], [29690, 31584], [33018, 34151], [35102, 39088], [39472, 45459], [45693, 47792], [48316, 52000], [53662, 58978], [59639, 64210], [66418, 68911], [69136, 70196], [70571, 72203], [72774, 74012], [74118, 75026], [75510, 76477], [77491, 78321], [78418, 84459], [85218, 86931], [87977, 94009], [94397, 95751], [97420, 101181], [102170, 106381], [106472, 107371], [107766, 110826], [112302, 114364], [114573, 116661]], "num_segments": 37}
{"id": "sakura_emotion_372_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_372_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["This is the best day ever, I feel on top of the world!", "That\u2019s just revolting, I can\u2019t believe it.", "It\u2019s hard to imagine things ever getting better.", "This is terrifying, I can\u2019t stop thinking about it."], "answer": "It\u2019s hard to imagine things ever getting better.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_372.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[197, 2260], [2344, 3246], [3533, 5427], [5834, 8914], [8990, 16587], [16864, 17975], [18418, 19589], [19872, 24569], [24675, 25559], [26509, 29326], [29749, 34233], [34258, 37654], [38398, 39802], [41360, 42166], [42802, 45958], [47660, 51321], [51372, 53489]], "num_segments": 17}
{"id": "sakura_emotion_370_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_370_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["A warm, genuine smile with slightly tilted head", "Wrinkled forehead and a forlorn expression", "Clenched teeth with side facial muscles showing tension.", "Head slightly pulled back with a terrified gaze, as if searching for an escape."], "answer": "A warm, genuine smile with slightly tilted head", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_370.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[436, 3102], [3263, 4889], [5697, 10360], [10904, 11869], [13103, 16846], [18346, 21737], [22353, 28080], [29914, 37733], [38309, 42153], [42595, 44521], [45209, 47190], [47805, 51973], [52032, 56535], [57032, 57909], [58490, 63430], [63963, 70947], [71309, 77129], [77489, 83567], [84513, 90860], [93774, 100858], [101936, 109254], [109746, 111112], [111180, 114581], [114691, 116540], [117792, 121225], [121513, 129367], [129594, 131224], [132733, 140456], [141562, 142457], [142608, 145133], [147027, 153455], [155467, 159506]], "num_segments": 32}
{"id": "sakura_emotion_373_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_373_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["sad", "angry", "fear", "happy"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_373.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[314, 1314], [1358, 7020], [7820, 8871], [9816, 11242], [11932, 12758], [13338, 14507], [14853, 15855], [16046, 17140], [17294, 22979], [23910, 29412], [29756, 34561], [34764, 35942], [36207, 39486], [40056, 43330], [43865, 49637], [50637, 53353], [53541, 55040], [55572, 56994], [57289, 63793], [64076, 65349]], "num_segments": 20}
{"id": "sakura_emotion_374_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_374_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["sad", "disgust", "happy", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_374.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[922, 2203], [2507, 4380], [5238, 7276], [7690, 8586], [9324, 15353], [15659, 16759], [17367, 19045], [19388, 21096], [21312, 22276], [22464, 27383], [27501, 31582], [31818, 33141], [33627, 35670], [36479, 41585], [42140, 46015], [47098, 48307], [49193, 50578]], "num_segments": 17}
{"id": "sakura_emotion_375_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_375_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["A sharp, piercing gaze and compressed lips", "Frozen facial expression with trembling lips and quickened breathing.", "A heavy sigh with a frown and slumped posture", "Averted gaze with a grimacing mouth"], "answer": "Frozen facial expression with trembling lips and quickened breathing.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_375.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[27, 1330], [2318, 4164], [4240, 5148], [5193, 7633], [8090, 13860], [14231, 20987], [21265, 23190], [23546, 26302], [26812, 34410], [34600, 39163], [39481, 41535]], "num_segments": 11}
{"id": "sakura_emotion_375_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_375_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "angry", "sad", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_375.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[781, 2244], [2555, 5515], [5693, 7448], [7523, 8433], [8819, 10273], [11106, 13098], [13825, 15275], [16215, 21649], [22308, 23208], [23325, 26863], [27161, 28225], [28280, 29268], [29280, 33718], [34615, 38103], [38150, 41534]], "num_segments": 15}
{"id": "sakura_emotion_374_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_374_masked_100pct.wav", "question": "Which facial expression best fits the emotion heard in the audio?", "choices": ["Clenched teeth with side facial muscles showing tension.", "Frozen facial expression with trembling lips and quickened breathing.", "A drooping gaze with a slack jaw", "A warm, genuine smile with slightly tilted head"], "answer": "Clenched teeth with side facial muscles showing tension.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_374.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[798, 1883], [1988, 3210], [3495, 9363], [9527, 10653], [11497, 13404], [14133, 17889], [17892, 21724], [21875, 22865], [23954, 25615], [25872, 29707], [29769, 32619], [32895, 35944], [37372, 43678], [43807, 49096], [49378, 51450]], "num_segments": 15}
{"id": "sakura_emotion_373_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_373_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Preparing for a high-stakes exam with anxiety.", "Reacting to a foul odor in a room.", "A parent scolding their child for misbehavior.", "Saying goodbye at an airport."], "answer": "A parent scolding their child for misbehavior.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_373.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[444, 4968], [5362, 6855], [7214, 13432], [14125, 17350], [17862, 20038], [20040, 20869], [21217, 22385], [23351, 24156], [24462, 25560], [25660, 26567], [28416, 34688], [35730, 37891], [38272, 43794], [45456, 46370], [46396, 47742], [47775, 49306], [50027, 55358], [55761, 56681], [57855, 59008], [59377, 60268], [60842, 64890]], "num_segments": 21}
{"id": "sakura_emotion_376_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_376_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "sad", "disgust", "fear"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_376.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[185, 996], [2494, 9585], [10389, 11900], [12055, 13498], [14872, 17190], [17360, 18364], [18401, 20956], [22188, 27098], [28668, 33054], [33468, 34492], [35591, 37324], [37516, 38654], [39064, 39952], [40460, 47952], [48505, 49476]], "num_segments": 15}
{"id": "sakura_emotion_378_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_378_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "fear", "disgust", "sad"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_378.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[398, 2014], [2590, 5854], [6816, 8890], [10338, 11509], [12435, 13494], [13568, 18531], [19965, 21206], [22690, 29490], [29799, 36177], [36744, 37740], [39240, 44344], [44488, 50858], [50944, 52370], [52631, 54083], [54441, 55452], [55727, 56733], [57851, 64125]], "num_segments": 17}
{"id": "sakura_emotion_376_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_376_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Offer reassurance and remind them they are safe.", "Express genuine excitement for their good news or achievement.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Listen empathetically and let them express their feelings."], "answer": "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_376.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[512, 3988], [4206, 5127], [5728, 8000], [8066, 9299], [9865, 10840], [11886, 14658], [15799, 17548], [17753, 19239], [19264, 21368], [22073, 22907], [23560, 24879], [26102, 27375], [27533, 30177], [30221, 31930], [33091, 35627], [36458, 37683], [37910, 41585], [43226, 44751], [45206, 46762], [46961, 47781], [47883, 48805]], "num_segments": 21}
{"id": "sakura_emotion_377_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_377_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["I can\u2019t believe this is happening, I\u2019m so furious!", "It\u2019s hard to imagine things ever getting better.", "I feel like I\u2019m in danger, and I don\u2019t know what to do.", "That\u2019s just revolting, I can\u2019t believe it."], "answer": "I feel like I\u2019m in danger, and I don\u2019t know what to do.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_377.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[260, 2834], [3446, 10931], [11866, 15802], [15879, 17875], [17914, 20719], [22045, 22860], [23284, 24743], [24848, 25660], [25745, 26688], [27712, 29993], [30778, 34024], [34667, 35583], [36108, 41867], [41907, 43045], [43079, 44201], [44788, 47501], [49103, 52621], [53083, 54230], [54454, 56951]], "num_segments": 19}
{"id": "sakura_emotion_370_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_370_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["sad", "fear", "happy", "angry"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_370.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1785, 7328], [8530, 10027], [10499, 12504], [12878, 14036], [14468, 19238], [20263, 21506], [22808, 24169], [24574, 25913], [26555, 28292], [28311, 29251], [29308, 30335], [30601, 31873], [32834, 33954], [34285, 35212], [35808, 36703], [36958, 42946], [43246, 44571], [46029, 47483], [47786, 49685], [50513, 53030], [53219, 59656], [61061, 63196], [63373, 64622], [66150, 67660], [68170, 70661], [71103, 72303], [73048, 77194], [78254, 84877], [86240, 87474], [87530, 89250], [90037, 91365], [91404, 92786], [92973, 100392], [101455, 102782], [103546, 106519], [107447, 109566], [110602, 115767], [117069, 118416], [118604, 120163], [121549, 123221], [123516, 127035], [127195, 129898], [130363, 131700], [131983, 135291], [136181, 137407], [137552, 138897], [140348, 148013], [150269, 155319], [157452, 159608]], "num_segments": 49}
{"id": "sakura_emotion_377_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_377_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["disgust", "happy", "fear", "angry"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_377.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[722, 4374], [4530, 6349], [6739, 8279], [8287, 12615], [12824, 14425], [14895, 16628], [17225, 19188], [20101, 22618], [24361, 27179], [27805, 28744], [28937, 30441], [31066, 35991], [36150, 37100], [37709, 39564], [39639, 40995], [41975, 46660], [47622, 54104], [54113, 55308], [55653, 56754]], "num_segments": 19}
{"id": "sakura_emotion_379_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_379_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["sad", "happy", "disgust", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_379.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[628, 1746], [1755, 4158], [4312, 8559], [9405, 15562], [16057, 17558], [17853, 21147], [21303, 22935], [23227, 25125], [25224, 28806], [29570, 32004], [32592, 37415], [37504, 38370], [39150, 41083], [41262, 42437], [42796, 44796]], "num_segments": 15}
{"id": "sakura_emotion_379_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_379_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["I feel so empty, like nothing matters anymore.", "I\u2019m really scared about what might happen next.", "I can\u2019t even look at this without feeling uncomfortable.", "I feel so grateful and full of joy right now."], "answer": "I\u2019m really scared about what might happen next.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_379.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[780, 2287], [2587, 4048], [4286, 8470], [9059, 10299], [11490, 13165], [13735, 18690], [20033, 22539], [23076, 25049], [25174, 29090], [30003, 31050], [31874, 35246], [35896, 40509], [40741, 41544], [41792, 44710]], "num_segments": 14}
{"id": "sakura_emotion_378_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_378_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Turning away from spoiled food.", "A person yelling after being cut off in traffic.", "A person smiling after receiving good news.", "Walking alone in a dark alley at night."], "answer": "Turning away from spoiled food.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_378.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[754, 2428], [2740, 4250], [4331, 5631], [6654, 9883], [9919, 17518], [19897, 21884], [22508, 23776], [23853, 25852], [26231, 27850], [28029, 28951], [29876, 32555], [32702, 35055], [35385, 36681], [36718, 38800], [38842, 39777], [40899, 45428], [45474, 48716], [49173, 55653], [55737, 59244], [60660, 65527]], "num_segments": 20}
{"id": "sakura_emotion_380_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_380_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Throwing an object in frustration.", "Saying goodbye at an airport.", "Watching a horror movie alone in the dark.", "Seeing an unpleasant image online."], "answer": "Watching a horror movie alone in the dark.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_380.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[754, 2024], [2142, 3295], [4214, 5220], [6240, 7204], [7324, 10085], [10397, 11348], [12445, 19338], [20934, 28055], [28201, 30239], [30598, 31665], [31685, 32690], [32942, 35228], [35918, 37386], [37813, 39772], [40916, 42183], [42461, 45645], [46764, 48148], [49037, 51929], [52021, 53182], [53330, 54234], [54793, 57669], [57698, 58760], [58823, 60760]], "num_segments": 23}
{"id": "sakura_emotion_380_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_380_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "angry", "disgust", "happy"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_380.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1247, 8887], [9118, 15528], [15654, 16909], [18424, 20728], [21009, 22065], [22642, 26028], [27347, 28463], [29701, 31756], [32299, 39110], [40918, 43699], [44932, 52116], [52151, 53116], [53894, 56293], [56825, 59905], [60852, 62001]], "num_segments": 15}
{"id": "sakura_emotion_382_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_382_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Attending a close friend's funeral.", "Hearing a shocking and offensive statement.", "Facing an aggressive dog on the street.", "Throwing an object in frustration."], "answer": "Hearing a shocking and offensive statement.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_382.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[476, 1329], [1578, 3209], [3610, 11066], [11135, 12719], [12908, 14365], [15267, 17898], [17998, 21037], [21694, 25190], [25678, 26821]], "num_segments": 9}
{"id": "sakura_emotion_382_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_382_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "disgust", "happy", "sad"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_382.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[522, 1323], [1689, 8204], [8318, 9621], [9801, 12078], [13176, 14051], [14179, 19516], [19845, 24051], [24283, 26366]], "num_segments": 8}
{"id": "sakura_emotion_383_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_383_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Apologize and admit your mistake, if appropriate.", "Suggest spending some time together to cheer them up.", "Offer reassurance and remind them they are safe.", "Express genuine excitement for their good news or achievement."], "answer": "Apologize and admit your mistake, if appropriate.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_383.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[348, 1452], [1704, 5825], [6315, 7518], [8091, 12458], [13936, 17530], [17551, 18531], [19367, 21243], [21565, 25894], [26107, 27216], [27433, 28379], [28474, 32002], [32349, 34258], [35480, 36525]], "num_segments": 13}
{"id": "sakura_emotion_383_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_383_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["sad", "fear", "disgust", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_383.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1709, 5277], [5996, 8187], [8622, 9909], [10743, 13380], [13685, 14633], [15487, 17192], [17377, 18726], [20045, 25004], [26454, 27540], [27607, 29814], [30763, 31973], [32087, 33181], [33747, 35422], [35754, 37202]], "num_segments": 14}
{"id": "sakura_emotion_384_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_384_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["I can\u2019t believe this is happening, I\u2019m so furious!", "I feel so empty, like nothing matters anymore.", "This is the best day ever, I feel on top of the world!", "It\u2019s so dirty! Please clean it as quick as possible."], "answer": "This is the best day ever, I feel on top of the world!", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_384.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[91, 3324], [3558, 5049], [6102, 7011], [7013, 8998], [9132, 16741], [16884, 19531], [19708, 20727], [21533, 25171], [25637, 26922]], "num_segments": 9}
{"id": "sakura_emotion_385_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_385_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Offer reassurance and remind them they are safe.", "Listen attentively without interrupting to let them vent.", "Suggest an activity to keep the positive energy flowing.", "Provide emotional support and avoid dismissing their sadness."], "answer": "Offer reassurance and remind them they are safe.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_385.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1390, 8233], [9210, 15710], [16098, 22821], [22988, 24735], [24858, 27878], [28497, 29520]], "num_segments": 6}
{"id": "sakura_emotion_386_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_386_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "angry", "disgust", "fear"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_386.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[255, 1388], [1429, 2538], [3677, 5634], [7016, 10849], [10931, 12376], [12482, 19387], [20482, 21809], [21923, 23530], [23919, 26433], [27791, 34641], [34781, 35585], [35842, 38216], [38292, 44162], [45574, 47542]], "num_segments": 14}
{"id": "sakura_emotion_384_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_384_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "happy", "angry", "sad"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_384.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[776, 2092], [3006, 9342], [10641, 12368], [12773, 13725], [13879, 21799], [22089, 22937], [23242, 24196], [24218, 25287], [26131, 27255]], "num_segments": 9}
{"id": "sakura_emotion_385_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_385_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "angry", "sad", "disgust"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_385.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[633, 2432], [2515, 5038], [5857, 7764], [7893, 9730], [10037, 14194], [14950, 19125], [20114, 22285], [22682, 23741], [24222, 29804]], "num_segments": 9}
{"id": "sakura_emotion_386_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_386_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Squinted eyes and a pinched nose", "A radiant expression with raised cheeks", "A sharp, piercing gaze and compressed lips", "Head slightly pulled back with a terrified gaze, as if searching for an escape."], "answer": "A sharp, piercing gaze and compressed lips", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_386.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[825, 3674], [4146, 6314], [7561, 12281], [12283, 14475], [15747, 20081], [20955, 22214], [22295, 28235], [28750, 29998], [30894, 35664], [35867, 38578], [39009, 40226], [40308, 43861], [45025, 48049]], "num_segments": 13}
{"id": "sakura_emotion_389_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_389_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["happy", "disgust", "fear", "sad"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_389.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[79, 5526], [5588, 6417], [6947, 8935], [9553, 13611], [14657, 15492], [15831, 18168], [18266, 20709], [21926, 26609], [27442, 28284], [28874, 31969]], "num_segments": 10}
{"id": "sakura_emotion_387_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_387_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["Clenched teeth with side facial muscles showing tension.", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "A warm, genuine smile with slightly tilted head", "Tightly furrowed brow with trembling lips"], "answer": "Tightly furrowed brow with trembling lips", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_387.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[215, 3591], [3902, 6196], [7605, 10034], [10538, 12570], [13529, 14686], [15317, 16534], [16871, 18756], [19249, 23375], [23653, 28743], [29862, 35655], [36842, 38652], [38672, 39702], [39736, 42893], [43087, 44902], [44919, 50016], [50442, 53219], [54064, 55766]], "num_segments": 17}
{"id": "sakura_emotion_389_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_389_masked_100pct.wav", "question": "Which facial expression best fits the emotion heard in the audio?", "choices": ["A sharp, piercing gaze and compressed lips", "A warm, genuine smile with slightly tilted head", "Tightly furrowed brow with trembling lips", "Downturned mouth and teary eyes"], "answer": "A warm, genuine smile with slightly tilted head", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_389.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[14, 1340], [1420, 4886], [4935, 7039], [8165, 12698], [12906, 16914], [17141, 22102], [22234, 23975], [24283, 31474]], "num_segments": 8}
{"id": "sakura_emotion_387_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_387_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["happy", "angry", "fear", "disgust"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_387.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[323, 1224], [2883, 7066], [7171, 10270], [11573, 17063], [17089, 22425], [24023, 30555], [30761, 32451], [32825, 34094], [34573, 36062], [36239, 37253], [37484, 40479], [40525, 42624], [42773, 48615], [48830, 51009], [51049, 51994], [52549, 55292]], "num_segments": 16}
{"id": "sakura_emotion_390_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_390_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "fear", "angry", "sad"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_390.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[963, 2047], [2284, 7265], [8042, 9647], [10084, 14645], [15176, 16850], [17126, 18519], [19176, 21986], [23188, 24055]], "num_segments": 8}
{"id": "sakura_emotion_391_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_391_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["disgust", "happy", "fear", "angry"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_391.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[562, 1698], [2302, 7478], [7585, 14535]], "num_segments": 3}
{"id": "sakura_emotion_392_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_392_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "happy", "fear", "sad"], "answer": "angry", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_392.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[161, 1765], [2408, 4557], [4703, 5657], [5879, 6790], [8009, 11950], [12139, 13639], [13809, 19364], [21278, 28929], [29094, 30469], [30723, 32157], [33300, 36133], [36627, 41272], [42563, 44270], [44478, 45333], [45845, 48026], [49976, 51944]], "num_segments": 16}
{"id": "sakura_emotion_381_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_381_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Hugging a loved one after a long separation.", "A heated argument between colleagues.", "Turning away from spoiled food.", "Attending a close friend's funeral."], "answer": "A heated argument between colleagues.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_381.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2, 1627], [2312, 6215], [6353, 9893], [10536, 16070], [16553, 19444], [19674, 21921], [21977, 26395], [27217, 30048], [30370, 31229], [33928, 34992], [36606, 37519], [37528, 38694], [38697, 45546], [46004, 52521], [53667, 54857], [54906, 60345], [61096, 62866], [63874, 71537], [72144, 79906], [81882, 83331], [84401, 86331], [86522, 87498], [87811, 88966], [91248, 93804], [93848, 97137], [97610, 99017], [100081, 101061], [101299, 104168], [107218, 108048], [108297, 109294], [110333, 111186], [111324, 116024], [118507, 120509], [122538, 128792], [129095, 130704], [131880, 133307], [133906, 135579], [135972, 139880], [140393, 142616], [142961, 144623], [147191, 148468], [148681, 149551], [151634, 153139], [153202, 154554], [155820, 160262], [160518, 165332], [166145, 174136], [174740, 176982], [177204, 181685], [183306, 185291], [185749, 186616], [187124, 193768]], "num_segments": 52}
{"id": "sakura_emotion_391_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_391_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["I can\u2019t believe this is happening, I\u2019m so furious!", "I just can\u2019t stop thinking about all those bad memories.", "I\u2019m really scared about what might happen next.", "I can\u2019t stop smiling, everything feels so right."], "answer": "I can\u2019t stop smiling, everything feels so right.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_391.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[20, 1946], [2182, 3759], [4045, 6213], [7538, 11010], [12053, 15361]], "num_segments": 5}
{"id": "sakura_emotion_381_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_381_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "fear", "sad", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_381.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[27, 2670], [4662, 5469], [6029, 8274], [8315, 11076], [12947, 15439], [16109, 17600], [17721, 19539], [20307, 24809], [27279, 28235], [28354, 30354], [30748, 34520], [35309, 36719], [36929, 42215], [43547, 44728], [45563, 49574], [49617, 56482], [57307, 59413], [60722, 68014], [68897, 70511], [70859, 73271], [74886, 78718], [79042, 86247], [86353, 93164], [93827, 94674], [94795, 96766], [98425, 99687], [99853, 103235], [103578, 104899], [105270, 108436], [110488, 118213], [118375, 119593], [120212, 121012], [121351, 122832], [123590, 126154], [126186, 127133], [128299, 129941], [131272, 138194], [139123, 144573], [145741, 152889], [154057, 161088], [161692, 163224], [163523, 165307], [165878, 167212], [167350, 169094], [169340, 170332], [171661, 176011], [176749, 183342], [184136, 191760], [192454, 194530]], "num_segments": 49}
{"id": "sakura_emotion_392_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_392_masked_100pct.wav", "question": "Which facial expression best matches the emotion in the audio?", "choices": ["Averted gaze with a grimacing mouth", "Furrowed brows with slightly open mouth, as if about to shout.", "A radiant expression with raised cheeks", "A heavy sigh with a frown and slumped posture"], "answer": "Furrowed brows with slightly open mouth, as if about to shout.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_392.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[725, 7914], [8084, 9748], [11109, 18079], [19244, 23119], [23823, 26025], [26086, 27022], [27193, 30226], [30444, 31383], [31825, 37696], [37863, 40617], [41685, 46150], [46670, 47525], [47766, 48632], [49056, 49933], [50027, 51965]], "num_segments": 15}
{"id": "sakura_emotion_388_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_388_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "angry", "happy", "fear"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_388.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[298, 2772], [3011, 5153], [7263, 8996], [10711, 12642], [13208, 15666], [15702, 23470], [23889, 25374], [26013, 27206], [28361, 32213], [32788, 33880], [35125, 39814], [40144, 42376], [42445, 43445], [44085, 52031], [52210, 59973], [61216, 62682], [64234, 65478], [68134, 71139], [71837, 73871], [74581, 79495], [80617, 81625], [82085, 83568]], "num_segments": 22}
{"id": "sakura_emotion_393_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_393_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["fear", "angry", "sad", "happy"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_393.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1412, 3702], [3811, 4704], [5741, 9270], [9809, 13481], [13866, 15051], [15163, 16187], [16462, 18050], [19193, 20793], [20823, 27236], [27346, 29633], [30037, 30958], [31026, 36516]], "num_segments": 12}
{"id": "sakura_emotion_388_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_388_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Listen empathetically and let them express their feelings.", "Celebrate their joy with a cheerful response.", "Express understanding calmly and suggest leaving the unpleasant environment.", "Hold their hand or offer some physical reassurance."], "answer": "Celebrate their joy with a cheerful response.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_388.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[900, 2000], [2236, 3376], [3554, 4661], [5142, 11403], [11515, 16079], [16897, 19987], [20389, 21833], [22361, 25529], [25715, 26634], [26678, 32310], [32786, 39311], [39678, 43310], [44466, 47156], [47555, 54923], [55064, 56100], [57498, 58429], [58648, 62074], [62871, 65709], [66547, 72249], [72958, 74279], [75657, 81464]], "num_segments": 21}
{"id": "sakura_emotion_390_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_390_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["This thing looks absolutely gross and dirty; I can\u2019t stand it!", "I feel so empty, like nothing matters anymore.", "I can\u2019t stop smiling, everything feels so right.", "This situation is really starting to piss me off!"], "answer": "This situation is really starting to piss me off!", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_390.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[370, 6974], [7044, 10383], [10616, 16130], [16441, 20741], [21575, 23320]], "num_segments": 5}
{"id": "sakura_emotion_393_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_393_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["This is terrifying, I can\u2019t stop thinking about it.", "I\u2019m just so happy I could burst!", "I can\u2019t even look at this without feeling uncomfortable.", "I don\u2019t know how to move on from this loss."], "answer": "This is terrifying, I can\u2019t stop thinking about it.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_393.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1069, 2911], [3828, 10309], [11215, 16473], [16619, 17842], [17863, 18783], [19061, 20655], [20817, 24023], [24395, 26557], [26788, 27724], [27926, 29878], [30575, 32958], [33979, 35223], [35385, 36581]], "num_segments": 13}
{"id": "sakura_emotion_396_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_396_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Encourage them to take deep breaths to relax.", "Give them space to cool off before engaging further.", "Suggest spending some time together to cheer them up.", "Express understanding calmly and suggest leaving the unpleasant environment."], "answer": "Give them space to cool off before engaging further.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_396.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[197, 1009], [1146, 2080], [2194, 5463]], "num_segments": 3}
{"id": "sakura_emotion_394_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_394_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "disgust", "sad", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_394.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[186, 7937], [8582, 12445], [13166, 19209], [19279, 20730], [22387, 29670], [30740, 35024], [35047, 36609], [36808, 38068], [38982, 46886], [47434, 50420], [50919, 52728], [52789, 54254], [54997, 57814], [59136, 60448], [61019, 64219]], "num_segments": 15}
{"id": "sakura_emotion_397_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_397_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "happy", "fear", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_397.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[295, 4875], [5439, 6332], [6802, 8843], [8940, 10975], [11103, 17636], [19042, 20052], [20293, 21785], [22506, 23401]], "num_segments": 8}
{"id": "sakura_emotion_396_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_396_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["disgust", "fear", "sad", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_396.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[18, 1364], [1643, 2549], [2886, 4657], [4721, 5528]], "num_segments": 4}
{"id": "sakura_emotion_394_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_394_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Eyes gazing downward with trembling lips", "Frozen facial expression with trembling lips and quickened breathing.", "A warm, genuine smile with slightly tilted head", "A sharp, piercing gaze and compressed lips"], "answer": "A sharp, piercing gaze and compressed lips", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_394.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[895, 4153], [4736, 6425], [6638, 9463], [10508, 15698], [16022, 22316], [22399, 27769], [28513, 29336], [29505, 33055], [33736, 38477], [39405, 42507], [42909, 44117], [44358, 51997], [52763, 56793], [56807, 64607], [65044, 66041]], "num_segments": 15}
{"id": "sakura_emotion_397_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_397_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Rejecting a tasteless meal with a grimace.", "Throwing an object in frustration.", "Walking alone in a dark alley at night.", "A person smiling after receiving good news."], "answer": "Throwing an object in frustration.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_397.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[839, 1985], [2690, 5005], [5053, 6045], [6661, 9330], [9409, 14024], [14183, 14987], [15095, 20924], [20979, 22545], [23700, 24651]], "num_segments": 9}
{"id": "sakura_emotion_395_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_395_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["angry", "fear", "disgust", "happy"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_395.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[320, 3532], [4829, 8305], [8612, 10034], [10142, 11201], [11563, 13863], [14401, 15566], [16552, 18202], [18297, 19282], [19757, 20979], [21232, 22386], [22972, 24045], [24506, 27533], [27573, 34367], [35431, 39135], [40665, 41506], [42900, 48443], [49413, 50332], [50492, 55287], [56498, 62524], [64748, 72010], [72876, 77956], [79101, 80238], [80609, 87183], [88317, 89895], [91056, 97650], [99151, 100956], [101224, 104372], [104540, 105904]], "num_segments": 28}
{"id": "sakura_emotion_398_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_398_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "fear", "happy", "disgust"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_398.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1197, 3830], [3954, 4754], [4813, 6723], [6886, 9141], [10060, 14420], [14644, 16257], [16441, 22534], [22694, 23671], [24844, 27077], [28225, 31744], [33257, 35934], [37588, 43907], [44036, 45832], [46192, 48183], [50223, 52081], [53186, 54254], [54292, 55940], [56222, 60936], [61360, 62653], [63500, 65334], [67391, 70214], [70575, 71629], [72049, 73629], [74203, 76426], [76608, 80749], [81009, 82007], [83492, 86989]], "num_segments": 27}
{"id": "sakura_emotion_395_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_395_masked_100pct.wav", "question": "Considering the emotion expressed in the audio, which of the following facial expressions would align most closely with it?", "choices": ["Wrinkled forehead and a forlorn expression", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "Flared nostrils with a tense expression", "Tightly furrowed brow with trembling lips"], "answer": "Retracted chin with one corner of the mouth twitching, as if intolerable.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_395.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1042, 2559], [4038, 11131], [11628, 19208], [19526, 24286], [24445, 25486], [26701, 27517], [27526, 30598], [31211, 36344], [36441, 37392], [38343, 40673], [41807, 42669], [43028, 44054], [45394, 50787], [51468, 55598], [56553, 58961], [59174, 63890], [64120, 65006], [65946, 66947], [70016, 72362], [73038, 75284], [76478, 78531], [79565, 85078], [86130, 87072], [88266, 95294], [96220, 100266], [100496, 103051], [104172, 105634]], "num_segments": 27}
{"id": "sakura_emotion_400_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_400_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["happy", "fear", "sad", "angry"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_400.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1289, 4496], [4852, 5673], [6304, 12339], [12786, 15310], [15569, 19804], [20464, 22391], [22676, 23779], [24049, 25202], [25706, 27423], [28199, 29885], [30183, 32364], [32443, 33439], [33680, 35259], [35499, 37935], [38058, 38869]], "num_segments": 15}
{"id": "sakura_emotion_398_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_398_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["How dare they treat me so unfairly like this!", "This is terrifying, I can\u2019t stop thinking about it.", "I feel so grateful and full of joy right now.", "I\u2019m feeling so down, like nothing can lift my spirits."], "answer": "I\u2019m feeling so down, like nothing can lift my spirits.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_398.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1197, 2270], [3270, 4271], [4696, 12415], [13304, 14361], [14709, 19357], [19428, 22866], [23310, 29955], [30117, 31682], [31992, 33283], [33440, 34530], [34747, 36175], [36903, 42616], [43864, 44939], [45065, 46076], [46130, 47389], [47725, 53387], [53699, 56742], [58620, 59814], [60933, 61830], [62028, 66498], [67101, 68879], [69762, 71958], [72693, 78328], [79346, 81424], [83346, 87804]], "num_segments": 25}
{"id": "sakura_emotion_400_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_400_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Express understanding calmly and suggest leaving the unpleasant environment.", "Offer reassurance and remind them they are safe.", "Calmly acknowledge their frustration and suggest a solution.", "Listen empathetically and let them express their feelings."], "answer": "Listen empathetically and let them express their feelings.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_400.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[92, 901], [2117, 4005], [4122, 6684], [7420, 13649], [13653, 20087], [20262, 27112], [28174, 31286], [31431, 36781], [37149, 38702]], "num_segments": 9}
{"id": "sakura_emotion_399_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_399_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "fear", "angry", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_399.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[286, 1118], [1314, 3101], [4183, 7308], [8192, 13244], [13341, 18102], [20371, 26937], [27741, 29855], [30672, 33721], [35092, 36426], [38914, 45549], [45830, 52340], [53381, 55575], [57325, 60105], [60654, 61606], [62844, 66024], [66129, 67103], [68497, 73725], [73738, 77534], [77594, 78440], [80043, 80984], [82041, 84059], [84910, 86782], [87233, 88283], [88826, 89806], [90649, 91950], [93738, 95644], [97345, 98377], [98953, 104454], [104600, 106476], [106860, 111806], [112678, 113760], [114164, 121932], [122304, 123796], [125833, 126831], [127377, 128571], [128958, 136810]], "num_segments": 36}
{"id": "sakura_emotion_401_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_401_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Offer reassurance and remind them they are safe.", "Apologize and admit your mistake, if appropriate.", "Reassure them and offer a way to move past the uncomfortable    situation.", "Offer a comforting hug or words of reassurance."], "answer": "Offer a comforting hug or words of reassurance.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_401.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[699, 1587], [1699, 5005], [5604, 9069], [9934, 11343], [12184, 13961], [14169, 19319], [20217, 21379], [22149, 24348], [24523, 25461], [25918, 29801], [30360, 31339], [31529, 34769], [35597, 39485], [39840, 41143], [41340, 42750], [42965, 44645], [44890, 47550], [48539, 49603], [49769, 51070], [51091, 56185], [56919, 58634]], "num_segments": 21}
{"id": "sakura_emotion_401_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_401_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["angry", "happy", "fear", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_401.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1121, 2659], [3020, 9749], [9923, 10792], [11374, 12202], [13995, 14850], [15061, 19234], [20688, 21965], [22419, 25490], [25801, 29758], [29892, 34537], [34931, 37931], [40722, 44505], [45565, 46762], [46875, 51023], [53015, 54121], [54835, 57697]], "num_segments": 16}
{"id": "sakura_emotion_399_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_399_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["Watching a touching but sorrowful movie scene.", "Walking alone in a dark alley at night.", "A parent scolding their child for misbehavior.", "A person smiling after receiving good news."], "answer": "Watching a touching but sorrowful movie scene.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_399.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2777, 4473], [4713, 10921], [12040, 15654], [15971, 23051], [23596, 24439], [25454, 27442], [28313, 31403], [32484, 33884], [35508, 38442], [38513, 44696], [44981, 47016], [48877, 50787], [52521, 53844], [54134, 56106], [57348, 58777], [58992, 60194], [60316, 65928], [67232, 68481], [69857, 77055], [77503, 85010], [87449, 88405], [88826, 90336], [90748, 92164], [92891, 93810], [94322, 95435], [98304, 105821], [106269, 109115], [111326, 118287], [120342, 124123], [124914, 127795], [130081, 131394], [131435, 134210], [134712, 135840], [135947, 138658]], "num_segments": 34}
{"id": "sakura_emotion_402_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_402_masked_100pct.wav", "question": "Considering the emotion expressed in the audio, which of the following facial expressions would align most closely with it?", "choices": ["Wrinkled forehead and a forlorn expression", "A wrinkled nose and raised upper lip", "Clenched teeth with side facial muscles showing tension.", "A broad smile with sparkling eyes"], "answer": "Wrinkled forehead and a forlorn expression", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_402.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[907, 3322], [3494, 8269], [8950, 10549], [10587, 11474], [12171, 13472], [14009, 19043], [19718, 20919], [21112, 22086], [23140, 26256], [27179, 28118], [29113, 30578], [30897, 35464], [35924, 43861], [44072, 45215], [45580, 50793], [51557, 58537]], "num_segments": 16}
{"id": "sakura_emotion_402_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_402_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "fear", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_402.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[159, 1151], [1237, 3959], [4604, 11738], [12372, 14216], [16117, 18297], [18327, 19143], [19709, 23498], [24779, 25621], [26140, 30231], [30363, 31840], [31892, 33363], [33864, 35729], [36001, 37442], [37947, 44564], [44776, 47026], [47069, 53053], [55073, 56351], [56853, 58224]], "num_segments": 18}
{"id": "sakura_emotion_404_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_404_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "fear", "sad", "disgust"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_404.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2308, 5438], [5674, 6734], [6737, 7939], [8012, 9545], [9689, 11028], [11679, 12557], [12566, 16365], [16558, 19103], [19628, 22375], [23224, 25114], [25499, 27649], [28748, 31303], [31829, 37403], [39078, 46780], [47056, 48155], [49513, 51625], [51695, 53299], [54204, 58388]], "num_segments": 18}
{"id": "sakura_emotion_404_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_404_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["Eyes crinkling with an open-mouthed laugh", "A heavy sigh with a frown and slumped posture", "A wrinkled nose and raised upper lip", "Head slightly pulled back with a terrified gaze, as if searching for an escape."], "answer": "Eyes crinkling with an open-mouthed laugh", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_404.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[11, 831], [1036, 2241], [2384, 3276], [3306, 8128], [8502, 10397], [11151, 12565], [12663, 13469], [13664, 18745], [19436, 20669], [20958, 24182], [24718, 25560], [25634, 28755], [29314, 30957], [31055, 32902], [33515, 35655], [35849, 37130], [37856, 41521], [41598, 48803], [49612, 51893], [52145, 54307], [54673, 55899], [55918, 58369]], "num_segments": 22}
{"id": "sakura_emotion_405_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_405_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "sad", "fear", "angry"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_405.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1803, 2737], [2919, 4768], [4843, 10844], [13120, 15104], [17932, 21953], [22105, 28228], [30334, 32059], [32326, 33602], [34694, 37163], [37876, 39050], [39225, 42075], [42448, 48569], [49989, 52629], [52990, 57064], [57350, 58176], [58804, 62930], [63271, 65381], [66667, 67714], [69077, 71419], [71577, 72562], [73062, 73883], [74960, 77399], [77507, 78907], [80915, 83602], [84826, 86559], [86958, 88095], [88247, 91120], [93278, 98516], [98900, 101020], [101479, 102553], [102609, 109187]], "num_segments": 31}
{"id": "sakura_emotion_408_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_408_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "happy", "disgust", "sad"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_408.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[24, 1359], [1595, 7400], [7916, 8976], [11062, 12813], [14060, 15230], [15265, 19685], [20768, 23847], [24061, 25596]], "num_segments": 8}
{"id": "sakura_emotion_403_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_403_masked_100pct.wav", "question": "Which situation best corresponds to the emotion conveyed in the speech?", "choices": ["A heated argument between colleagues.", "Reacting to a sudden loud noise in an empty house.", "Winning a long-anticipated award or prize.", "Reading a heartfelt goodbye letter."], "answer": "Reacting to a sudden loud noise in an empty house.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_403.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[951, 7961], [8421, 14007], [14223, 19834], [20246, 25595], [26048, 27442], [27490, 29026], [29028, 30123], [30449, 35161], [35424, 37030], [37614, 39266], [39470, 40293], [42138, 46082], [46097, 49375], [49480, 51735], [51921, 53393], [55378, 59297], [59620, 66152], [67977, 70739], [70794, 71614], [71909, 72899]], "num_segments": 20}
{"id": "sakura_emotion_403_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_403_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "sad", "happy", "angry"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_403.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[293, 1221], [1533, 2392], [2586, 4912], [6196, 13672], [15543, 18787], [19571, 22109], [22121, 23943], [24584, 28967], [30954, 32307], [32446, 33893], [34831, 37863], [38663, 40003], [40295, 43294], [44653, 45754], [45754, 50510], [52489, 60459], [61443, 65429], [65649, 66617], [67294, 73855]], "num_segments": 19}
{"id": "sakura_emotion_405_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_405_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["Eyes crinkling with an open-mouthed laugh", "Tightly pressed lips with glaring eyes", "Downturned mouth and teary eyes", "Wide-open eyes with raised eyebrows and slightly parted lips."], "answer": "Downturned mouth and teary eyes", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_405.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[900, 2004], [2789, 7137], [8015, 15416], [15778, 20655], [20700, 23732], [23872, 28102], [30473, 32309], [33181, 38077], [38157, 40960], [41176, 44319], [44903, 51832], [51925, 55850], [55958, 59281], [59794, 61851], [63103, 65789], [66030, 69822], [70610, 71705], [72367, 74903], [76078, 76933], [77697, 82302], [82751, 84263], [84743, 87008], [88009, 89130], [89405, 90307], [90776, 91624], [92767, 94960], [95176, 96590], [97667, 99678], [100717, 107720], [108313, 109439]], "num_segments": 30}
{"id": "sakura_emotion_408_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_408_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I can\u2019t breathe, I\u2019m just so afraid right now.", "I can\u2019t believe this is happening, I\u2019m so furious!", "It\u2019s so dirty! Please clean it as quick as possible.", "I\u2019m so excited, I just can\u2019t contain my happiness!"], "answer": "It\u2019s so dirty! Please clean it as quick as possible.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_408.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1258, 2116], [2373, 8771], [9680, 10849], [11020, 12018], [12655, 13662], [13836, 15063], [15615, 16607], [16726, 17824], [18568, 21950], [22114, 23877], [24177, 25277]], "num_segments": 11}
{"id": "sakura_emotion_406_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_406_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["happy", "angry", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_406.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[339, 4718], [5316, 6738], [8394, 9860], [11138, 13916], [16355, 17402], [18356, 19288], [20896, 25929], [27109, 28893], [29295, 31867], [32516, 34527], [35899, 37622], [37834, 43450], [44914, 49591], [50630, 56525], [57102, 58746], [59832, 60639], [61342, 63240], [64053, 65119], [65958, 67509], [68517, 70002], [70103, 71505], [72250, 76333], [77116, 78916], [79125, 82790], [83738, 86583], [87054, 93926], [94689, 96222], [96532, 97697], [98547, 102084], [102706, 104078], [104084, 111849], [112793, 117908], [118894, 120577], [121210, 122020]], "num_segments": 34}
{"id": "sakura_emotion_407_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_407_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "happy", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_407.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1499, 2465], [3206, 4098], [4326, 7147], [9024, 12325], [13642, 15334], [15517, 20055], [20157, 22492], [23555, 28028], [28123, 29766], [29775, 30897], [31295, 35566], [36367, 37367], [37452, 39745], [40977, 48748], [51390, 52825], [53289, 55961], [57103, 59320], [59470, 60844], [60917, 64500], [64780, 65887], [66372, 70240], [70733, 72265], [74559, 75791], [75999, 80784], [81541, 83068], [83478, 85098]], "num_segments": 26}
{"id": "sakura_emotion_409_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_409_masked_100pct.wav", "question": "Considering the emotion expressed in the audio, which of the following facial expressions would align most closely with it?", "choices": ["Retracted chin with one corner of the mouth twitching, as if intolerable.", "Downturned mouth and teary eyes", "Eyes crinkling with an open-mouthed laugh", "Flared nostrils with a tense expression"], "answer": "Flared nostrils with a tense expression", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_409.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1129, 3019], [3136, 3961], [4016, 7741], [8981, 10766], [10886, 12291], [12714, 13786]], "num_segments": 6}
{"id": "sakura_emotion_409_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_409_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "sad", "angry", "fear"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_409.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[371, 1758], [1861, 2786], [3536, 10929], [11317, 12382], [12458, 13412]], "num_segments": 5}
{"id": "sakura_emotion_411_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_411_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["happy", "angry", "sad", "fear"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_411.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1485, 6620], [8311, 11343], [12903, 16776], [16929, 18048], [18871, 20428], [20756, 26679], [27759, 28892], [29404, 36070], [36331, 43641], [43791, 46637], [47844, 48853], [49249, 51712]], "num_segments": 12}
{"id": "sakura_emotion_407_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_407_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["This is terrifying, I can\u2019t stop thinking about it.", "I just can\u2019t stop thinking about all those bad memories.", "I can\u2019t believe this is happening, I\u2019m so furious!", "I\u2019m just so happy I could burst!"], "answer": "I just can\u2019t stop thinking about all those bad memories.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_407.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1275, 2219], [2261, 3903], [4869, 7368], [7712, 9387], [9901, 15042], [15069, 21329], [22406, 24373], [24868, 25983], [27063, 28262], [28726, 30597], [31078, 33163], [33283, 35713], [36500, 37555], [37652, 40552], [41142, 42075], [43296, 44327], [44664, 47944], [48750, 54346], [54944, 56300], [56421, 57262], [57805, 61257], [61257, 65339], [66614, 68045], [69327, 71924], [72731, 75954], [76451, 84087], [84353, 86187]], "num_segments": 27}
{"id": "sakura_emotion_410_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_410_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["How dare they treat me so unfairly like this!", "I can\u2019t shake the feeling that something bad is coming.", "I just can\u2019t stop thinking about all those bad memories.", "This is the best day ever, I feel on top of the world!"], "answer": "I just can\u2019t stop thinking about all those bad memories.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_410.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[337, 1608], [2488, 6587], [7181, 9321], [9657, 10516], [10527, 11587], [11943, 13107], [13506, 14991], [16312, 19030], [19825, 23028], [23772, 29435], [30071, 31081], [31536, 36508], [37971, 38803], [38908, 40986], [41206, 43625]], "num_segments": 15}
{"id": "sakura_emotion_411_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_411_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Tightly furrowed brow with trembling lips", "Furrowed brows with slightly open mouth, as if about to shout.", "A broad smile with sparkling eyes", "Retracted chin with one corner of the mouth twitching, as if intolerable."], "answer": "A broad smile with sparkling eyes", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_411.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[642, 1963], [2028, 3109], [3130, 4404], [4513, 5502], [5571, 6557], [7869, 12508], [13425, 14806], [15313, 21801], [23994, 30602], [30781, 33377], [33811, 35106], [35609, 36803], [36940, 42320], [43780, 47106], [47687, 50615]], "num_segments": 15}
{"id": "sakura_emotion_413_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_413_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "sad", "disgust", "fear"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_413.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[265, 1709], [2231, 4105], [4521, 6789], [7241, 12380], [13530, 19934], [20778, 27829], [28150, 29336], [29868, 31743]], "num_segments": 8}
{"id": "sakura_emotion_410_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_410_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["sad", "fear", "happy", "disgust"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_410.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[571, 1778], [2233, 3052], [3310, 7732], [8560, 9445], [9518, 10375], [11438, 18694], [18814, 19824], [21544, 24176], [24315, 25528], [25773, 26753], [26791, 32161], [33079, 39625], [39823, 42287], [42482, 43335]], "num_segments": 14}
{"id": "sakura_emotion_413_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_413_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I just can\u2019t stop thinking about all those bad memories.", "I can\u2019t breathe, I\u2019m just so afraid right now.", "It\u2019s so dirty! Please clean it as quick as possible.", "I\u2019m just so happy I could burst!"], "answer": "I just can\u2019t stop thinking about all those bad memories.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_413.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[747, 3386], [3540, 4342], [4744, 9521], [10151, 11225], [11450, 13040], [13491, 17661], [18521, 25238], [25482, 26343], [26875, 31233]], "num_segments": 9}
{"id": "sakura_emotion_412_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_412_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Offer reassurance and remind them they are safe.", "Smile and engage positively in the conversation.", "Provide emotional support and avoid dismissing their sadness.", "Give them space to cool off before engaging further."], "answer": "Offer reassurance and remind them they are safe.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_412.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[392, 8267], [8274, 9627], [10477, 12528], [13312, 16610], [17061, 17926], [20320, 22182], [23530, 29398], [30630, 31920], [32482, 33928], [34996, 38471], [38487, 42835], [43323, 44920], [45378, 51271], [51484, 53021], [53031, 55596], [57103, 61444], [61457, 62627], [62697, 66765], [67182, 74799], [74871, 78322], [79176, 85361], [85980, 90105], [91559, 92673]], "num_segments": 23}
{"id": "sakura_emotion_412_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_412_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["fear", "happy", "angry", "disgust"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_412.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1364, 8179], [9302, 10176], [10230, 11338], [12943, 20274], [20688, 28459], [28562, 30284], [30799, 31798], [32038, 34148], [34208, 35590], [35950, 38488], [38851, 40274], [40722, 42123], [42395, 46190], [46343, 47186], [47499, 49182], [50679, 51525], [53626, 58396], [59475, 60324], [60717, 65361], [65535, 67849], [69002, 74345], [75343, 76592], [77022, 78651], [78910, 81071], [81603, 84406], [84967, 87246], [87694, 90613]], "num_segments": 27}
{"id": "sakura_emotion_415_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_415_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "sad", "fear", "happy"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_415.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[12, 2854], [2875, 3791], [4379, 10910], [11052, 12338], [13111, 13962]], "num_segments": 5}
{"id": "sakura_emotion_415_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_415_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Eyes crinkling with an open-mouthed laugh", "A heavy sigh with a frown and slumped posture", "A sharp, piercing gaze and compressed lips", "Averted gaze with a grimacing mouth"], "answer": "A heavy sigh with a frown and slumped posture", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_415.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[82, 1368], [1570, 3404], [3997, 9878], [10147, 13770]], "num_segments": 4}
{"id": "sakura_emotion_406_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_406_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Suggest spending some time together to cheer them up.", "Calmly acknowledge their frustration and suggest a solution.", "Smile and engage positively in the conversation.", "Offer reassurance and remind them they are safe."], "answer": "Suggest spending some time together to cheer them up.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_406.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[681, 6314], [7876, 11439], [11603, 16968], [17793, 21169], [22019, 23642], [24937, 27324], [27568, 31488], [33048, 34447], [35088, 36297], [37203, 38730], [39191, 43403], [44604, 46172], [46257, 48269], [49659, 51497], [53919, 58573], [58677, 61790], [61903, 68685], [68961, 71688], [71770, 73424], [73473, 74286], [74529, 82224], [83204, 91170], [92187, 95077], [96099, 97512], [97769, 99046], [99148, 100688], [101037, 104499], [106147, 107565], [108141, 109319], [109678, 112616], [112751, 119498], [120330, 121283]], "num_segments": 32}
{"id": "sakura_emotion_414_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_414_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["fear", "disgust", "sad", "happy"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_414.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1348, 3743], [4401, 8180], [8384, 12415], [13838, 14883], [14970, 20119], [20735, 24648], [24709, 27180], [27515, 35174], [36668, 42972], [43165, 44581], [44626, 46147], [47154, 49001], [50178, 51329], [51742, 53118], [54763, 57277], [58145, 60172], [60199, 62200], [62908, 63760], [64529, 70948], [71426, 73246], [73639, 75484], [76265, 81804], [82657, 87727], [89046, 90307], [90568, 91888], [92565, 97173], [98230, 100749], [102359, 103814]], "num_segments": 28}
{"id": "sakura_emotion_418_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_418_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "disgust", "sad", "fear"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_418.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1558, 6969], [7363, 9545], [10379, 12618], [13246, 14398], [14532, 18354], [18379, 20099], [20545, 21541], [23276, 30131], [30346, 32972]], "num_segments": 9}
{"id": "sakura_emotion_414_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_414_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Encourage them to take deep breaths to relax.", "Reassure them and offer a way to move past the uncomfortable    situation.", "Calmly acknowledge their frustration and suggest a solution.", "Listen empathetically and let them express their feelings."], "answer": "Encourage them to take deep breaths to relax.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_414.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1593, 2554], [3087, 6720], [7251, 8741], [8990, 12233], [13604, 14817], [14869, 19912], [19984, 22863], [24394, 29417], [29422, 30537], [30593, 31564], [31576, 37367], [37602, 39626], [40693, 48613], [48813, 50057], [50419, 53634], [54523, 60140], [63515, 71092], [73010, 78845], [79952, 87103], [88320, 90621], [90742, 92456], [92501, 93431], [94186, 95643], [95712, 96527], [97197, 98476], [98725, 100699], [101971, 103989]], "num_segments": 27}
{"id": "sakura_emotion_417_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_417_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["disgust", "sad", "angry", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_417.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[359, 7788], [8913, 12495], [12849, 14162], [14540, 18896], [19200, 21774], [22250, 28763], [29300, 30784], [31662, 35206], [35732, 38307], [38592, 40030]], "num_segments": 10}
{"id": "sakura_emotion_418_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_418_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Stay calm and provide support to ease their anxiety.", "Provide emotional support and avoid dismissing their sadness.", "Reassure them and offer a way to move past the uncomfortable    situation.", "Smile and engage positively in the conversation."], "answer": "Provide emotional support and avoid dismissing their sadness.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_418.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[375, 1222], [1443, 2631], [2817, 3671], [3954, 11592], [11705, 13138], [13540, 15878], [16789, 23041], [24052, 26957], [27065, 32211]], "num_segments": 9}
{"id": "sakura_emotion_417_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_417_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["I\u2019m feeling so down, like nothing can lift my spirits.", "It\u2019s so dirty! Please clean it as quick as possible.", "I can\u2019t stop smiling, everything feels so right.", "How dare they treat me so unfairly like this!"], "answer": "I can\u2019t stop smiling, everything feels so right.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_417.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2053, 3114], [3467, 11166], [11217, 12311], [12463, 16993], [17297, 18356], [18883, 23412], [23645, 25303], [25318, 32285], [32659, 33663], [34080, 39521]], "num_segments": 10}
{"id": "sakura_emotion_419_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_419_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["fear", "sad", "happy", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_419.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[445, 1837], [1978, 2824], [3485, 10205], [10797, 11996], [12050, 13784], [14467, 18239], [18997, 26043]], "num_segments": 7}
{"id": "sakura_emotion_419_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_419_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Listen empathetically and let them express their feelings.", "Express understanding calmly and suggest leaving the unpleasant environment.", "Encourage them to take deep breaths to relax.", "Calmly acknowledge their frustration and suggest a solution."], "answer": "Express understanding calmly and suggest leaving the unpleasant environment.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_419.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[89, 1048], [1823, 2674], [2937, 6486], [7478, 8832], [9645, 14858], [15412, 16234], [16528, 17473], [18512, 25856]], "num_segments": 8}
{"id": "sakura_emotion_420_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_420_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["angry", "sad", "happy", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_420.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[629, 1790], [3105, 9697], [9709, 10624], [10991, 15373], [15952, 19787], [21800, 22887], [23259, 26604], [27362, 29327], [29338, 34538], [34668, 35740], [35951, 40799], [41319, 42737]], "num_segments": 12}
{"id": "sakura_emotion_416_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_416_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "disgust", "sad", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_416.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[170, 7150], [7936, 11528], [12730, 18050], [18498, 20551], [20693, 21911], [23110, 30496], [32105, 38424], [38873, 39784], [40786, 44974], [47019, 48673], [49785, 50618], [52007, 52829], [53050, 56540], [58791, 63323], [64791, 68781], [68821, 73533], [73867, 76545], [76633, 77784], [78026, 78864], [80390, 87549], [87827, 88836], [89300, 90393], [92405, 98211], [98306, 99469], [100746, 101774], [103165, 104535], [105192, 108401], [109859, 114333], [114528, 116693], [116770, 118942], [120639, 128011], [128363, 135340], [135615, 140209], [140374, 143855], [144038, 147227], [147408, 149427]], "num_segments": 36}
{"id": "sakura_emotion_416_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_416_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Walking alone in a dark alley at night.", "Watching a touching but sorrowful movie scene.", "A heated argument between colleagues.", "Rejecting a tasteless meal with a grimace."], "answer": "Walking alone in a dark alley at night.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_416.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[6, 7099], [8180, 9445], [11097, 12516], [12765, 14164], [14559, 15437], [15845, 22047], [22357, 24016], [24581, 25786], [27206, 29558], [30413, 31348], [32188, 34551], [34877, 37401], [37890, 38973], [39148, 40800], [41914, 48988], [50080, 50988], [52288, 57991], [59446, 64969], [65431, 67622], [67758, 74270], [74589, 76585], [76806, 77841], [80284, 84022], [84238, 85333], [85384, 90813], [91422, 93621], [93773, 98925], [100106, 104007], [104391, 111138], [112089, 116073], [117495, 118387], [118648, 122750], [123053, 128166], [128689, 130492], [130845, 132980], [134118, 137366], [137705, 140534], [141200, 147080], [147831, 149472]], "num_segments": 39}
{"id": "sakura_emotion_421_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_421_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "fear", "happy", "angry"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_421.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[122, 2202], [2233, 8940], [10023, 11785], [13897, 17200], [17900, 23417], [24821, 26423], [27154, 29463], [29535, 32087], [32508, 34053], [34562, 37398], [37678, 44498], [45101, 49839], [50262, 51336], [51911, 55528], [55834, 57330], [59223, 60880]], "num_segments": 16}
{"id": "sakura_emotion_420_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_420_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Suggest an activity to keep the positive energy flowing.", "Suggest spending some time together to cheer them up.", "Apologize and admit your mistake, if appropriate.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable."], "answer": "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_420.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[890, 5947], [6179, 11691], [12362, 13929], [14619, 16118], [17307, 21115], [21741, 22551], [22847, 23778], [24565, 29522], [30127, 32094], [32266, 36135], [37280, 41354], [41874, 42896]], "num_segments": 12}
{"id": "sakura_emotion_421_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_421_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Reacting to a sudden loud noise in an empty house.", "Hugging a loved one after a long separation.", "Turning away from spoiled food.", "Slamming a door after a disagreement."], "answer": "Reacting to a sudden loud noise in an empty house.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_421.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1220, 6866], [7739, 8951], [10134, 10974], [11481, 14739], [15304, 16442], [16480, 20239], [20469, 21898], [21978, 24119], [25661, 32832], [33162, 38134], [38609, 39632], [40294, 42871], [42942, 46978], [47230, 53072], [53521, 58550], [60104, 61078]], "num_segments": 16}
{"id": "sakura_emotion_423_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_423_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Smile and engage positively in the conversation.", "Hold their hand or offer some physical reassurance.", "Avoid discussing further and respect their aversion to the topic.", "Calmly acknowledge their frustration and suggest a solution."], "answer": "Smile and engage positively in the conversation.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_423.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[682, 1733], [1763, 4877], [5450, 6810], [6888, 7775], [7941, 15828]], "num_segments": 5}
{"id": "sakura_emotion_422_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_422_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["angry", "happy", "sad", "fear"], "answer": "sad", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_422.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1738, 2697], [2981, 7354], [7446, 8451], [8820, 11575], [11764, 14745], [15030, 19412], [20421, 24371], [24556, 31413], [31565, 32447], [32862, 33745], [34805, 35973], [36412, 42211], [42490, 43712], [43787, 45280], [45633, 50669], [51902, 58947], [59305, 60781], [61360, 63657], [64007, 64809], [64844, 67907], [68641, 69773], [70311, 71260], [72114, 74686], [74849, 75860], [76470, 79758], [80427, 84185]], "num_segments": 26}
{"id": "sakura_emotion_424_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_424_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "happy", "fear", "disgust"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_424.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[651, 1927], [1946, 2881], [2985, 8446], [9060, 13931], [13969, 15602], [15769, 16920], [17234, 18604], [18985, 24616], [25234, 27884]], "num_segments": 9}
{"id": "sakura_emotion_423_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_423_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["angry", "fear", "sad", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_423.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[713, 1818], [1964, 3966], [4058, 5856], [6092, 7434], [7492, 8327], [8566, 14981], [15239, 16164]], "num_segments": 7}
{"id": "sakura_emotion_424_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_424_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Celebrate their joy with a cheerful response.", "Suggest spending some time together to cheer them up.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Hold their hand or offer some physical reassurance."], "answer": "Celebrate their joy with a cheerful response.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_424.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[245, 5443], [5989, 6956], [8020, 12762], [12774, 13606], [13867, 16443], [16727, 18529], [19479, 23077], [23626, 25303], [26290, 27736]], "num_segments": 9}
{"id": "sakura_emotion_422_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_422_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Stay calm and provide support to ease their anxiety.", "Apologize and admit your mistake, if appropriate.", "Avoid discussing further and respect their aversion to the topic.", "Offer a comforting hug or words of reassurance."], "answer": "Offer a comforting hug or words of reassurance.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_422.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[301, 1888], [2181, 9969], [10056, 11323], [12029, 13234], [13509, 14332], [14338, 17666], [18540, 20872], [21464, 26174], [26636, 30442], [30635, 34571], [35491, 41395], [41908, 42927], [44166, 47500], [47674, 49240], [50162, 51078], [51092, 56066], [56531, 57718], [57742, 59034], [59210, 60658], [60885, 61772], [61801, 62737], [63232, 70505], [71001, 73275], [73453, 74867], [75338, 76269], [77421, 82870]], "num_segments": 26}
{"id": "sakura_emotion_425_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_425_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["angry", "happy", "fear", "sad"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_425.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1181, 3368], [3994, 4994], [5287, 9463], [10005, 11198], [12627, 17170], [17547, 18676], [19276, 21863], [22790, 24503], [24884, 25872], [26289, 27251], [27313, 29004]], "num_segments": 11}
{"id": "sakura_emotion_425_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_425_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["A person smiling after receiving good news.", "A heated argument between colleagues.", "Facing an aggressive dog on the street.", "A person crying after a breakup."], "answer": "A person smiling after receiving good news.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_425.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[346, 5844], [6132, 9717], [10293, 11608], [11737, 12973], [13193, 19213], [19234, 20913], [21621, 27089], [27134, 28996]], "num_segments": 8}
{"id": "sakura_emotion_426_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_426_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["disgust", "sad", "angry", "fear"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_426.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[413, 7272], [8525, 11240], [12004, 13915], [14582, 16311], [17065, 21783], [22085, 23245], [23875, 24771], [25514, 30879], [32650, 37794], [39450, 40818], [41504, 44631], [45505, 46407], [46575, 48028], [48092, 48940], [49020, 50521], [50778, 52359], [53650, 61536], [61787, 62762], [63611, 67715], [67875, 70389], [71876, 73017], [74337, 78029], [79597, 82412], [82682, 83718], [83766, 84946], [85668, 89432], [89980, 93320], [95355, 101506], [103374, 105824]], "num_segments": 29}
{"id": "sakura_emotion_427_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_427_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Attending a close friend's funeral.", "Winning a long-anticipated award or prize.", "Seeing an unpleasant image online.", "Throwing an object in frustration."], "answer": "Attending a close friend's funeral.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_427.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1531, 6972], [7121, 8528], [8678, 9632], [11138, 15218], [15989, 19441], [20203, 22031], [22396, 25140], [25209, 26150], [27040, 34378], [35481, 36757], [36792, 38236], [38280, 39381], [39495, 41085], [41331, 47085]], "num_segments": 14}
{"id": "sakura_emotion_426_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_426_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["Downturned mouth and teary eyes", "Flared nostrils with a tense expression", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "Eyes crinkling with an open-mouthed laugh"], "answer": "Retracted chin with one corner of the mouth twitching, as if intolerable.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_426.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[400, 4862], [5821, 6737], [7237, 14863], [15802, 16822], [17389, 20625], [20707, 22577], [22601, 24955], [25176, 27978], [29585, 35907], [35988, 37697], [37756, 39139], [39892, 43525], [43542, 49350], [50135, 51387], [51683, 55340], [55675, 56829], [58198, 62227], [62752, 65189], [65319, 68181], [69090, 73588], [73825, 77262], [77488, 78482], [79333, 82517], [82715, 87611], [88228, 89793], [90202, 93065], [95137, 101523], [102229, 103245], [103507, 105800]], "num_segments": 29}
{"id": "sakura_emotion_428_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_428_masked_100pct.wav", "question": "From the provided sentences, which one best matches the emotional state of individuals who are experiencing the same emotion as the speaker?", "choices": ["I feel like I\u2019m in danger, and I don\u2019t know what to do.", "I\u2019ve had enough of this nonsense.", "I\u2019m just so happy I could burst!", "It\u2019s hard to imagine things ever getting better."], "answer": "It\u2019s hard to imagine things ever getting better.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_428.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[201, 1012], [1399, 3491], [4564, 7447], [9087, 13767], [13968, 17488], [17684, 22713], [23214, 26464], [26604, 27929], [28732, 33994], [34006, 38045], [38345, 39185], [40017, 44201]], "num_segments": 12}
{"id": "sakura_emotion_427_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_427_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["sad", "disgust", "angry", "happy"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_427.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[247, 1062], [1962, 3468], [4735, 6070], [6094, 10004], [10308, 15927], [16071, 17315], [17321, 19807], [20024, 21793], [22936, 24530], [24565, 25794], [26080, 27142], [27346, 29502], [29984, 31829], [32687, 33904], [34527, 35534], [35880, 38645], [38824, 40228], [40525, 42551], [42635, 44657], [45104, 47401]], "num_segments": 20}
{"id": "sakura_emotion_428_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_428_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "fear", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_428.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1449, 2962], [3771, 11000], [11221, 17459], [17720, 18879], [19084, 23610], [24035, 28810], [29163, 31142], [32004, 38529], [38683, 43937]], "num_segments": 9}
{"id": "sakura_emotion_430_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_430_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["fear", "angry", "disgust", "sad"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_430.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1645, 3402], [3460, 4514], [4813, 9063], [9607, 10512], [10749, 14667], [14977, 20586], [21800, 29548], [29585, 31153], [31660, 32743]], "num_segments": 9}
{"id": "sakura_emotion_429_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_429_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "sad", "disgust", "fear"], "answer": "angry", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_429.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[233, 1582], [2185, 4879], [5614, 6665], [7596, 13601], [14722, 17506], [18889, 19710], [19914, 21436], [21569, 23252], [24107, 25164], [25315, 29406], [30201, 36245], [37298, 40311], [40913, 41786], [42559, 43374], [43560, 44563]], "num_segments": 15}
{"id": "sakura_emotion_429_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_429_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["Wide-open eyes with raised eyebrows and slightly parted lips.", "Relaxed facial muscles with a cheerful grin", "Tightly pressed lips with glaring eyes", "Downturned mouth and teary eyes"], "answer": "Tightly pressed lips with glaring eyes", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_429.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[754, 3293], [4375, 6196], [6746, 9223], [9983, 13704], [13774, 18331], [18802, 20030], [21458, 26136], [27037, 28175], [28263, 35085], [35206, 41515], [42311, 44631]], "num_segments": 11}
{"id": "sakura_emotion_430_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_430_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Avoid discussing further and respect their aversion to the topic.", "Listen empathetically and let them express their feelings.", "Smile and engage positively in the conversation.", "Encourage them to take deep breaths to relax."], "answer": "Encourage them to take deep breaths to relax.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_430.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[11, 927], [2061, 3531], [3546, 4607], [5147, 6104], [6504, 8565], [8594, 9993], [10506, 11820], [12701, 15398], [16244, 17297], [18088, 18946], [19095, 20084], [21100, 22683], [22814, 29563], [29717, 32393]], "num_segments": 14}
{"id": "sakura_emotion_432_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_432_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Suggest spending some time together to cheer them up.", "Stay calm and provide support to ease their anxiety.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Express genuine excitement for their good news or achievement."], "answer": "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_432.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[88, 2158], [3432, 6221], [6653, 9869], [10435, 13768], [13907, 16051], [16500, 19706], [20084, 25040], [25580, 31548], [31872, 34346], [34622, 38527], [38653, 42404], [42979, 43933], [44135, 46558], [46679, 47708], [48013, 48987], [49431, 51018]], "num_segments": 16}
{"id": "sakura_emotion_433_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_433_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Offer a comforting hug or words of reassurance.", "Express understanding calmly and suggest leaving the unpleasant environment.", "Suggest an activity to keep the positive energy flowing.", "Calmly acknowledge their frustration and suggest a solution."], "answer": "Express understanding calmly and suggest leaving the unpleasant environment.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_433.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[346, 1201], [1369, 2971], [3569, 5871], [7209, 13046], [13053, 14087], [14685, 15553], [15796, 22407], [22458, 23897], [24085, 25115], [26365, 32953]], "num_segments": 10}
{"id": "sakura_emotion_435_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_435_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["fear", "angry", "happy", "sad"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_435.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[803, 3566], [4029, 11545], [12212, 16860], [18271, 22558], [22802, 23635], [23752, 28830], [29050, 29910]], "num_segments": 7}
{"id": "sakura_emotion_432_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_432_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["sad", "angry", "disgust", "fear"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_432.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[456, 2561], [2855, 4436], [5340, 6906], [8283, 10291], [10773, 11677], [12398, 16405], [17751, 25176], [25622, 26694], [27037, 28277], [28522, 29413], [29734, 33846], [34004, 36361], [36518, 39169], [39327, 44788], [45920, 46881], [47825, 49539], [50324, 52645]], "num_segments": 17}
{"id": "sakura_emotion_433_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_433_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["angry", "sad", "happy", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_433.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[413, 4010], [4208, 6359], [6360, 9450], [9755, 11560], [12023, 13571], [13683, 16044], [16916, 17962], [18129, 25635], [26012, 27187], [28401, 32697], [33049, 34766]], "num_segments": 11}
{"id": "sakura_emotion_436_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_436_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "happy", "angry", "disgust"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_436.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[594, 2399], [2597, 7202], [7426, 11752], [12216, 13436], [13616, 17259]], "num_segments": 5}
{"id": "sakura_emotion_436_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_436_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Watching a horror movie alone in the dark.", "Saying goodbye at an airport.", "Celebrating a birthday with friends and family.", "A parent scolding their child for misbehavior."], "answer": "A parent scolding their child for misbehavior.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_436.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[488, 2661], [3099, 5261], [6097, 7277], [7360, 15057], [15620, 17117]], "num_segments": 5}
{"id": "sakura_emotion_434_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_434_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["This is the best day ever, I feel on top of the world!", "I don\u2019t know how to move on from this loss.", "That\u2019s just revolting, I can\u2019t believe it.", "This is terrifying, I can\u2019t stop thinking about it."], "answer": "That\u2019s just revolting, I can\u2019t believe it.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_434.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[422, 1476], [2233, 3144], [3514, 5603], [7536, 9054], [10096, 13095], [14513, 15365], [17287, 19808], [20047, 21562], [21837, 26927], [27747, 29395], [29774, 32958], [33378, 41157], [41192, 42019], [42410, 47141], [48124, 49057], [50308, 52760], [53504, 56743], [59092, 60013], [60367, 67730], [68089, 70441], [70580, 76917], [77230, 78893]], "num_segments": 22}
{"id": "sakura_emotion_434_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_434_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "angry", "fear", "sad"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_434.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2208, 4627], [5856, 11944], [12291, 13324], [13599, 14403], [14529, 15894], [16527, 17603], [18457, 19484], [19735, 21970], [22818, 23743], [24246, 26179], [26238, 31299], [31341, 32626], [33489, 34745], [36082, 38538], [38678, 39805], [40383, 41535], [42023, 43696], [43854, 45372], [45573, 46558], [46673, 51826], [52067, 54276], [56054, 60450], [61704, 62885], [64503, 65685], [65775, 68253], [69651, 71713], [73093, 75811], [76055, 77323], [77668, 78549]], "num_segments": 29}
{"id": "sakura_emotion_431_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_431_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "sad", "fear", "disgust"], "answer": "fear", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_431.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[189, 1331], [1688, 4918], [6428, 8524], [10065, 12166], [13797, 17176], [17242, 20663], [22098, 23048], [26108, 30234], [31147, 32781], [33091, 34146], [34699, 38794], [39331, 44229], [44813, 52722], [54003, 56957], [57538, 62915], [63984, 65416], [66373, 71994], [72012, 74291], [74308, 77687], [78342, 84039], [84835, 89201], [89818, 92320], [92778, 97918], [99714, 106099], [106763, 108891], [109140, 114840], [115764, 118096], [118583, 122240], [123226, 125399], [125584, 132892], [133870, 139041], [139152, 140399], [140402, 141750], [142074, 145626], [146160, 150549]], "num_segments": 35}
{"id": "sakura_emotion_435_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_435_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Saying goodbye at an airport.", "A person yelling after being cut off in traffic.", "Winning a long-anticipated award or prize.", "Watching a horror movie alone in the dark."], "answer": "A person yelling after being cut off in traffic.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_435.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[218, 1031], [1310, 2808], [3362, 4693], [5913, 6906], [7980, 10100], [10113, 11785], [11863, 15364], [15613, 19484], [20436, 26945], [27539, 29580]], "num_segments": 10}
{"id": "sakura_emotion_437_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_437_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["fear", "angry", "disgust", "sad"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_437.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[439, 1890], [2870, 6756], [7219, 8630], [8635, 9708], [9797, 10638], [11921, 16222], [17151, 18904], [19193, 20172], [20239, 21198], [21406, 22979], [23476, 24386], [24546, 31767], [32476, 33292], [33308, 34170]], "num_segments": 14}
{"id": "sakura_emotion_437_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_437_masked_100pct.wav", "question": "What facial expression best represents the emotion in the clip?", "choices": ["Furrowed brows with slightly open mouth, as if about to shout.", "A drooping gaze with a slack jaw", "Wide-open eyes with raised eyebrows and slightly parted lips.", "A wrinkled nose and raised upper lip"], "answer": "A wrinkled nose and raised upper lip", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_437.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[484, 2733], [2871, 4090], [5117, 6737], [6980, 12300], [12680, 14935], [15003, 16797], [16812, 17640], [17799, 24670], [26037, 33233], [33651, 34694]], "num_segments": 10}
{"id": "sakura_emotion_438_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_438_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["happy", "angry", "disgust", "sad"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_438.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[482, 1341], [1828, 7072], [7191, 8307], [8382, 9906], [10484, 16132], [16376, 24222], [24395, 25810], [27072, 27918], [29225, 30846]], "num_segments": 9}
{"id": "sakura_emotion_431_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_431_masked_100pct.wav", "question": "Which situation best corresponds to the emotion conveyed in the speech?", "choices": ["A parent scolding their child for misbehavior.", "Laughing at a funny joke in a conversation.", "Walking alone in a dark alley at night.", "Attending a close friend's funeral."], "answer": "Walking alone in a dark alley at night.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_431.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2636, 3447], [3607, 7617], [8036, 13755], [14264, 15523], [17681, 22822], [22897, 25075], [25699, 28036], [29804, 32614], [32872, 34630], [35991, 39029], [41270, 42862], [44263, 49749], [50878, 57504], [59292, 63534], [63592, 71135], [71393, 72628], [72910, 78855], [78865, 80958], [81234, 85498], [87489, 90269], [91706, 97992], [98443, 105876], [106256, 107462], [108630, 109794], [110195, 111723], [111870, 113820], [113958, 115061], [115069, 116988], [118421, 121299], [121710, 128328], [128347, 129832], [130893, 134567], [134901, 140985], [142160, 146237], [147825, 150768]], "num_segments": 35}
{"id": "sakura_emotion_438_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_438_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["I can\u2019t breathe, I\u2019m just so afraid right now.", "I can\u2019t stop smiling, everything feels so right.", "I just can\u2019t stop thinking about all those bad memories.", "That\u2019s just revolting, I can\u2019t believe it."], "answer": "I can\u2019t stop smiling, everything feels so right.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_438.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[522, 1699], [2144, 4904], [5751, 7020], [7154, 9913], [10122, 12202], [13368, 17826], [18603, 20257], [20435, 22256], [22328, 23754], [23852, 26229], [27502, 30874]], "num_segments": 11}
{"id": "sakura_emotion_439_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_439_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["fear", "disgust", "angry", "sad"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_439.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[952, 7393], [7439, 8793], [9999, 12479], [12715, 15619], [15851, 17079], [17481, 18441], [19723, 20671], [20874, 22119], [22157, 24572], [24779, 29068], [29609, 30571], [30666, 32404], [32671, 33821], [33941, 35483], [35666, 41244], [42217, 49062], [49304, 56516], [56793, 58348]], "num_segments": 18}
{"id": "sakura_emotion_439_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_439_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Slamming a door after a disagreement.", "Rejecting a tasteless meal with a grimace.", "Preparing for a high-stakes exam with anxiety.", "Laughing at a funny joke in a conversation."], "answer": "Preparing for a high-stakes exam with anxiety.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_439.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[487, 2051], [2292, 7547], [8174, 12339], [12516, 17051], [18593, 21323], [21531, 24806], [25173, 26055], [26379, 34277], [35409, 36626], [37479, 40150], [40168, 45938], [46425, 53440], [53857, 56710]], "num_segments": 13}
{"id": "sakura_emotion_440_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_440_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "sad", "happy", "angry"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_440.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[293, 2659], [2728, 4314], [5059, 7064], [7574, 8624], [9614, 12437], [14410, 17372], [17522, 18988], [19028, 19994], [20002, 22407], [22435, 24871], [25283, 27254], [28099, 31901], [32354, 33899]], "num_segments": 13}
{"id": "sakura_emotion_441_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_441_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "sad", "fear", "happy"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_441.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[431, 2027], [2111, 4989], [5050, 6129], [6775, 10840], [11857, 14306], [14914, 16007], [16463, 17527], [17654, 19794], [20039, 23460], [24634, 26960], [28523, 32685], [33217, 38509], [39792, 45818], [45917, 46830], [47375, 51125]], "num_segments": 15}
{"id": "sakura_emotion_442_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_442_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "sad", "angry", "happy"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_442.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[391, 1627], [1864, 3144], [3416, 5358], [5613, 6555], [6570, 13583], [13935, 15407], [15813, 18662], [19114, 21879], [22266, 23634], [23847, 28321], [29122, 32398]], "num_segments": 11}
{"id": "sakura_emotion_440_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_440_masked_100pct.wav", "question": "Which sentence best reflects the same emotion identified in the audio?", "choices": ["I feel like I\u2019m in danger, and I don\u2019t know what to do.", "This is the best day ever, I feel on top of the world!", "I\u2019m feeling so down, like nothing can lift my spirits.", "This situation is really starting to piss me off!"], "answer": "I\u2019m feeling so down, like nothing can lift my spirits.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_440.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1064, 2223], [2248, 3415], [3435, 4497], [4891, 7565], [7715, 9694], [9796, 11293], [12150, 14401], [16076, 17034], [18939, 22649], [22945, 23814], [23903, 31177], [31311, 33215]], "num_segments": 12}
{"id": "sakura_emotion_442_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_442_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Saying goodbye at an airport.", "Rejecting a tasteless meal with a grimace.", "Preparing for a high-stakes exam with anxiety.", "Throwing an object in frustration."], "answer": "Throwing an object in frustration.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_442.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[585, 1411], [1817, 3115], [3345, 6437], [7310, 8424], [9112, 11914], [13178, 19410], [20152, 23421], [23828, 30738], [30887, 32181]], "num_segments": 9}
{"id": "sakura_emotion_441_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_441_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Encourage them to take deep breaths to relax.", "Provide emotional support and avoid dismissing their sadness.", "Give them space to cool off before engaging further.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable."], "answer": "Provide emotional support and avoid dismissing their sadness.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_441.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[889, 2084], [2790, 5822], [6062, 6875], [7100, 12848], [13281, 14286], [15515, 20569], [20855, 21892], [21978, 25932], [26642, 33711], [33711, 37307], [39143, 45101], [45956, 47005], [47044, 49554]], "num_segments": 13}
{"id": "sakura_emotion_445_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_445_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["happy", "disgust", "angry", "sad"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_445.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[612, 4981]], "num_segments": 1}
{"id": "sakura_emotion_444_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_444_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "disgust", "happy", "angry"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_444.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1489, 2610], [3020, 4021], [4644, 9028], [9688, 11799], [11916, 13352], [13372, 20688], [20895, 25160], [25735, 28907], [29728, 32960], [33561, 38377], [38638, 40102], [40117, 46261], [47059, 49217], [49325, 50334], [51246, 52125], [52189, 57029], [57052, 57877]], "num_segments": 17}
{"id": "sakura_emotion_443_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_443_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["angry", "happy", "sad", "disgust"], "answer": "angry", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_443.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1396, 5976], [7470, 9012], [9646, 14920], [15445, 17038], [18147, 19307], [20275, 24556], [25994, 30250], [30283, 31265], [33161, 35456], [35810, 39083], [39783, 41448], [42162, 48019], [48801, 49944], [49972, 50822], [51195, 58005], [58809, 60421], [61078, 68483], [68694, 70229]], "num_segments": 18}
{"id": "sakura_emotion_445_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_445_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Suggest spending some time together to cheer them up.", "Apologize and admit your mistake, if appropriate.", "Express understanding calmly and suggest leaving the unpleasant environment.", "Suggest an activity to keep the positive energy flowing."], "answer": "Apologize and admit your mistake, if appropriate.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_445.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[282, 1185], [1538, 3112], [3447, 5687]], "num_segments": 3}
{"id": "sakura_emotion_444_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_444_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Encourage them to take deep breaths to relax.", "Offer congratulations or compliments to share their happiness.", "Express understanding calmly and suggest leaving the unpleasant environment.", "Listen attentively without interrupting to let them vent."], "answer": "Express understanding calmly and suggest leaving the unpleasant environment.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_444.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[190, 3696], [3896, 4737], [5310, 6170], [6990, 10900], [12225, 16235], [17672, 21066], [21355, 26681], [28546, 29861], [29863, 31520], [32368, 33170], [33507, 34677], [35634, 38716], [39814, 41337], [42233, 48339], [49107, 52132], [52678, 55101], [55327, 56681], [56698, 57998]], "num_segments": 18}
{"id": "sakura_emotion_446_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_446_masked_100pct.wav", "question": "Among the following facial expressions, which one do you think best corresponds to the emotion conveyed in the audio clip?", "choices": ["A wrinkled nose and raised upper lip", "Frozen facial expression with trembling lips and quickened breathing.", "Raised eyebrows with a scowl", "A broad smile with sparkling eyes"], "answer": "Raised eyebrows with a scowl", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_446.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[538, 2285], [2704, 3810], [4063, 6334], [6947, 13144]], "num_segments": 4}
{"id": "sakura_emotion_443_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_443_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["This situation is really starting to piss me off!", "That\u2019s just revolting, I can\u2019t believe it.", "I feel so grateful and full of joy right now.", "I feel like I\u2019m in danger, and I don\u2019t know what to do."], "answer": "This situation is really starting to piss me off!", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_443.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[828, 1729], [1794, 3215], [3224, 9054], [10705, 12134], [12623, 14460], [14478, 22011], [22706, 23694], [24860, 30419], [30717, 32607], [34208, 37326], [39820, 41081], [42038, 45378], [46070, 46913], [47059, 51395], [52277, 53850], [54321, 58394], [59258, 64790], [65440, 69687]], "num_segments": 18}
{"id": "sakura_emotion_446_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_446_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["disgust", "sad", "happy", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_446.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[846, 2731], [3260, 4634], [5011, 6616], [6766, 13840]], "num_segments": 4}
{"id": "sakura_emotion_447_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_447_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "sad", "angry", "disgust"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_447.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1107, 2550], [2774, 5305], [5586, 8420], [8426, 9233], [9773, 11708], [12232, 13657], [13730, 21335], [21370, 22172], [22827, 24834], [24907, 26508], [26606, 29431], [30404, 32278], [32362, 34970], [35294, 40700]], "num_segments": 14}
{"id": "sakura_emotion_447_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_447_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Celebrate their joy with a cheerful response.", "Stay calm and provide support to ease their anxiety.", "Avoid discussing further and respect their aversion to the topic.", "Listen attentively without interrupting to let them vent."], "answer": "Stay calm and provide support to ease their anxiety.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_447.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1451, 6959], [7885, 11875], [13172, 17016], [17301, 21563], [21715, 24779], [24806, 26069], [26164, 28651], [29956, 30993], [31073, 32585], [32882, 33988], [34022, 37203], [37355, 39896]], "num_segments": 12}
{"id": "sakura_emotion_448_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_448_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["I can\u2019t stop smiling, everything feels so right.", "I don\u2019t know how to move on from this loss.", "I can\u2019t believe this is happening, I\u2019m so furious!", "I feel like I\u2019m in danger, and I don\u2019t know what to do."], "answer": "I feel like I\u2019m in danger, and I don\u2019t know what to do.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_448.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[239, 1447], [1638, 3358], [3690, 8602], [9650, 11792], [12239, 19317], [19618, 26867], [26886, 28357], [30319, 34632], [35849, 38211], [38549, 39708], [40153, 48138], [48848, 49699], [50474, 51387], [52451, 58779], [59693, 64532], [65458, 67398], [67478, 73987], [74666, 76152]], "num_segments": 18}
{"id": "sakura_emotion_448_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_448_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "happy", "sad", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_448.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[70, 1545], [2056, 3065], [3370, 4235], [5981, 11204], [12078, 14741], [14861, 16181], [16588, 20462], [21301, 24725], [25396, 27160], [27178, 30183], [30183, 31126], [31308, 33018], [33223, 39219], [39477, 40634], [41009, 42446], [43220, 45099], [45605, 46717], [47381, 52169], [53455, 56824], [57554, 59169], [59401, 63685], [65297, 71072], [71422, 72751], [72810, 74606], [74763, 75628]], "num_segments": 25}
{"id": "sakura_emotion_449_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_449_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "angry", "fear", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_449.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[576, 1585], [2355, 3301], [3315, 10397], [11514, 12464], [12594, 13599], [13642, 21211], [22950, 24924], [25211, 26313], [26952, 27796], [28802, 31493], [33418, 38344], [38950, 44044], [44123, 46592], [46712, 48000], [49015, 50068], [50245, 51131], [51685, 53988]], "num_segments": 17}
{"id": "sakura_emotion_449_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_449_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Suggest spending some time together to cheer them up.", "Calmly acknowledge their frustration and suggest a solution.", "Encourage them to take deep breaths to relax.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable."], "answer": "Suggest spending some time together to cheer them up.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_449.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[159, 1030], [1263, 2711], [2720, 3560], [4167, 6907], [9033, 12122], [12483, 15511], [16398, 17533], [18018, 19213], [19527, 21029], [21482, 23812], [24088, 27151], [27186, 29002], [30092, 31005], [31063, 32008], [32094, 35452], [35807, 37756], [38418, 40322], [40406, 41284], [41991, 42836], [43107, 45873], [46698, 48101], [48160, 51017], [51357, 53931]], "num_segments": 23}
{"id": "sakura_emotion_453_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_453_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["sad", "angry", "happy", "disgust"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_453.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[22, 1031], [1243, 4144], [5079, 6661], [7311, 14698], [14995, 17112], [17272, 19869], [20426, 21356], [21385, 22524], [23805, 29099], [29226, 30133], [30147, 32313], [32916, 37222], [37853, 39161], [39372, 43378], [43794, 49966], [50392, 53105], [53436, 59343], [60506, 61729], [62251, 63469], [64578, 68297], [68923, 73840]], "num_segments": 21}
{"id": "sakura_emotion_451_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_451_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["angry", "disgust", "happy", "fear"], "answer": "angry", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_451.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2182, 8487], [8531, 10407], [11502, 18367], [18870, 20072], [20648, 21958], [23689, 24809], [24825, 32273], [32352, 40185], [40497, 42059], [43098, 46822], [48427, 50205], [50822, 57647], [58570, 62269], [62296, 63362], [63709, 64649]], "num_segments": 15}
{"id": "sakura_emotion_453_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_453_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Smile and engage positively in the conversation.", "Provide emotional support and avoid dismissing their sadness.", "Calmly acknowledge their frustration and suggest a solution.", "Hold their hand or offer some physical reassurance."], "answer": "Calmly acknowledge their frustration and suggest a solution.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_453.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[711, 2402], [2850, 9632], [11189, 13802], [14374, 16858], [18373, 19317], [20152, 22120], [23452, 24615], [25012, 30327], [30512, 31367], [31508, 32903], [33310, 35142], [35237, 37145], [37191, 38143], [39535, 42117], [43131, 44193], [45962, 46812], [47643, 51346], [51465, 55385], [55708, 63356], [63618, 64853], [65208, 72328]], "num_segments": 21}
{"id": "sakura_emotion_451_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_451_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Saying goodbye at an airport.", "Hearing a shocking and offensive statement.", "Walking alone in a dark alley at night.", "A person yelling after being cut off in traffic."], "answer": "A person yelling after being cut off in traffic.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_451.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[210, 1517], [2306, 5225], [5604, 6641], [8772, 14280], [15228, 16557], [17822, 19596], [19682, 20841], [21295, 22099], [22116, 25267], [25613, 27887], [27989, 30655], [31749, 32662], [33795, 34801], [34813, 39361], [39412, 40378], [40683, 45084], [45659, 46472], [47055, 53117], [53144, 54036], [54455, 57544], [58864, 65852]], "num_segments": 21}
{"id": "sakura_emotion_450_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_450_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "sad", "disgust", "angry"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_450.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2911, 9588], [10959, 16740], [17076, 18016], [18980, 23072], [23123, 28650], [29040, 30155], [31354, 35139], [36231, 39705], [39930, 44161], [45584, 46514], [46685, 49665], [51450, 52430], [53881, 59541], [60135, 61761], [63230, 67016], [67423, 68402], [68706, 71312], [72873, 79179], [79660, 87434], [87731, 93914], [95740, 96884], [98669, 101198], [102120, 106033], [107883, 110495], [111888, 112789], [112997, 113887], [113926, 115725], [116128, 122429], [122445, 123858], [124054, 127089], [128150, 135294], [135311, 138921], [140455, 141512], [142393, 144270], [144438, 146628], [147962, 148951], [148996, 150431], [150836, 153611], [153902, 157523], [157766, 158976], [162153, 163283], [163876, 169081], [170690, 177209], [178690, 179578], [180134, 181241]], "num_segments": 45}
{"id": "sakura_emotion_456_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_456_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "disgust", "fear", "sad"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_456.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[851, 2089], [2340, 4275], [5128, 6006], [6167, 8815], [9212, 12360], [12681, 14775], [15672, 17547], [17982, 20983], [21472, 22506], [22719, 23853]], "num_segments": 10}
{"id": "sakura_emotion_452_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_452_masked_100pct.wav", "question": "What scenario best aligns with the speaker's emotion identified in this speech?", "choices": ["Facing an aggressive dog on the street.", "Throwing an object in frustration.", "Winning a long-anticipated award or prize.", "Watching a touching but sorrowful movie scene."], "answer": "Watching a touching but sorrowful movie scene.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_452.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1322, 2228], [3085, 5643], [7166, 10604], [10733, 12034], [12083, 18974], [20347, 21284], [22044, 23593], [23973, 25178], [25290, 29046], [30033, 36078], [37207, 38698], [38729, 40293], [40765, 47325], [48505, 50926], [51523, 52569], [53745, 58104], [58161, 63527], [64611, 66603], [67480, 71588], [71944, 75773], [75955, 76762], [77108, 80343], [81358, 82781]], "num_segments": 23}
{"id": "sakura_emotion_454_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_454_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "fear", "angry", "happy"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_454.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[412, 2825], [3144, 7844], [8058, 11349], [12179, 17274], [18272, 24891], [25782, 26896], [28066, 35364], [35531, 37181], [37394, 42875], [43761, 45953], [46618, 54229], [54887, 57441], [57582, 59994], [60708, 61975], [63078, 67136]], "num_segments": 15}
{"id": "sakura_emotion_452_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_452_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["fear", "sad", "angry", "happy"], "answer": "sad", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_452.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[696, 2859], [3192, 6817], [7432, 12302], [12722, 13857], [14647, 15463], [16738, 19200], [19928, 20799], [20905, 22691], [23189, 24878], [25863, 30103], [30244, 31662], [32287, 38626], [39107, 40857], [40999, 42837], [43213, 45509], [46020, 47091], [48382, 49434], [49660, 52097], [52722, 54285], [54627, 56326], [57284, 58382], [58747, 60730], [62220, 68440], [68790, 72329], [74262, 75293], [76783, 80162], [81777, 83424]], "num_segments": 27}
{"id": "sakura_emotion_456_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_456_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Give them space to cool off before engaging further.", "Offer reassurance and remind them they are safe.", "Smile and engage positively in the conversation."], "answer": "Smile and engage positively in the conversation.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_456.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[949, 2449], [2662, 3612], [4051, 5131], [5897, 9090], [9280, 10131], [10249, 11847], [12810, 14158], [14558, 17853], [17903, 19589], [19815, 21679], [22353, 23648]], "num_segments": 11}
{"id": "sakura_emotion_454_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_454_masked_100pct.wav", "question": "Which situation best fits the emotion expressed in the speech?", "choices": ["Throwing an object in frustration.", "Hugging a loved one after a long separation.", "Facing an aggressive dog on the street.", "Watching a touching but sorrowful movie scene."], "answer": "Facing an aggressive dog on the street.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_454.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[190, 3619], [4797, 10799], [11212, 14951], [16207, 17997], [18936, 20638], [22841, 25274], [26851, 28306], [29308, 33578], [34827, 37841], [38272, 39205], [39402, 45587], [46326, 48068], [48142, 53536], [53818, 54630], [55072, 56262], [56325, 57259], [58594, 66470]], "num_segments": 17}
{"id": "sakura_emotion_455_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_455_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["A heated argument between colleagues.", "Saying goodbye at an airport.", "Hugging a loved one after a long separation.", "Facing an aggressive dog on the street."], "answer": "Facing an aggressive dog on the street.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_455.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1826, 7831], [8332, 11920], [13509, 16838], [18236, 22791], [23350, 24661], [24851, 25999], [27847, 33637], [35722, 38195], [38895, 42750], [43743, 49977], [50363, 52842], [54382, 55451], [55653, 57936], [58894, 63089], [63102, 64076], [65145, 66155], [67393, 68316], [68506, 69823], [70567, 72613], [72934, 74749]], "num_segments": 20}
{"id": "sakura_emotion_450_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_450_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Express understanding calmly and suggest leaving the unpleasant environment.", "Suggest spending some time together to cheer them up.", "Listen attentively without interrupting to let them vent.", "Suggest an activity to keep the positive energy flowing."], "answer": "Express understanding calmly and suggest leaving the unpleasant environment.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_450.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1971, 4751], [5410, 6805], [6994, 9384], [9990, 11107], [11689, 12819], [13622, 18980], [20148, 22380], [22604, 24451], [24812, 26752], [28799, 33116], [34443, 36270], [37172, 44944], [46068, 47257], [47547, 49023], [49147, 51173], [51446, 55352], [56625, 57794], [57940, 64554], [64700, 66350], [67180, 68211], [69397, 75122], [75433, 76495], [76755, 83540], [85209, 86605], [88022, 91487], [93943, 96338], [96403, 97790], [97972, 100294], [100684, 102886], [105052, 105943], [107162, 114510], [114728, 118422], [118576, 119460], [120269, 124846], [125445, 129661], [129793, 131431], [131560, 132402], [133088, 134306], [134597, 135683], [136013, 143819], [144312, 146322], [148007, 150070], [150197, 151691], [153095, 156288], [157014, 160053], [160175, 163399], [164641, 166648], [166909, 167741], [167747, 171329], [171948, 173490], [174022, 179037], [180032, 181353]], "num_segments": 52}
{"id": "sakura_emotion_455_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_455_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["happy", "fear", "sad", "disgust"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_455.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1966, 3014], [3985, 4957], [5816, 6678], [6747, 9593], [9943, 15011], [15175, 18731], [18756, 24462], [24854, 25705], [26729, 28455], [29518, 31451], [32077, 36286], [36454, 38357], [38463, 39341], [40270, 41087], [41729, 42701], [42789, 44484], [45170, 49316], [50224, 53169], [53409, 55317], [56234, 58334], [58461, 64169], [65735, 67825], [68048, 73044]], "num_segments": 23}
{"id": "sakura_emotion_457_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_457_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["disgust", "happy", "sad", "angry"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_457.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[859, 6634], [7187, 9028], [9427, 12737], [12907, 13866], [14002, 15044], [15184, 16550], [16555, 17829], [18496, 19632], [19750, 24790], [25245, 26586], [28133, 29059], [30321, 34537], [35056, 39701]], "num_segments": 13}
{"id": "sakura_emotion_457_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_457_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Offer congratulations or compliments to share their happiness.", "Offer a comforting hug or words of reassurance.", "Apologize and admit your mistake, if appropriate.", "Avoid discussing further and respect their aversion to the topic."], "answer": "Offer congratulations or compliments to share their happiness.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_457.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[876, 2728], [3878, 8972], [9250, 13006], [13517, 18473], [18764, 20458], [20950, 23443], [24808, 29571], [30619, 34827], [36005, 39330]], "num_segments": 9}
{"id": "sakura_emotion_458_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_458_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Downturned mouth and teary eyes", "Squinted eyes and a pinched nose", "Furrowed brows with slightly open mouth, as if about to shout.", "A broad smile with sparkling eyes"], "answer": "A broad smile with sparkling eyes", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_458.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[267, 1507], [3040, 5100], [5886, 9032], [10055, 11078], [11089, 12664], [13124, 16195], [17704, 23228], [23864, 29816], [30749, 34180], [34290, 35753], [36075, 37332], [38227, 42259]], "num_segments": 12}
{"id": "sakura_emotion_458_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_458_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "happy", "disgust", "sad"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_458.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[267, 7714], [7977, 13433], [14098, 15003], [15364, 16574], [16827, 18479], [18834, 20488], [21962, 22860], [23330, 25900], [26352, 27303], [27421, 29551], [31051, 36279], [36337, 37622], [38293, 41944]], "num_segments": 13}
{"id": "sakura_emotion_459_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_459_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "disgust", "fear", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_459.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[456, 3210], [3779, 4839], [5944, 8419], [10365, 15055], [15936, 20633], [21073, 22452], [23218, 27038], [27242, 28362], [28666, 34685], [35617, 39804], [41129, 42827], [43751, 44892], [45980, 50872], [50876, 52260], [53067, 54522], [56552, 57457], [57680, 59228], [59814, 67471], [68122, 69247], [69776, 71336], [73250, 76567], [77141, 80117]], "num_segments": 22}
{"id": "sakura_emotion_460_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_460_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["happy", "disgust", "fear", "sad"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_460.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[250, 3016], [4051, 6323], [6877, 14189], [15325, 16585], [16766, 17810], [18733, 22284], [23327, 28394], [28724, 31698], [32605, 33918], [34237, 36733]], "num_segments": 10}
{"id": "sakura_emotion_460_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_460_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Express genuine excitement for their good news or achievement.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Offer reassurance and remind them they are safe.", "Calmly acknowledge their frustration and suggest a solution."], "answer": "Express genuine excitement for their good news or achievement.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_460.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[170, 1023], [1278, 3460], [4261, 6314], [6397, 7232], [7351, 12880], [13641, 14947], [15310, 19226], [20562, 27248], [27603, 29739], [30114, 33824], [33985, 36115]], "num_segments": 11}
{"id": "sakura_emotion_459_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_459_masked_100pct.wav", "question": "Based on the emotion identified in the audio, Which social interaction would be most appropriate as a response ?", "choices": ["Reassure them and offer a way to move past the uncomfortable    situation.", "Hold their hand or offer some physical reassurance.", "Apologize and admit your mistake, if appropriate.", "Listen empathetically and let them express their feelings."], "answer": "Listen empathetically and let them express their feelings.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_459.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[47, 1032], [2397, 4275], [5212, 11140], [11630, 14103], [15323, 18168], [18792, 19606], [21265, 28185], [28582, 29609], [30020, 35925], [36151, 42773], [43364, 44264], [44565, 50729], [50793, 52581], [52964, 55938], [56080, 57573], [59525, 64301], [64772, 66389], [67147, 69168], [70054, 71106], [71761, 78078], [78752, 79730]], "num_segments": 21}
{"id": "sakura_emotion_461_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_461_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["angry", "disgust", "happy", "sad"], "answer": "happy", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_461.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[147, 2287], [2370, 3205], [4037, 6448], [7618, 9172], [9455, 10699], [10745, 13137], [14676, 16343], [16671, 17481], [18082, 22563], [23608, 27214], [27928, 28933], [30330, 31506], [31843, 32742], [32882, 40608], [41327, 46957], [48696, 50843], [50961, 53276], [53446, 54772], [54803, 58992], [60839, 61922], [62242, 68209]], "num_segments": 21}
{"id": "sakura_emotion_462_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_462_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["fear", "sad", "angry", "happy"], "answer": "fear", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_462.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1102, 2532], [3098, 5232], [6052, 9299], [9459, 11565], [12220, 13199], [13306, 17670], [18671, 19770], [20195, 21578], [22037, 25815], [27768, 28841], [29487, 30797], [31651, 38277], [38629, 43005], [43889, 50460], [51220, 53511], [54877, 56936], [57929, 59364], [61532, 64840], [65629, 67082], [67973, 75892], [77156, 84272], [84606, 92145]], "num_segments": 22}
{"id": "sakura_emotion_463_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_463_masked_100pct.wav", "question": "Based on the emotion identified in the audio, which of these facial expressions is most likely to match the speaker's emotional state?", "choices": ["Eyes gazing downward with trembling lips", "Relaxed facial muscles with a cheerful grin", "Raised eyebrows with a scowl", "Averted gaze with a grimacing mouth"], "answer": "Averted gaze with a grimacing mouth", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_463.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[486, 5621], [6487, 7340], [7560, 8445], [8465, 9275], [9648, 14211], [15204, 20653], [21860, 22783], [23582, 24857], [25586, 30412], [30617, 35723]], "num_segments": 10}
{"id": "sakura_emotion_461_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_461_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["I feel so empty, like nothing matters anymore.", "I\u2019ve had enough of this nonsense.", "I feel like I\u2019m in danger, and I don\u2019t know what to do.", "I can\u2019t stop smiling, everything feels so right."], "answer": "I can\u2019t stop smiling, everything feels so right.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_461.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[356, 1875], [1917, 4029], [4394, 6050], [6219, 12854], [14007, 20950], [21865, 29002], [29111, 29926], [30369, 31407], [31614, 33592], [33667, 36759], [36931, 41002], [41925, 42872], [43084, 48029], [48458, 50240], [50487, 53857], [54736, 58529], [59974, 65215], [65248, 66461], [66807, 68696]], "num_segments": 19}
{"id": "sakura_emotion_462_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_462_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["A drooping gaze with a slack jaw", "Clenched teeth with side facial muscles showing tension.", "Averted gaze with a grimacing mouth", "Frozen facial expression with trembling lips and quickened breathing."], "answer": "Frozen facial expression with trembling lips and quickened breathing.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_462.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[222, 1581], [2116, 4226], [6315, 12726], [12762, 13607], [13818, 16211], [16658, 20465], [21199, 23861], [24358, 25870], [26038, 29130], [29305, 33893], [33894, 41444], [43026, 44637], [45210, 46115], [47355, 55331], [56145, 57893], [59651, 65461], [66325, 69773], [70911, 74392], [74755, 77744], [77872, 85766], [85950, 92378]], "num_segments": 21}
{"id": "sakura_emotion_463_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_463_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["disgust", "angry", "happy", "fear"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_463.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1324, 3609], [3623, 4489], [4636, 5539], [6370, 8634], [8976, 12191], [12318, 13271], [13544, 16731], [16876, 18005], [18067, 25044], [25276, 26767], [27569, 28562], [28695, 33454], [34493, 37151]], "num_segments": 13}
{"id": "sakura_emotion_465_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_465_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Winning a long-anticipated award or prize.", "Throwing an object in frustration.", "Turning away from spoiled food.", "Walking alone in a dark alley at night."], "answer": "Winning a long-anticipated award or prize.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_465.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[493, 6652], [7241, 8917], [9117, 13387], [13823, 15241], [15361, 16439], [17237, 20186], [20526, 22020], [22021, 23599], [23864, 24739]], "num_segments": 9}
{"id": "sakura_emotion_465_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_465_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["angry", "happy", "disgust", "sad"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_465.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[151, 2110], [2630, 3931], [4100, 11214], [11278, 14131], [14605, 16614], [17491, 24810]], "num_segments": 6}
{"id": "sakura_emotion_464_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_464_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "disgust", "angry", "sad"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_464.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1640, 2539], [2788, 6237], [6877, 13649], [14683, 17473], [18041, 19304], [19380, 20260], [20756, 21563], [22229, 29140], [30060, 34426], [34659, 36079], [36560, 38838], [39035, 40756], [41938, 44667], [44746, 51676], [53145, 54238], [54265, 59056], [59275, 61414], [61534, 63675], [64120, 65870], [66088, 69272], [69549, 71756]], "num_segments": 21}
{"id": "sakura_emotion_464_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_464_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Eyes crinkling with an open-mouthed laugh", "Squinted eyes and a pinched nose", "Wide-open eyes with raised eyebrows and slightly parted lips.", "Eyes gazing downward with trembling lips"], "answer": "Squinted eyes and a pinched nose", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_464.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1093, 7229], [7559, 10065], [11475, 19032], [19794, 21368], [22267, 24507], [26256, 30439], [30831, 32743], [33604, 41240], [41578, 43398], [43815, 48353], [49089, 51923], [53162, 58014], [58014, 59287], [59655, 66207], [66804, 68870], [70653, 72030]], "num_segments": 16}
{"id": "sakura_emotion_466_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_466_masked_100pct.wav", "question": "Based on the emotion identified in the audio, which of these facial expressions is most likely to match the speaker's emotional state?", "choices": ["Retracted chin with one corner of the mouth twitching, as if intolerable.", "A warm, genuine smile with slightly tilted head", "Flared nostrils with a tense expression", "Eyes gazing downward with trembling lips"], "answer": "Eyes gazing downward with trembling lips", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_466.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[160, 3242], [3551, 10338], [10528, 12332], [13072, 15298], [15372, 18570], [18694, 19518], [19538, 22079], [22167, 23115], [24040, 28502], [29074, 30292], [30592, 31403], [31509, 32441], [32733, 34146], [34171, 36468], [36520, 37358]], "num_segments": 15}
{"id": "sakura_emotion_466_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_466_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "fear", "happy", "angry"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_466.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[81, 1961], [2027, 2980], [3231, 5226], [6082, 11984], [12303, 13595], [13686, 14533], [15044, 15862], [16468, 17360], [17363, 18724], [18906, 19965], [20025, 21214], [21357, 22301], [22790, 29663], [30047, 31835], [31995, 32834], [33018, 36424]], "num_segments": 16}
{"id": "sakura_emotion_468_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_468_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["I just can\u2019t stop thinking about all those bad memories.", "I can\u2019t shake the feeling that something bad is coming.", "That\u2019s just revolting, I can\u2019t believe it.", "This is the best day ever, I feel on top of the world!"], "answer": "That\u2019s just revolting, I can\u2019t believe it.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_468.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[83, 1639], [2463, 8596], [8652, 10190], [11648, 16061], [17524, 24019], [25449, 27838], [28855, 30087], [31198, 32750], [33049, 34063], [35085, 38161], [39541, 43003], [43572, 44905]], "num_segments": 12}
{"id": "sakura_emotion_468_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_468_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["angry", "happy", "fear", "disgust"], "answer": "disgust", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_468.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[30, 1446], [1725, 3854], [3887, 4805], [6152, 7726], [8280, 9253], [10269, 11897], [12312, 16381], [16686, 18282], [18757, 19928], [21011, 22003], [22019, 28821], [30763, 38554], [39005, 40580], [40997, 45222]], "num_segments": 14}
{"id": "sakura_emotion_469_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_469_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["happy", "fear", "sad", "disgust"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_469.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[724, 5322], [6250, 8630], [8837, 9907], [10397, 15054], [15295, 20117], [20462, 25065], [25238, 29204], [29453, 30346], [30603, 31420], [31737, 38149], [39451, 42273], [42740, 45348], [45462, 49874], [50172, 51003], [51803, 55309], [55362, 56811], [57818, 62442], [63452, 64456], [65130, 69577], [69915, 75498]], "num_segments": 20}
{"id": "sakura_emotion_469_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_469_masked_100pct.wav", "question": "Which facial expression best matches the emotion in the audio?", "choices": ["Eyes crinkling with an open-mouthed laugh", "A wrinkled nose and raised upper lip", "Wide-open eyes with raised eyebrows and slightly parted lips.", "Clenched teeth with side facial muscles showing tension."], "answer": "Wide-open eyes with raised eyebrows and slightly parted lips.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_469.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[245, 1570], [1776, 3417], [3434, 4547], [4812, 6391], [6929, 8920], [10994, 12299], [13098, 14022], [14159, 16708], [18458, 19515], [19522, 20436], [20599, 24940], [26563, 33873], [34577, 36506], [37230, 42904], [43125, 45741], [46026, 47405], [48309, 50692], [51520, 55438], [55524, 58715], [59007, 59894], [60202, 65015], [65868, 67986], [68428, 71445], [71791, 75490]], "num_segments": 24}
{"id": "sakura_emotion_471_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_471_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["fear", "sad", "disgust", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_471.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[431, 1603], [1792, 7509], [8200, 9092], [10082, 14945], [16068, 16969], [17021, 21203], [21411, 23749], [24854, 25832], [26273, 27941]], "num_segments": 9}
{"id": "sakura_emotion_471_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_471_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["Rejecting a tasteless meal with a grimace.", "A person smiling after receiving good news.", "Throwing an object in frustration.", "A person crying after a breakup."], "answer": "Throwing an object in frustration.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_471.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[52, 2024], [2239, 8485], [9589, 13230], [13875, 14845], [14945, 22045], [22445, 25300], [25966, 27325], [27358, 28630]], "num_segments": 8}
{"id": "sakura_emotion_472_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_472_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["Walking alone in a dark alley at night.", "Seeing an unpleasant image online.", "Attending a close friend's funeral.", "A parent scolding their child for misbehavior."], "answer": "Seeing an unpleasant image online.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_472.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[264, 1709], [2037, 3537], [4211, 5610], [6320, 7264], [8444, 12803], [13117, 14113], [15021, 22409], [22483, 23390], [24028, 25516], [26426, 29870], [30829, 35716], [36731, 43757], [44058, 45008], [45124, 48088]], "num_segments": 14}
{"id": "sakura_emotion_472_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_472_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["fear", "angry", "disgust", "sad"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_472.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[8, 2483], [2795, 3745], [3985, 7692], [7888, 9107], [10819, 18665], [19562, 20404], [21128, 21962], [22902, 24353], [24621, 30732], [31469, 32326], [33332, 37789], [38545, 39355], [39361, 47140], [47260, 48323]], "num_segments": 14}
{"id": "sakura_emotion_473_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_473_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "fear", "angry", "sad"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_473.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[30, 909], [1251, 2103], [2509, 4938], [5060, 8832], [9234, 10491], [11626, 18463], [19874, 20986], [21609, 22624], [23095, 24502], [24731, 29143], [29522, 31377], [31761, 35784], [35857, 37052], [37260, 38329], [38654, 40056], [40268, 43656], [43731, 44818], [45430, 48062], [48189, 49999], [50870, 52049], [52284, 53830], [53868, 54952], [56243, 62164], [62465, 65246], [65591, 68770], [69687, 70559], [72272, 74445], [74834, 76757]], "num_segments": 28}
{"id": "sakura_emotion_467_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_467_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["This thing looks absolutely gross and dirty; I can\u2019t stand it!", "This is terrifying, I can\u2019t stop thinking about it.", "I\u2019m just so happy I could burst!", "I can\u2019t believe this is happening, I\u2019m so furious!"], "answer": "I\u2019m just so happy I could burst!", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_467.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1454, 4468], [4944, 12457], [12747, 13553], [14908, 16478], [18405, 23677], [23723, 26045], [26612, 34100], [34389, 35702], [36798, 37861], [38314, 40902], [41108, 42200], [42683, 48281], [49299, 50655], [50673, 57988], [60015, 60901], [61384, 66253], [66357, 67461], [68986, 74877], [76890, 78922], [79502, 81392], [81646, 85522], [86822, 91800], [92401, 100137], [103460, 106193], [106484, 109054], [111137, 116740], [118014, 119898], [120167, 122554], [124033, 127041], [127895, 132360], [134394, 136318], [136355, 137165], [137854, 139506], [139856, 143527], [143866, 144889], [145955, 148438], [149569, 150876], [151350, 155048], [155075, 161739], [162366, 170183], [170485, 171861], [172073, 175060], [175141, 176341], [176879, 179758], [181368, 183448], [183511, 184597], [184628, 185544], [187374, 190652], [190899, 191738], [192435, 194250], [194531, 197417], [197966, 202442], [202535, 204170]], "num_segments": 53}
{"id": "sakura_emotion_467_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_467_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["angry", "disgust", "fear", "happy"], "answer": "happy", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_467.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[746, 1568], [2719, 4021], [6029, 9396], [9862, 14200], [15007, 16318], [17522, 20165], [21015, 23828], [24462, 26107], [28037, 31879], [32421, 33710], [34178, 37413], [38956, 45084], [45659, 47305], [47503, 53994], [56432, 57708], [58805, 59804], [61047, 65419], [65481, 69960], [71041, 75937], [77488, 78618], [78853, 80266], [80704, 82640], [84032, 88980], [90040, 95889], [96042, 97582], [98223, 104752], [104760, 108855], [110311, 111998], [112017, 113042], [113946, 115920], [117829, 124305], [127348, 128757], [128941, 134985], [135110, 139121], [139542, 144765], [146932, 148811], [150542, 157266], [157619, 165505], [166563, 167981], [169395, 170426], [171222, 175084], [177590, 178459], [178615, 181846], [182999, 187678], [188129, 189602], [190136, 192750], [194345, 196778], [198473, 201496], [202214, 204863]], "num_segments": 49}
{"id": "sakura_emotion_475_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_475_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Relaxed facial muscles with a cheerful grin", "A wrinkled nose and raised upper lip", "Downturned mouth and teary eyes", "Clenched teeth with side facial muscles showing tension."], "answer": "Clenched teeth with side facial muscles showing tension.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_475.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[64, 7425], [7962, 10552], [11366, 19058], [19693, 20945], [21937, 23767], [24485, 25965], [26177, 29517], [30300, 31684], [32306, 33544], [34355, 39247], [41030, 44792], [46025, 48014]], "num_segments": 12}
{"id": "sakura_emotion_474_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_474_masked_100pct.wav", "question": "Which facial expression best matches the emotion in the audio?", "choices": ["Relaxed facial muscles with a cheerful grin", "Downturned mouth and teary eyes", "Clenched teeth with side facial muscles showing tension.", "Squinted eyes and a pinched nose"], "answer": "Relaxed facial muscles with a cheerful grin", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_474.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1143, 2692], [4042, 8550], [8704, 9689], [9922, 12371], [13035, 14146], [15998, 23289], [23902, 28301], [29757, 32142], [32240, 35915], [36584, 41907], [42244, 43873], [44897, 47203]], "num_segments": 12}
{"id": "sakura_emotion_475_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_475_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "disgust", "angry", "fear"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_475.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1533, 6529], [7383, 9680], [10158, 11724], [13043, 14486], [15478, 16623], [17823, 21687], [22659, 23499], [23980, 31313], [31710, 32591], [32744, 35000], [35250, 37990], [38569, 42270], [43767, 44781], [45297, 47919], [47933, 48839]], "num_segments": 15}
{"id": "sakura_emotion_470_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_470_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["Slamming a door after a disagreement.", "Reacting to a foul odor in a room.", "Saying goodbye at an airport.", "Laughing at a funny joke in a conversation."], "answer": "Reacting to a foul odor in a room.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_470.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[273, 2799], [4089, 11791], [12081, 14378], [14791, 18381], [19788, 25220], [25350, 26638], [27813, 29136], [29166, 32795], [32893, 37931], [38439, 43035], [43415, 50885], [52328, 57769], [59305, 60893], [60983, 63745], [64352, 65345], [66332, 68662], [69474, 73715], [74993, 77694], [77735, 85388], [85604, 87476], [87618, 88774], [89577, 95958], [96024, 96968], [98732, 100356], [101808, 106801], [107251, 111038], [111056, 116683], [119513, 123561], [123563, 125157], [126148, 131363]], "num_segments": 30}
{"id": "sakura_emotion_474_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_474_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["happy", "sad", "angry", "fear"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_474.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[260, 3476], [3862, 5816], [6093, 12821], [13489, 14550], [14764, 16497], [16764, 18704], [20857, 23361], [25209, 26139], [26505, 32185], [32861, 33940], [34140, 35587], [36008, 43016], [44045, 47235]], "num_segments": 13}
{"id": "sakura_emotion_473_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_473_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["A person crying after a breakup.", "Reacting to a foul odor in a room.", "Throwing an object in frustration.", "Laughing at a funny joke in a conversation."], "answer": "Laughing at a funny joke in a conversation.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_473.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[177, 2658], [3491, 4466], [6185, 8155], [8614, 12962], [13749, 15064], [17044, 23027], [23781, 26430], [26784, 30585], [30764, 31913], [33524, 34782], [35220, 40247], [41137, 42049], [42346, 43239], [43686, 48266], [49637, 50482], [51835, 54645], [55876, 59636], [59934, 61515], [62205, 65673], [66107, 67660], [69782, 71464], [72088, 73761], [74112, 75542], [75692, 76786], [77096, 78508]], "num_segments": 25}
{"id": "sakura_emotion_470_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_470_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["disgust", "fear", "happy", "angry"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_470.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[2301, 6682], [6806, 7992], [8661, 10119], [11378, 16121], [18677, 25012], [25777, 27055], [27103, 29358], [29845, 30660], [32639, 35174], [36884, 40246], [40713, 42023], [43512, 44546], [44905, 50833], [51258, 53269], [54911, 62314], [62340, 65715], [66506, 71430], [71761, 74537], [75281, 79909], [81330, 83388], [84034, 86443], [87100, 88445], [90346, 95964], [96678, 97794], [98249, 100921], [101134, 108292], [110324, 111315], [111797, 114157], [116052, 118768], [120379, 122071], [122487, 124058], [124300, 129353], [129502, 130591]], "num_segments": 33}
{"id": "sakura_emotion_476_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_476_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["angry", "happy", "disgust", "fear"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_476.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[332, 4926], [6054, 8467], [8739, 11941], [11950, 17920], [18069, 25493], [26190, 27600], [28524, 29538], [30037, 34057], [35117, 41142], [41352, 42319], [42406, 49504], [49745, 51541]], "num_segments": 12}
{"id": "sakura_emotion_477_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_477_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "happy", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_477.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1219, 8088], [8235, 9802], [10257, 12918], [13988, 15077], [15612, 17091], [18169, 19145], [20601, 26818], [26922, 29909], [29997, 34164], [35229, 36851], [36870, 43925], [44990, 45849], [45932, 46795], [47358, 48419], [48592, 50860], [51905, 53463], [55363, 57231], [58159, 62125], [62808, 68860], [69573, 75808], [78362, 84685], [85763, 88256]], "num_segments": 22}
{"id": "sakura_emotion_476_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_476_masked_100pct.wav", "question": "Based on the emotion conveyed by the speaker in the audio, which of the following social interactions would be the most suitable response?", "choices": ["Offer congratulations or compliments to share their happiness.", "Encourage them to take deep breaths to relax.", "Reassure them and offer a way to move past the uncomfortable    situation.", "Give them space to cool off before engaging further."], "answer": "Reassure them and offer a way to move past the uncomfortable    situation.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_476.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[161, 1249], [1471, 3231], [4194, 11660], [11957, 18648], [19237, 25152], [25660, 26976], [26982, 29072], [29203, 34737], [34756, 40775], [42538, 45953], [46999, 49195], [49772, 50671]], "num_segments": 12}
{"id": "sakura_emotion_477_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_477_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Downturned mouth and teary eyes", "Tightly furrowed brow with trembling lips", "Clenched teeth with side facial muscles showing tension.", "Relaxed facial muscles with a cheerful grin"], "answer": "Downturned mouth and teary eyes", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_477.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[621, 4145], [5453, 7039], [8181, 12501], [12847, 19800], [20691, 21937], [23317, 26571], [26793, 28415], [29382, 30324], [30504, 33346], [33346, 36690], [37539, 42809], [43308, 44282], [45142, 47197], [48011, 48922], [48951, 53204], [53231, 57493], [59229, 66995], [67402, 69128], [70617, 73685], [73747, 75337], [75766, 82723], [83483, 85002], [85148, 86481], [86656, 88275]], "num_segments": 24}
{"id": "sakura_emotion_479_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_479_masked_100pct.wav", "question": "From the provided sentences, which one best matches the emotional state of individuals who are experiencing the same emotion as the speaker?", "choices": ["I\u2019m so excited, I just can\u2019t contain my happiness!", "This situation is really starting to piss me off!", "It\u2019s so dirty! Please clean it as quick as possible.", "I can\u2019t shake the feeling that something bad is coming."], "answer": "I\u2019m so excited, I just can\u2019t contain my happiness!", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_479.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[60, 1899], [2151, 3955], [5345, 6814], [7371, 8435], [8437, 13791], [14609, 16090], [16576, 17803], [18341, 19375], [19446, 20289], [21513, 23218], [24221, 26824], [27150, 28871], [29474, 32984], [34548, 35413], [35789, 40903]], "num_segments": 15}
{"id": "sakura_emotion_478_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_478_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "happy", "disgust", "angry"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_478.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[29, 1191], [1319, 3307], [3705, 9526], [9560, 16690], [17474, 24464], [24605, 25713], [26480, 28755], [29041, 30852], [31670, 33775], [35121, 39864], [40013, 42784], [42838, 48352], [48669, 50577], [50843, 52119], [52337, 55118], [55158, 56424], [56445, 58066], [58400, 61731], [61920, 63841], [64603, 66419]], "num_segments": 20}
{"id": "sakura_emotion_479_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_479_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "sad", "angry", "fear"], "answer": "happy", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_479.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[978, 1837], [1918, 4719], [4805, 6041], [6681, 13000], [13067, 14224], [14406, 19252], [19373, 21533], [21751, 23943], [24031, 25505], [25625, 29464], [29614, 30446], [30836, 31727], [31778, 33378], [33921, 37561], [37606, 39879], [40486, 41332]], "num_segments": 16}
{"id": "sakura_emotion_478_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_478_masked_100pct.wav", "question": "Considering the emotion communicated in this speech, which of these scenarios aligns most closely with the speaker's emotional state?", "choices": ["Walking alone in a dark alley at night.", "Laughing at a funny joke in a conversation.", "Reacting to a foul odor in a room.", "A heated argument between colleagues."], "answer": "Reacting to a foul odor in a room.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_478.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1210, 2047], [2346, 3218], [3662, 6259], [6646, 8874], [9345, 11764], [13370, 14666], [15914, 16802], [17898, 19061], [19634, 23756], [24095, 28614], [28672, 30701], [31027, 32816], [32996, 38049], [38178, 39497], [40400, 41521], [42350, 45898], [47631, 48593], [49129, 56429], [58421, 59511], [59586, 62012], [62255, 63541], [64477, 66890]], "num_segments": 22}
{"id": "sakura_emotion_480_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_480_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["I\u2019ve had enough of this nonsense.", "I can\u2019t shake the feeling that something bad is coming.", "It\u2019s hard to imagine things ever getting better.", "I can\u2019t even look at this without feeling uncomfortable."], "answer": "I can\u2019t shake the feeling that something bad is coming.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_480.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[281, 6864], [7333, 8200], [9139, 12342], [12344, 13769], [13973, 17935], [17939, 20336], [20457, 21717], [23609, 24655], [25200, 26854], [27698, 33714], [34218, 41098], [41843, 42762], [43183, 44069], [44176, 46073], [47661, 51199], [52153, 56012]], "num_segments": 16}
{"id": "sakura_emotion_480_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_480_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["disgust", "fear", "sad", "angry"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_480.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[293, 1245], [1529, 9011], [9470, 12495], [13008, 13808], [14164, 15243], [15788, 21553], [21572, 23867], [25299, 27619], [29205, 35066], [35456, 37451], [37636, 39208], [39644, 40501], [40634, 42403], [42533, 48809], [49685, 50540], [50807, 56285]], "num_segments": 16}
{"id": "sakura_emotion_481_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_481_masked_100pct.wav", "question": "Which sentence most accurately reflects how people feeling the same emotion as the speaker might express themselves?", "choices": ["It\u2019s so dirty! Please clean it as quick as possible.", "Stop making excuses; this is entirely your fault!", "This is the best day ever, I feel on top of the world!", "It\u2019s hard to imagine things ever getting better."], "answer": "Stop making excuses; this is entirely your fault!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_481.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[76, 7815], [8486, 10989], [11201, 13639], [14536, 16465], [16477, 17362], [17400, 18462], [18881, 22303], [23009, 26780], [27716, 31456], [33357, 40212], [41835, 42879], [43691, 44894], [45450, 48162], [48965, 50396]], "num_segments": 14}
{"id": "sakura_emotion_481_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_481_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["happy", "disgust", "angry", "sad"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_481.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[842, 2973], [3487, 11061], [11133, 12389], [12462, 13365], [13437, 16982], [17014, 18880], [20761, 22128], [22187, 26227], [26771, 27858], [27941, 29353], [30374, 32649], [34331, 35233], [35773, 39285], [39345, 41587], [42194, 48847], [48987, 50613]], "num_segments": 16}
{"id": "sakura_emotion_484_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_484_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["fear", "happy", "disgust", "angry"], "answer": "angry", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_484.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[161, 1027], [1901, 3115], [4481, 9778], [9981, 11107], [11168, 17943], [19205, 23283]], "num_segments": 6}
{"id": "sakura_emotion_484_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_484_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Frozen facial expression with trembling lips and quickened breathing.", "A warm, genuine smile with slightly tilted head", "Tightly pressed lips with glaring eyes", "A wrinkled nose and raised upper lip"], "answer": "Tightly pressed lips with glaring eyes", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_484.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[965, 5241], [5360, 6306], [6396, 11986], [12434, 18285], [18812, 23235]], "num_segments": 5}
{"id": "sakura_emotion_482_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_482_masked_100pct.wav", "question": "Based on the emotion identified in the audio, which of these facial expressions is most likely to match the speaker's emotional state?", "choices": ["Flared nostrils with a tense expression", "Tightly furrowed brow with trembling lips", "Retracted chin with one corner of the mouth twitching, as if intolerable.", "Eyes crinkling with an open-mouthed laugh"], "answer": "Tightly furrowed brow with trembling lips", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_482.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1263, 2597], [3109, 4223], [4422, 10946], [11344, 12319], [14268, 15104], [15148, 18074], [19532, 25090], [25742, 27244], [28726, 33422], [35448, 39427], [40120, 42383], [43377, 46156], [47877, 49999], [52180, 53860], [54356, 58652], [59976, 67256], [69100, 73552], [74209, 76889], [77372, 81418], [82400, 83947], [85681, 87035], [87042, 89188], [89369, 92067], [92482, 97180], [97287, 98561], [98985, 100777], [101537, 106222], [107292, 108624], [108841, 110484], [110757, 114215], [115169, 118149]], "num_segments": 31}
{"id": "sakura_emotion_485_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_485_masked_100pct.wav", "question": "From the listed facial expressions, which do you think is the most accurate representation of the emotion heard in the audio?", "choices": ["Eyes crinkling with an open-mouthed laugh", "Downturned mouth and teary eyes", "Head slightly pulled back with a terrified gaze, as if searching for an escape.", "A wrinkled nose and raised upper lip"], "answer": "Eyes crinkling with an open-mouthed laugh", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_485.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[400, 1203], [1487, 9268], [9332, 10922], [10968, 17242], [17641, 18633], [18673, 19927]], "num_segments": 6}
{"id": "sakura_emotion_485_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_485_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["sad", "happy", "disgust", "fear"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_485.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[967, 4742], [5637, 12854], [12862, 19834]], "num_segments": 3}
{"id": "sakura_emotion_483_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_483_masked_100pct.wav", "question": "Considering the emotion expressed by the speaker in the audio, which social interaction do you think is most appropriate as a response?", "choices": ["Smile and engage positively in the conversation.", "Hold their hand or offer some physical reassurance.", "Listen attentively without interrupting to let them vent.", "Listen empathetically and let them express their feelings."], "answer": "Listen attentively without interrupting to let them vent.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_483.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[226, 1031], [2001, 2960], [3099, 6101], [6361, 8502], [9008, 9984], [10141, 12263], [14083, 18271], [18346, 19656], [19843, 20843], [21608, 22492], [23096, 24182], [25269, 26518], [26760, 28371], [29006, 34939], [35066, 38566], [38578, 41133], [41760, 48832], [49072, 52968], [53340, 54224]], "num_segments": 19}
{"id": "sakura_emotion_482_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_482_masked_100pct.wav", "question": "How does the speaker feel in the recording?", "choices": ["happy", "disgust", "sad", "fear"], "answer": "fear", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_482.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[68, 2660], [2737, 4691], [5371, 7669], [7995, 9470], [9709, 14570], [14603, 16452], [16731, 21292], [21828, 22634], [24375, 26583], [27100, 29023], [30018, 31949], [33278, 35811], [36260, 37904], [37987, 38809], [39289, 40091], [41438, 47041], [48065, 50276], [50859, 52763], [53906, 55652], [55959, 57509], [58657, 62823], [64004, 67765], [68553, 72924], [73214, 75188], [75315, 78410], [78790, 86540], [86788, 89999], [90579, 93751], [95632, 97903], [98825, 99947], [101941, 107203], [108685, 110667], [110712, 114266], [114974, 115823], [116159, 117014], [117660, 118654]], "num_segments": 36}
{"id": "sakura_emotion_486_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_486_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "disgust", "happy", "sad"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_486.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[582, 1389], [1824, 2759], [3129, 4420], [4834, 12780], [13417, 17885], [18280, 19214]], "num_segments": 6}
{"id": "sakura_emotion_486_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_486_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["I just can\u2019t stop thinking about all those bad memories.", "I can\u2019t even look at this without feeling uncomfortable.", "This is terrifying, I can\u2019t stop thinking about it.", "I can\u2019t believe this is happening, I\u2019m so furious!"], "answer": "I can\u2019t even look at this without feeling uncomfortable.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_486.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[334, 1737], [2174, 4607], [5317, 8440], [8884, 15038], [15122, 16069], [16195, 18100]], "num_segments": 6}
{"id": "sakura_emotion_483_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_483_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["disgust", "sad", "angry", "happy"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_483.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1225, 3293], [4420, 5625], [5681, 10838], [12422, 18973], [19501, 22024], [22308, 25486], [26145, 27173], [28288, 29679], [30022, 31054], [32090, 32959], [32988, 40137], [40858, 45397], [45740, 46995], [47663, 53881]], "num_segments": 14}
{"id": "sakura_emotion_488_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_488_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["angry", "happy", "disgust", "sad"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_488.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[212, 1342], [1380, 6687], [7728, 8791], [9731, 11554], [11818, 18643], [19952, 20878], [21318, 23831], [24766, 31777], [32426, 38692], [38933, 41042], [41917, 43991], [44297, 45215]], "num_segments": 12}
{"id": "sakura_emotion_489_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_489_masked_100pct.wav", "question": "Considering the speaker's emotion, which sentence would best represent the feelings of others who are experiencing the same emotion?", "choices": ["I don\u2019t know how to move on from this loss.", "This is the best day ever, I feel on top of the world!", "Stop making excuses; this is entirely your fault!", "I can\u2019t even look at this without feeling uncomfortable."], "answer": "This is the best day ever, I feel on top of the world!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_489.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[222, 1055], [1230, 3277], [3546, 4496]], "num_segments": 3}
{"id": "sakura_emotion_487_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_487_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["fear", "disgust", "angry", "sad"], "answer": "angry", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_487.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1601, 4437], [4442, 5778], [6612, 8784], [9242, 10550], [11356, 18125], [18908, 19716], [19936, 23604], [24369, 25753], [25871, 27117], [27240, 28225], [29153, 35130], [35204, 36055], [36436, 37331], [39285, 40714], [41629, 43915], [44317, 47859], [47996, 48823], [49960, 53551], [54156, 54988], [55117, 62943], [63516, 64902], [65130, 69490], [70526, 77666], [79041, 80872], [81072, 81997]], "num_segments": 25}
{"id": "sakura_emotion_487_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_487_masked_100pct.wav", "question": "From the provided sentences, which one best matches the emotional state of individuals who are experiencing the same emotion as the speaker?", "choices": ["I can\u2019t stop smiling, everything feels so right.", "How dare they treat me so unfairly like this!", "I\u2019m really scared about what might happen next.", "I can\u2019t even look at this without feeling uncomfortable."], "answer": "How dare they treat me so unfairly like this!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_487.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[929, 4440], [6266, 11546], [12164, 13398], [13544, 14358], [16428, 18995], [19997, 20869], [21128, 22791], [22863, 24209], [25999, 26857], [28995, 30056], [30636, 32010], [32148, 33422], [34018, 39966], [40612, 44409], [44572, 45577], [47050, 48545], [49523, 54931], [55319, 57593], [58052, 58878], [60142, 65820], [66177, 67123], [67579, 68864], [70020, 77971], [78171, 80509]], "num_segments": 24}
{"id": "sakura_emotion_488_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_488_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Reading a heartfelt goodbye letter.", "Throwing an object in frustration.", "Turning away from spoiled food.", "Celebrating a birthday with friends and family."], "answer": "Turning away from spoiled food.", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_488.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[390, 1429], [1924, 5146], [5771, 6605], [7320, 10464], [11143, 12267], [12708, 13676], [13685, 15245], [15549, 16364], [16599, 24207], [25179, 27206], [27236, 28299], [29043, 29995], [31302, 32577], [33776, 34681], [35591, 38537], [39539, 45260]], "num_segments": 16}
{"id": "sakura_emotion_489_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_489_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["sad", "happy", "disgust", "angry"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_489.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[425, 1270], [1980, 5061]], "num_segments": 2}
{"id": "sakura_emotion_490_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_490_masked_100pct.wav", "question": "From the provided sentences, which one best matches the emotional state of individuals who are experiencing the same emotion as the speaker?", "choices": ["Stop making excuses; this is entirely your fault!", "This thing looks absolutely gross and dirty; I can\u2019t stand it!", "This is terrifying, I can\u2019t stop thinking about it.", "I feel so empty, like nothing matters anymore."], "answer": "This thing looks absolutely gross and dirty; I can\u2019t stand it!", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_490.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1057, 2399], [2917, 10292], [10984, 12860], [14530, 18213], [18365, 19196], [19249, 20565], [21050, 22849], [24018, 25637], [25712, 27224], [27625, 29255], [30237, 33642], [33881, 34814], [35095, 40196], [41478, 42600], [43276, 44154], [44459, 45455]], "num_segments": 16}
{"id": "sakura_emotion_490_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_490_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["angry", "fear", "disgust", "happy"], "answer": "disgust", "answer_key": 2, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_490.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1280, 4333], [5468, 11016], [12305, 17684], [17760, 18642], [18839, 24043], [24122, 25692], [25970, 30028], [30592, 31790], [31795, 33169], [34222, 36636], [36654, 38685], [40323, 45880]], "num_segments": 12}
{"id": "sakura_emotion_492_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_492_masked_100pct.wav", "question": "Using the provided audio clip as input, how would you interpret or classify the speaker's underlying emotions?", "choices": ["sad", "happy", "disgust", "angry"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_492.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[278, 1364], [2482, 8369], [10057, 16907], [17672, 20312], [21994, 24695], [25163, 28204], [28314, 29331], [29440, 34465], [35082, 36225]], "num_segments": 9}
{"id": "sakura_emotion_492_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_492_masked_100pct.wav", "question": "From the provided options, which scenario most likely corresponds to the emotion expressed by the speaker in the speech?", "choices": ["Watching a touching but sorrowful movie scene.", "Reacting to a foul odor in a room.", "Walking alone in a dark alley at night.", "Winning a long-anticipated award or prize."], "answer": "Winning a long-anticipated award or prize.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_492.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[350, 2428], [3425, 7008], [8092, 8924], [8990, 11234], [11599, 19077], [20298, 21320], [21325, 27749], [27958, 28776], [28988, 30771], [30875, 31839], [32070, 33062], [33359, 34966], [35085, 36451]], "num_segments": 13}
{"id": "sakura_emotion_491_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_491_masked_100pct.wav", "question": "Based on the emotion expressed in the audio, which facial expression would be the most likely one?", "choices": ["Relaxed facial muscles with a cheerful grin", "A heavy sigh with a frown and slumped posture", "Furrowed brows with slightly open mouth, as if about to shout.", "Frozen facial expression with trembling lips and quickened breathing."], "answer": "A heavy sigh with a frown and slumped posture", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_491.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[781, 2228], [3761, 5634], [5721, 9327], [9992, 11992], [12812, 16488], [16953, 20913], [21528, 22688], [22740, 24592], [24803, 26151], [26237, 33620], [33933, 34843], [35243, 38277], [38631, 41142], [43146, 50625]], "num_segments": 14}
{"id": "sakura_emotion_493_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_493_masked_100pct.wav", "question": "Considering a provided audio clip, can you determine the emotional state expressed by the speaker in the recording?", "choices": ["disgust", "fear", "sad", "angry"], "answer": "disgust", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_493.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1424, 2425], [2738, 4497], [5249, 6315], [6496, 7420], [8026, 10752], [10786, 16152], [16301, 17214], [17612, 18908]], "num_segments": 8}
{"id": "sakura_emotion_491_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_491_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["sad", "angry", "fear", "happy"], "answer": "sad", "answer_key": 0, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_491.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[831, 3174], [3656, 9669], [9821, 10628], [11779, 13461], [13660, 15472], [15548, 20900], [21026, 23546], [23824, 27757], [27903, 29010], [30624, 31498], [31921, 33190], [33623, 34431], [34451, 38165], [39427, 42942], [43441, 44315], [44413, 51144]], "num_segments": 16}
{"id": "sakura_emotion_494_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_494_masked_100pct.wav", "question": "What emotional tone or feeling is conveyed by the speaker in the given audio file based on their vocal cues?", "choices": ["angry", "happy", "disgust", "sad"], "answer": "sad", "answer_key": 3, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_494.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[194, 1294], [1873, 2723], [3074, 3956], [4664, 6282], [6341, 14142], [14958, 16413], [17866, 19697], [20921, 25966], [26265, 27432], [28698, 32441], [32712, 38674], [38855, 40393], [41063, 42090]], "num_segments": 13}
{"id": "sakura_emotion_493_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_493_masked_100pct.wav", "question": "Which sentence best matches the emotional state of others with the same emotion expressed in the audio?", "choices": ["I\u2019m really scared about what might happen next.", "I can\u2019t stop smiling, everything feels so right.", "I just can\u2019t stop thinking about all those bad memories.", "I can\u2019t even look at this without feeling uncomfortable."], "answer": "I can\u2019t even look at this without feeling uncomfortable.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_493.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[170, 1033], [1388, 4856], [5875, 10424], [10642, 11592], [11605, 16781], [17541, 19425]], "num_segments": 6}
{"id": "sakura_emotion_494_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_494_masked_100pct.wav", "question": "Given the emotion the speaker expressed in the audio, which social interaction is the most appropriate response?", "choices": ["Suggest spending some time together to cheer them up.", "Smile and engage positively in the conversation.", "Apologize for their discomfort and change the topic to avoid making them more uncomfortable.", "Listen attentively without interrupting to let them vent."], "answer": "Suggest spending some time together to cheer them up.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_494.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[97, 1525], [1921, 2889], [2965, 4059], [4230, 8591], [8648, 11788], [12110, 13585], [13793, 14842], [14927, 15807], [17346, 18686], [18859, 20066], [20372, 27187], [27341, 28626], [30735, 33543], [33595, 35205], [36222, 37117], [38636, 39965], [40425, 42314]], "num_segments": 17}
{"id": "sakura_emotion_496_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_496_masked_100pct.wav", "question": "What is the emotional tone of the speaker in the audio?", "choices": ["disgust", "angry", "fear", "sad"], "answer": "angry", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_496.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[198, 1347], [1642, 4105], [4320, 5530], [5614, 8804], [9011, 10334], [10511, 11588], [11849, 13401], [13543, 14651], [14897, 15840], [16092, 16916], [17217, 18475], [19378, 21024], [21983, 23680], [23819, 25184], [25914, 27638]], "num_segments": 15}
{"id": "sakura_emotion_496_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_496_masked_100pct.wav", "question": "Which sentence would people feeling the same emotion most likely to say?", "choices": ["This is the best day ever, I feel on top of the world!", "I can\u2019t even look at this without feeling uncomfortable.", "I feel so empty, like nothing matters anymore.", "Stop making excuses; this is entirely your fault!"], "answer": "Stop making excuses; this is entirely your fault!", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_496.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1234, 3655], [4092, 5215], [6442, 12073], [12594, 13950], [14200, 16894], [17091, 18250], [18498, 20173], [20322, 25720], [25724, 26919], [27818, 28653]], "num_segments": 10}
{"id": "sakura_emotion_495_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_495_masked_100pct.wav", "question": "Which facial expression best fits the emotion heard in the audio?", "choices": ["Downturned mouth and teary eyes", "Head slightly pulled back with a terrified gaze, as if searching for an escape.", "A wrinkled nose and raised upper lip", "A warm, genuine smile with slightly tilted head"], "answer": "A wrinkled nose and raised upper lip", "answer_key": 2, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_495.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[350, 1366], [1732, 3202], [3228, 8371], [8815, 14394], [15583, 16462], [17281, 23338], [24363, 29578], [29635, 31812], [32111, 37923], [37972, 41356], [41425, 42992], [44036, 46374], [46375, 47350], [47559, 49824], [49912, 56088], [56479, 58790], [60084, 61355], [62425, 66155], [67814, 70020], [70445, 75532], [75803, 78027], [79696, 82322], [82933, 88058], [89709, 91920]], "num_segments": 24}
{"id": "sakura_emotion_495_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_495_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "disgust", "fear", "sad"], "answer": "disgust", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_495.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1783, 2704], [3001, 3969], [4455, 7083], [8720, 16611], [17245, 18844], [19074, 20678], [21651, 23056], [23279, 24352], [25829, 33045], [33371, 36778], [36916, 37782], [38016, 40492], [42219, 43651], [43829, 45561], [45606, 46725], [46904, 52547], [52790, 53995], [54036, 55663], [56350, 61013], [63102, 64358], [65173, 65974], [67050, 70255], [70417, 74967], [75524, 77249], [77250, 79609], [80332, 83825], [85470, 89649]], "num_segments": 27}
{"id": "sakura_emotion_498_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_498_masked_100pct.wav", "question": "Which of the following scenarios do you think best matches the speaker's emotion conveyed in this speech?", "choices": ["Throwing an object in frustration.", "Preparing for a high-stakes exam with anxiety.", "Seeing an unpleasant image online.", "Laughing at a funny joke in a conversation."], "answer": "Preparing for a high-stakes exam with anxiety.", "answer_key": 1, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_498.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[35, 885], [1228, 2106], [2200, 3340], [3354, 4220], [4801, 8266], [9245, 12424], [12457, 13373], [13486, 14774], [16103, 17700], [18012, 20182], [20773, 21589], [22064, 24050], [24105, 28735], [29447, 32066], [32947, 35931], [36297, 37686], [38246, 39901], [41748, 45723], [46661, 48145], [48844, 50386], [51718, 53584], [53643, 57821], [58748, 59659]], "num_segments": 23}
{"id": "sakura_emotion_498_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_498_masked_100pct.wav", "question": "Can you identify the speaker's emotion from this clip?", "choices": ["disgust", "fear", "happy", "sad"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_498.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1512, 2444], [2761, 3692], [3786, 4612], [4880, 6963], [8464, 10891], [10917, 11758], [12145, 14810], [16934, 19608], [19972, 22311], [22754, 23573], [24148, 25948], [25983, 26954], [27142, 34436], [34530, 35875], [35948, 41257], [41420, 43401], [43634, 46855], [47358, 50770], [52193, 56203], [56737, 59252]], "num_segments": 20}
{"id": "sakura_emotion_497_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_497_masked_100pct.wav", "question": "What emotion is the speaker expressing in the audio?", "choices": ["angry", "happy", "disgust", "sad"], "answer": "happy", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_497.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[990, 8225], [10032, 12201], [12966, 15345], [17283, 21799], [22278, 29061], [29717, 34564], [35604, 40637], [41375, 42495], [43626, 50373], [50726, 53783], [54600, 57435], [59067, 61524], [62443, 69677], [71009, 72998], [73178, 74293], [75312, 76287], [77543, 78462], [78887, 84534], [85918, 86930], [87037, 88979], [89047, 90760], [91689, 98305], [100165, 101169], [101169, 102416], [104955, 110370], [110382, 112501], [113066, 116461], [117367, 119098], [119352, 120211], [121285, 128007], [130641, 132085], [132918, 138333]], "num_segments": 32}
{"id": "sakura_emotion_497_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_497_masked_100pct.wav", "question": "Based on the emotional tone of the speech, which scenario seems to best reflect the speaker's emotion?", "choices": ["Laughing at a funny joke in a conversation.", "Reacting to a foul odor in a room.", "A parent scolding their child for misbehavior.", "Attending a close friend's funeral."], "answer": "Laughing at a funny joke in a conversation.", "answer_key": 0, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_497.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[1241, 2305], [3400, 5719], [7155, 10379], [11441, 18780], [18880, 22614], [22951, 25254], [25526, 31675], [33745, 35388], [36718, 37994], [38273, 40746], [43048, 49568], [51508, 58988], [61028, 61991], [64549, 69265], [69840, 70643], [72187, 79601], [79956, 82545], [82730, 89804], [89962, 92436], [93088, 97501], [99444, 100996], [101760, 107519], [108200, 115762], [116530, 118318], [118407, 119788], [121264, 122094], [124705, 128986], [130056, 132155], [132643, 133638], [134310, 135266], [135816, 136795]], "num_segments": 31}
{"id": "sakura_emotion_499_single", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_499_masked_100pct.wav", "question": "From the available audio recording, can you analyze and identify the emotion being expressed by the speaker?", "choices": ["angry", "fear", "sad", "disgust"], "answer": "fear", "answer_key": 1, "hop_type": "single", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_499.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[350, 3427], [3552, 8877], [9103, 15529], [17581, 18784], [19590, 22072], [23589, 28508], [29360, 31331], [31763, 37820], [38907, 44986], [45995, 47015], [47124, 48972], [50381, 52805], [53348, 55229], [55240, 59801], [60156, 66260], [66787, 72528], [72777, 75173], [75589, 76925], [77753, 81409], [83878, 88543], [88672, 91696]], "num_segments": 21}
{"id": "sakura_emotion_499_multi", "audio_path": "data/sakura/emotion_masked/noise_scattered/100/audio/sakura_emotion_audio_499_masked_100pct.wav", "question": "What facial expression most aligns with the emotion in the recording?", "choices": ["A sharp, piercing gaze and compressed lips", "A broad smile with sparkling eyes", "Eyes gazing downward with trembling lips", "Frozen facial expression with trembling lips and quickened breathing."], "answer": "Frozen facial expression with trembling lips and quickened breathing.", "answer_key": 3, "hop_type": "multi", "track": "emotion", "modality": "audio", "language": "en", "source": "sakura", "original_audio_path": "data/sakura/emotion/audio/sakura_emotion_audio_499.wav", "mask_type": "noise", "mask_mode": "scattered", "mask_percent": 100, "mask_segments": [[791, 1698], [1979, 3066], [3352, 4475], [4807, 9920], [10232, 12315], [12345, 13700], [13752, 16770], [18322, 20692], [20721, 22254], [22312, 26569], [27208, 33205], [33318, 34650], [35322, 36400], [37035, 39073], [39900, 45293], [46170, 48805], [49934, 55619], [55846, 56669], [56751, 57969], [58291, 61904], [63728, 66105], [67393, 74199], [76174, 78705], [79795, 87123], [88179, 89707], [91440, 92637]], "num_segments": 26}
